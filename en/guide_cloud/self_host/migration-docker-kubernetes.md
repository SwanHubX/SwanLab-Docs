# Migration from Docker Version to K8S Version

This guide is intended for migrating data from the SwanLab Docker version to the **SwanLab Kubernetes (K8S)** version, and is only applicable to scenarios where external services are integrated into the **SwanLab Kubernetes (K8S)** version (see [Customizing Basic Service Resources](/en/guide_cloud/self_host/kubernetes-deploy.md#_3-1-customizing-basic-service-resources)).

![migration from docker to kubernetes](./kubernetes/migration.png)

If you wish to migrate to managed services provided by cloud vendors or to self-deployed cloud-native high-availability services, this guide can serve as a reference. Meanwhile, please refer to the official migration documentation of the corresponding cloud vendors and cloud-native projects, and ensure that database names, table names, and object storage bucket names are correct during migration.

[[toc]]

-----

**Requirements for this solution:**

1.  Migrate data first, then deploy services.
2.  You utilize the [Customizing Basic Service Resources](/en/guide_cloud/self_host/kubernetes-deploy.md#_3-1-customizing-basic-service-resources) feature.
3.  You have a busybox image for performing migration tasks.
4.  Ensure your Storage Class reclaim policy does not delete data when Pods are uninstalled.

**We pre-create storage volumes by packaging data, downloading it to store in data volumes, and then mounting the storage volume resources.**

-----

**Please identify the resources you need to migrate:**

1.  **PostgreSQL Single Instance**: Stores SwanLab's core business data.
2.  **Clickhouse Single Instance**: Stores metric data.
3.  **MinIO Single Instance**: Stores media resources.
4.  **Redis Single Instance**: Cache service.

Note that SwanLab-House does not require data migration.

:::warning
Before migrating, please ensure:

1.  Your Docker service has stopped, or you ensure the migrated data is extracted based on a specific storage snapshot.
2.  You have located the data volume path mounted by the SwanLab Docker version. By default, it should be under the `docker/swanlab/data` directory of the [self-hosted](https://github.com/SwanHubX/self-hosted) project. If you have forgotten the storage path, you can find the data volume mount location of the corresponding service container via the `docker inspect` command.
3.  You have found the `docker-compose.yaml` generated by swanlab. This is mainly for migrating account credentials. If you have forgotten the location of the `docker-compose.yaml` file, you can still find the corresponding account password environment variables via `docker inspect`.
:::

For ease of description, the following docker-related commands are based on `self-hosted/docker/swanlab/`. Please adjust the corresponding paths according to your actual situation.

In addition, the account credentials involved in this guide are for reference only; please adjust them according to your actual configuration.

Please clarify the storage locations of various basic service resources in the Docker version:

1.  PostgreSQL data is in `self-hosted/docker/swanlab/data/postgres`
2.  Clickhouse data is stored in `self-hosted/docker/swanlab/data/clickhouse`
3.  Minio data is stored in `self-hosted/docker/swanlab/data/minio`
4.  Redis data is stored in `self-hosted/docker/swanlab/data/redis`

<img src="./kubernetes/datadir.png" alt="Data Directory" width=300>

<br>

-----

**Terminology:**

  - `self-hosted`: The deployed SwanLab Kubernetes cluster

## 1\. Migrating Postgresql

  - Connection string example: `postgresql://swanlab:1uuYNzZa4p@postgres:5432/app?schema=public`

### 1.1 Packaging and Uploading the Archive

:::warning
Note that for pg, its data directory is located under `/var/lib/postgresql/data`, corresponding to the external data volume `/data/postgres/data`. However, pg does not allow folders other than `data` in the `/var/lib/postgresql` directory, so for PG, the final archive must be a `data` directory.
:::

Use the following command to package pg data:

```bash
tar -czvf postgres-data.tar.gz -C data/postgres/ .
```

Then upload it to object storage or any network storage service accessible by the cluster. In this example, we upload to Aliyun Object Storage. The file link example is:

```
https://xxx.oss-cn-beijing.aliyuncs.com/self-hosted/docker/postgres-data.tar.gz
```

### 1.2 Copying Data to Storage Volume

Reference configuration is as follows:

```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: postgres-migrate
  labels:
    swanlab: postgres
spec:
  template:
    spec:
      restartPolicy: OnFailure
      containers:
        - name: postgres-migrate
          image: busybox:1.37.0
          imagePullPolicy: IfNotPresent
          volumeMounts:
            - name: postgres-volume
              mountPath: /data
          env:
            - name: FILE_URL
              value: "https://xxx.oss-cn-beijing.aliyuncs.com/self-hosted/docker/postgres-data.tar.gz"
          command:
            - /bin/sh
            - -c
            - |
              wget $FILE_URL -O /tmp/postgres-data.tar.gz
              tar -xzvf /tmp/postgres-data.tar.gz -C /data
      volumes:
        - name: postgres-volume
          persistentVolumeClaim:
            claimName: postgres-docker-pvc
```

### 1.3 Clarify Your Configuration

You need to modify the corresponding resources under `dependencies.postgres` to bind the PVC and correctly set the corresponding account credentials. An example is as follows:

```yaml
dependencies:
  postgres:
    username: "swanlab"
    password: "1uuYNzZa4p"
    persistence:
      existingClaim: "postgres-docker-pvc"
```

> `self-hosted` itself will create Secret resources based on `username` and `password` and will not store them in plain text.

## 2\. Migrating Redis

In the SwanLab Docker version, the Redis connection string is the default connection string `redis://default@redis:6379`.

### 2.1 Packaging and Uploading the Archive

Use the following command to package redis data:

```bash
tar -czvf redis-data.tar.gz -C data/redis/ .
```

Then upload it to object storage or any network storage service accessible by the cluster. In this example, we upload to Aliyun Object Storage. The file link example is:

```
https://xxx.oss-cn-beijing.aliyuncs.com/self-hosted/docker/redis-data.tar.gz
```

### 2.2 Copying Data to Storage Volume

Reference configuration is as follows:

```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: redis-migrate
  labels:
    swanlab: redis
spec:
  template:
    spec:
      restartPolicy: OnFailure
      containers:
        - name: redis-migrate
          image: busybox:1.37.0
          imagePullPolicy: IfNotPresent
          volumeMounts:
            - name: redis-volume
              mountPath: /data
          env:
            - name: FILE_URL
              value: "https://xxx.oss-cn-beijing.aliyuncs.com/self-hosted/docker/redis-data.tar.gz"
          command:
            - /bin/sh
            - -c
            - |
              wget $FILE_URL -O /tmp/redis-data.tar.gz
              tar -xzvf /tmp/redis-data.tar.gz -C /data
      volumes:
        - name: redis-volume
          persistentVolumeClaim:
            claimName: redis-docker-pvc
```

Pay attention to the PVC name, and run it after confirming it is correct.

### 2.3 Clarify Your Configuration

You need to modify the corresponding resources under `dependencies.redis` to bind the PVC and correctly set the corresponding account credentials. An example is as follows:

```yaml
dependencies:
  redis:
    persistence:
      existingClaim: "redis-docker-pvc"
```

## 3\. Migrating Clickhouse

### 3.1 Packaging and Uploading the Archive

  - Connection string: `tcp://swanlab:2jwnZiojEV@clickhouse-docker:9000/app`
  - HTTP port: `8123`

Use the following command to package clickhouse data:

```bash
tar -czvf clickhouse-data.tar.gz -C data/clickhouse/ .
```

Then upload it to object storage or any network storage service accessible by the cluster. In this example, we upload to Aliyun Object Storage. The uploaded file link example is:

```
https://xxxx.oss-cn-beijing.aliyuncs.com/self-hosted/docker/clickhouse-data.tar.gz
```

### 3.2 Copying Data to Storage Volume

Reference configuration is as follows:

```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: clickhouse-migrate
  labels:
    swanlab: clickhouse
spec:
  template:
    spec:
      restartPolicy: OnFailure
      containers:
        - name: clickhouse-migrate
          image: busybox:latest
          imagePullPolicy: IfNotPresent
          volumeMounts:
            - name: clickhouse-volume
              mountPath: /data
          env:
            - name: FILE_URL
              value: "https://xxx.oss-cn-beijing.aliyuncs.com/self-hosted/docker/clickhouse-data.tar.gz"
          command:
            - /bin/sh
            - -c
            - |
              wget $FILE_URL -O /tmp/clickhouse-data.tar.gz
              tar -xzvf /tmp/clickhouse-data.tar.gz -C /data
      volumes:
        - name: clickhouse-volume
          persistentVolumeClaim:
            claimName: clickhouse-docker-pvc
```

### 3.3 Clarify Your Configuration

You need to modify the corresponding resources under `dependencies.clickhouse` to bind the PVC and correctly set the corresponding account credentials. An example is as follows:

```yaml
dependencies:
  clickhouse:
    username: "swanlab"
    password: "2jwnZiojEV"
    persistence:
      existingClaim: "clickhouse-docker-pvc"
```

> `self-hosted` itself will create Secret resources based on `username` and `password` and will not store them in plain text.

## 4\. Migrating Minio

  - accessKey: `swanlab`
  - accessSecret: `qtllV4B9KZ`

### 4.1 Packaging and Uploading the Archive

Use the following command to package minio data:

```bash
tar -czvf minio-data.tar.gz -C data/minio/ .
```

Then upload it to object storage or any network storage service accessible by the cluster. In this example, we upload to Aliyun Object Storage. The uploaded file link example is:

```
https://xxx.oss-cn-beijing.aliyuncs.com/self-hosted/docker/minio-data.tar.gz
```

### 4.2 Copying Data to Storage Volume

Reference configuration is as follows:

```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: minio-migrate
  labels:
    swanlab: minio
spec:
  template:
    spec:
      restartPolicy: OnFailure
      containers:
        - name: minio-migrate
          image: busybox:latest
          imagePullPolicy: IfNotPresent
          volumeMounts:
            - name: minio-volume
              mountPath: /data
          env:
            - name: FILE_URL
              value: "https://xxx.oss-cn-beijing.aliyuncs.com/self-hosted/docker/minio-data.tar.gz"
          command:
            - /bin/sh
            - -c
            - |
              wget $FILE_URL -O /tmp/minio-data.tar.gz
              tar -xzvf /tmp/minio-data.tar.gz -C /data
      volumes:
        - name: minio-volume
          persistentVolumeClaim:
            claimName: minio-docker-pvc
```

### 4.3 Clarify Your Configuration

You need to modify the corresponding resources under `dependencies.minio` to bind the PVC and correctly set the corresponding account credentials. An example is as follows:

```yaml
dependencies:
  s3:
    accessKey: "swanlab"
    secretKey: "qtllV4B9KZ"
    persistence:
      existingClaim: "minio-docker-pvc"
```

## 5\. Service Deployment

Once you have completed the above 4 steps, you can start deploying the SwanLab Kubernetes service.

> For basic operations on deploying Kubernetes services, see: [Using Kubernetes for Deployment](/en/guide_cloud/self_host/kubernetes-deploy.md).

You just need to modify the `dependencies` section based on the original [values.yaml](https://github.com/SwanHubX/charts/blob/main/charts/self-hosted/values.yaml).

Reference values are as follows (please ensure your keys are correct):

```yaml
dependencies:
  postgres:
    username: "swanlab"
    password: "1uuYNzZa4p"
    persistence:
      existingClaim: "postgres-docker-pvc"
  redis:
    persistence:
      existingClaim: "redis-docker-pvc"
  clickhouse:
    username: "swanlab"
    password: "2jwnZiojEV"
    persistence:
      existingClaim: "clickhouse-docker-pvc"
  s3:
    accessKey: "swanlab"
    secretKey: "qtllV4B9KZ"
    persistence:
      existingClaim: "minio-docker-pvc"
```

After completing the modifications, execute the following command to deploy the SwanLab Kubernetes service:

```bash
helm install swanlab-self-hosted swanlab/self-hosted -f values.yaml
```

> After deployment, if you have already logged into **Swanlab Docker Version** on your browser, and the domain name remains consistent before and after migration, you do not need to log in again.

For more detailed operations on Kubernetes deployment, please refer to: [Using Kubernetes for Deployment](/en/guide_cloud/self_host/kubernetes-deploy.md).