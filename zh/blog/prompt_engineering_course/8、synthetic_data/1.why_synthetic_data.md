## 为什么需要合成数据？

在了解为什么需要合成数据前，我们先简单了解下何为“合成数据”。

合成数据（Synthetic Data）是指用算法、生成模型或仿真程序“造”出来的数据，它模仿真实世界数据的统计分布和结构，但并不直接来源于真实观测，在此教程里，合成数据是由大模型根据不同的提示词生成的数据。

为什么需要合成数据，其实核心的核心是数据的`质量问题`，我们知道，对于大模型来说，优秀的大模型往往需要经过预训练、后训练，后训练包含微调、强化训练等，关于每个阶段训练使用的数据，其`数据质量`对于每个阶段来说有些微的不同，不过每个阶段的共同点是都需要数据的`丰富度`。

下面我们针对每个阶段的合成数据进行细致的分析，讨论为什么需要合成数据。


### 预训练阶段的合成数据

我们知道，早期的大模型（204年前），大模型的性能提升着重于预训练阶段，早期提到的[Scaling Law法则](https://arxiv.org/pdf/2001.08361/1000)中，我们得知，模型规模、数据规模和模型性能之间呈现幂律增长的趋势，当模型参数量和训练数据规模同时增长的时候，模型性能有稳定的提升。下图展示了Scaling Law的图表原理[1]：

<img src="./picture/scaling_law.png" alt="ScalingLaw原理图" style="zoom:80%;" />

因此在当时的学者看来，训练数据越多，模型就能越大，模型表现就能越好，这不难理解，就跟人类18岁以前的学习一样，15-18岁必然比12岁左右懂得知识多，理解也会更深刻。

在大模型发展的早期，OpenAI的GPT系列模型可谓是AI领域的领头羊，其中GPT-3，后面经过后训练得到的GPT-3.5不仅拥有超大规模的参数量（175B，当然现在的模型参数量甚至有1TB，但在当时已经是模型规模的极限），而且在零样本/少样本领域能力突出，拥有2k多tokens窗口的上下文理解能力，在各个领域的应用都非常显著。而能拥有如此强大的通用性能力，和预训练阶段庞大的数据规模密不可分，在GPT-3的论文里[Language Models are Few-Shot Learners](https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf)，作者给出GPT-3的训练数据分布[2]：

<img src="./picture/gpt3_training_data.png" alt="GPT-3的训练数据分布" style="zoom:80%;" />

根据Scaling Law法则得知，这个规模的数据对应的模型规模175B已经是模型性能提升的极限，而在[洪永淼、汪寿阳：ChatGPT 与大模型将对经济学研究范式产生什么影响?](https://mp.weixin.qq.com/s?__biz=MzI0NzY3MzkzNw==&mid=2247485830&idx=1&sn=5a4111e768b12233909d1af0b096a1f4#:~:text=ChatGPT的第一个版本GPT-1，其参数数量为1.17亿，这是非常庞大的数量。在GPT-2版本中，模型参数数量从1.17亿上升到15亿，训练数据也增加了。在GPT-3版本中，参数数量达到1750亿个，并使用大约2%2F3互联网数据、整个维基百科以及2个大型图书馆数据进行训练。)一文中指出，GPT-3的预训练模型使用大约2/3互联网数据、整个维基百科以及2个大型图书馆数据进行训练，由于数据需要经过去重、清洗，事实上，GPT-3预训练使用的互联网数据规模基本是能获取的数据规模极限，因此模型规模也没有再有提升的空间。

但是我们知道对于科学的探索是无止境的，在数据和模型规模都到达瓶颈的情况下，如何提升模型性能呢？

[Textbooks Are All You Need](https://arxiv.org/pdf/2306.11644)这篇论文思考在预训练阶段如果对数据质量提升，能否提升模型性能。

作者给出的答案是肯定的，并且开创性的在论文中提出，预训练阶段“教科书”级数据能够给模型带来非常不错的提升，并且认为后面的大模型的发展取决于合成数据，当然从现在看来，这并不是模型发展的未来，在2025年的今天，模型发展到了后训练阶段。不过即便如此，在当今社会，合成数据仍然是各个AI行业不可或缺的一环。

我们接着回到论文的讨论，作者认为，在预训练阶段，数据集的质量集中在`多样性`、`去除噪声`以及`教科书`。

`1、多样性`：

这一点其实很好理解，所有的大模型在预训练阶段既要保证数据主题的广泛性，要涵盖尽可能多的知识点，也要保证数据不会有明显的重复。

重复数据对于模型训练来说基本是毁灭性的打击，如果数据中存在大量重复内容（例如同一篇文章被多次收录），模型会优先 “记住” 这些重复信息，而非学习背后的通用模式，泛化能力降低，同时会人为放大某类信息的占比，导致模型误以为这类信息更重要或更常见。

`2、去除噪声`：

我们知道训练大规模语言模型，预训练数据大多来源于互联网数据，在互联网中存在大量会干扰模型学习有效规律、导致模型学到错误模式或者降低泛化能力的内容，比如网页中存在的各种营销类文本、HTML 标签（如<div><p>）、表格乱码，同时可能存在大量无意义内容，比如很多的随机字符如 （“qwertyuiop”）、重复堆砌的短句（如 “加油加油加油……”）、空白或乱码（如 “�￥%”）。

在常见任务示例中，我们使用Qwen2.5-base模型有可能会出现大量无意义重复表情包，这很有可能是预训练数据集中存在的噪声未被及时清理并且训练过拟合。因此去除噪声是保证数据质量的又一关键要素。

不过需要注意的是，高质量的判定并不包含Toxic信息，也就是有毒内容，因为即便是涉及安全类信息，只要不是重复性高、多样化程度低的数据其实都算高质量数据，而有毒内容的剔除往往是后训练阶段处理。

`3、教科书数据`：

其实我认为这一概念的提出和当时学者对于大模型的定位有关，在攻克了自然语言处理任务后，大模型充当问答辅助工具或者对话工具，而如果跟现实联系起来，大模型就很像是经验丰富的“老师”，那要想成为这样的老师，学习“教科书”数据显然能够大幅度提升模型的能力，但是这类数据在网络上其实并不多，大多数还是类似于科普类专业数据。即便将所有的“教科书”数据提取出来并数据清洗去重，得到的结果其实也有偏向，比如数学类比较多，文学类比较少，这样训练出来的模型很有可能发生过拟合的现象。

基于此，Phi论文[3]的作者认为可以用大模型合成“教科书”数据，一来GPT-3拥有广泛的知识储备和问答能力，合成的数据自然在`多样性`上不会有问题，并且合成的`噪声`也不会很多；其次因为强大的零样本/少样本学习能力，模型能够很好的理解提示词并生成高质量的回答，只要设定好对应的`受众群体`，比如对于面向年幼儿童的教科书，内容需要使用非常简单、日常的语言和短句，以便10岁左右的孩子能够轻松理解；对于面向专业人士和研究人员的教科书，内容则需要深入探讨主题，包括对最新研究成果和领域内辩论的批判性分析；而对于面向高中生的教科书，内容需要平衡教育的严谨性和可访问性。使用的语言和例子应该能够与青少年学生产生共鸣，同时激发他们对日常生活相关性的好奇心。对于不同的`受众群体`，提示词的构建也会有相应的调整，在[huggingface的博客](https://huggingface.co/blog/zh/cosmopedia)中提到了*少儿、专业人士和研究人员以及高中生生成相同主题的教科书的提示：*[4]

<img src="./picture/huggingface_phi_data.png" alt="少儿、专业人士和研究人员以及高中生生成相同主题的教科书的提示" style="zoom:80%;" />

而面对不同的群体，哪怕是同一个知识点，不同群体之间的关联度其实很低，你将化学元素周期表跟小孩子讲，他们大概率连字都不认识，而对于高中生而言，这只不过是他们日常试题的一部分，因此这样生成的数据，即便背后的知识一致，也不会导致重复性数据，从而训练过拟合，而这样生成的数据，规模是成倍增长的，并且由于大部分知识可以从网络知识中获取，那么“教科书”数据可以确保数据质量和规模。

不过，为了保证模型不会完全在“教课”这一条路上走到黑，Phi的作者将网络数据和教科书数据混合训练模型，成果相当不错，不过模型规模只有3B，因为Scaling Law法则的影响，毕竟数据规模就那么大，模型规模也大不到哪里去。那我们就提出疑问了，既然“教科书”数据这么强，何不把所有的网络数据改造成合成数据？这样数据规模扩大了，那模型规模不也能接着扩大？

答案是不行。事实上预训练阶段模型训练的其实是“常识”，对于网络数据源，其中的专业知识类是必不可少的，如果转换成“教科书”，训练出来的模型就会偏向于各个阶段的教育，这其实也是一种降低泛化能力的行为。那如果将“教科书”数据和大规模网络数据混合呢？

答案也是不行，因为就像是数学类比较多，文学类比较少的这种有明确占比的网络中的教科书数据，如果只是简单的叠加这类数据，事实上是增加“教科书”数据的占比，那么模型训练的结果必然是偏向于这一类的，从而导致通用泛化能力降低。

讲了这么多，其实对于预训练阶段，使用大模型合成数据确实能够提升模型的整体性能，而这类数据需要注意`多样性`、`去除噪声`以及可以适当采用`教科书数据`，这些都是保证预训练阶段数据质量的关键。


---

### 参考资料

[1].[Scaling Laws for Neural Language Models](https://arxiv.org/pdf/2001.08361)


[2].[GPT-1, GPT-2, GPT-3, GPT-3.5, GPT-4论文内容解读](https://blog.csdn.net/BGoodHabit/article/details/130134446?ops_request_misc=%257B%2522request%255Fid%2522%253A%25226ee3a9ef15f6a61581e883f22d069f12%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fblog.%2522%257D&request_id=6ee3a9ef15f6a61581e883f22d069f12&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~blog~first_rank_ecpm_v1~rank_v31_ecpm-1-130134446-null-null.nonecase&utm_term=gpt&spm=1018.2226.3001.4450)

[3].[Textbooks Are All You Need II: phi-1.5 technical report](https://arxiv.org/pdf/2309.05463)

[4].[Cosmopedia: how to create large-scale synthetic data for pre-training](https://huggingface.co/blog/zh/cosmopedia)








