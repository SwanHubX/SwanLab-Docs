# 前言

在学习提示词工程之前，我们提出一个疑问，为什么需要提示词工程？对于这个问题，我们需要从提示词的发展说起。

以 BERT 为代表的预训练模型掀起了一场技术变革，彼时主流的技术范式是 “预训练 - 微调”：研究者们先在大规模通用语料上训练出基础模型，再针对具体任务（如文本分类、情感分析）在小规模标注数据上进行微调，通过调整模型参数来适配特定场景。这种模式虽然在众多任务中取得了优异效果，但也存在明显局限 —— 对标注数据的强依赖使得它在低资源场景中难以施展，且不同任务需要单独微调，模型的通用性受到制约。

提示词能很好的解决这个问题。预训练后的大模型本身是具备零样本回答能力的[1]，在没有举任何例子的情况下只要多一句`Let's think step by step`，模型就能自主思考，无需微调，不过需要注意的是，大模型在高参数量的时候效果会很好，当参数量较少的时候，即便再怎么调整提示词，模型都不一定能完美表达正确的意思，这源于大模型的涌现能力[2]，简单点说，如果一个大模型本身比较“笨”，那你再怎么问、再怎么修改提示词，人家也回答不出来。

而随着大语言模型技术的不断成熟，“预训练 - 提示 - 预测” [3]这一范式逐渐成为主流，这也让提示词的价值被彻底释放。就像我们前面说的，大模型在预训练阶段已经吸收了海量知识，提示词就像是一把钥匙，能把这些知识激活并引导到具体任务中。比如面对一道复杂的数学题，直接问答案可能会出错，但加上 “请分步骤推导” 这样的提示，模型就能顺着逻辑一步步拆解问题，这正是提示词对模型思维的引导作用。

这种无需微调就能解决问题的特性，让提示词在实际应用中变得越来越重要。要知道，不是所有场景都有足够的标注数据来做微调，也不是所有团队都有能力承担微调的成本。这时候，一句精准的提示词就能让大模型在零样本或少样本的情况下完成任务，大大降低了使用门槛。但我们也要清楚，提示词的效果和模型本身的能力紧密相关。只有当模型参数量达到一定规模，涌现出足够强的理解和推理能力时，提示词才能发挥最大作用。要是模型本身 “底子薄”，哪怕提示词设计得再精巧，也很难得到理想的结果。

提示词工程应运而生。它不是简单的文字组合，而是要结合模型特性、任务需求来设计提示策略。怎么让提示词更清晰地传达任务目标？怎么通过提示规避模型的常见错误？怎么在不同模型上调整提示方式以获得最佳效果？这些都是提示词工程要解决的问题。也正因如此，学习提示词工程，其实就是学会如何更好地和大模型 “沟通”，让这一强大的技术工具真正为我们所用，这也是我们深入研究它的意义所在。

<div style="background:#d4edda;color:#000;padding:12px 16px;border-left:4px solid #28a745;">
✅ <strong>我们的所有代码均可在 <a href="https://github.com/828Tina/PromptEngineeringCourse" target="_blank" rel="noopener">GitHub</a> 查看。</strong>
</div>
[1].[Large Language Models are Zero-Shot Reasoners](https://arxiv.org/pdf/2205.11916)

[2].[Emergent Abilities of Large Language Models](https://arxiv.org/pdf/2206.07682)

[3].[Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing](https://dl.acm.org/doi/pdf/10.1145/3560815)