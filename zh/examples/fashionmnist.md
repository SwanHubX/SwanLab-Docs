# FashionMNIST

:::info
å›¾åƒåˆ†ç±»ã€æœºå™¨å­¦ä¹ å…¥é—¨ã€ç°åº¦å›¾åƒ
:::

## æ¦‚è¿°

FashionMNIST æ˜¯ä¸€ä¸ªå¹¿æ³›ç”¨äºæµ‹è¯•æœºå™¨å­¦ä¹ ç®—æ³•çš„å›¾åƒæ•°æ®é›†ï¼Œç‰¹åˆ«æ˜¯åœ¨å›¾åƒè¯†åˆ«é¢†åŸŸã€‚å®ƒç”± Zalando å‘å¸ƒï¼Œæ—¨åœ¨æ›¿ä»£ä¼ ç»Ÿçš„ MNIST æ•°æ®é›†ï¼Œåè€…ä¸»è¦åŒ…å«æ‰‹å†™æ•°å­—çš„å›¾ç‰‡ã€‚FashionMNIST çš„è®¾è®¡åˆè¡·æ˜¯æä¾›ä¸€ä¸ªç¨å¾®æ›´å…·æŒ‘æˆ˜æ€§çš„é—®é¢˜ï¼ŒåŒæ—¶ä¿æŒä¸åŸå§‹ MNIST æ•°æ®é›†ç›¸åŒçš„å›¾åƒå¤§å°ï¼ˆ28x28 åƒç´ ï¼‰å’Œç»“æ„ï¼ˆè®­ç»ƒé›†60,000å¼ å›¾ç‰‡ï¼Œæµ‹è¯•é›†10,000å¼ å›¾ç‰‡ï¼‰ã€‚

![fashion-mnist](/assets/example-fashionmnist.png)

FashionMNIST åŒ…å«æ¥è‡ª 10 ä¸ªç±»åˆ«çš„æœè£…å’Œé‹ç±»å•†å“çš„ç°åº¦å›¾åƒã€‚è¿™äº›ç±»åˆ«åŒ…æ‹¬ï¼š

1. Tæ¤/ä¸Šè¡£ï¼ˆT-shirt/topï¼‰
2. è£¤å­ï¼ˆTrouserï¼‰
3. å¥—å¤´è¡«ï¼ˆPulloverï¼‰
4. è£™å­ï¼ˆDressï¼‰
5. å¤–å¥—ï¼ˆCoatï¼‰
6. å‡‰é‹ï¼ˆSandalï¼‰
7. è¡¬è¡«ï¼ˆShirtï¼‰
8. è¿åŠ¨é‹ï¼ˆSneakerï¼‰
9. åŒ…ï¼ˆBagï¼‰
10. çŸ­é´ï¼ˆAnkle bootï¼‰

æ¯ä¸ªç±»åˆ«éƒ½æœ‰ç›¸åŒæ•°é‡çš„å›¾åƒï¼Œä½¿å¾—è¿™ä¸ªæ•°æ®é›†æˆä¸ºä¸€ä¸ªå¹³è¡¡çš„æ•°æ®é›†ã€‚è¿™äº›å›¾åƒçš„ç®€å•æ€§å’Œæ ‡å‡†åŒ–å°ºå¯¸ä½¿å¾— FashionMNIST æˆä¸ºè®¡ç®—æœºè§†è§‰å’Œæœºå™¨å­¦ä¹ é¢†åŸŸå…¥é—¨çº§çš„ç†æƒ³é€‰æ‹©ã€‚æ•°æ®é›†è¢«å¹¿æ³›ç”¨äºæ•™è‚²å’Œç ”ç©¶ï¼Œç”¨äºæµ‹è¯•å„ç§å›¾åƒè¯†åˆ«æ–¹æ³•çš„æ•ˆæœã€‚

æœ¬æ¡ˆä¾‹ä¸»è¦ï¼š

- ä½¿ç”¨`pytorch`è¿›è¡Œ[ResNet34](https://arxiv.org/abs/1512.03385)(æ®‹å·®ç¥ç»ç½‘ç»œ)ç½‘ç»œçš„æ„å»ºã€æ¨¡å‹è®­ç»ƒä¸è¯„ä¼°
- ä½¿ç”¨`swanlab` è·Ÿè¸ªè¶…å‚æ•°ã€è®°å½•æŒ‡æ ‡å’Œå¯è§†åŒ–ç›‘æ§æ•´ä¸ªè®­ç»ƒå‘¨æœŸ

## ç¯å¢ƒå®‰è£…

æœ¬æ¡ˆä¾‹åŸºäº`Python>=3.8`ï¼Œè¯·åœ¨æ‚¨çš„è®¡ç®—æœºä¸Šå®‰è£…å¥½Pythonã€‚
ç¯å¢ƒä¾èµ–ï¼š
```
torch
torchvision
swanlab
```
å¿«é€Ÿå®‰è£…å‘½ä»¤ï¼š
```bash
pip install torch torchvision swanlab
```

## å®Œæ•´ä»£ç 

```python
import os
import torch
from torch import nn, optim, utils
import torch.nn.functional as F
from torchvision.datasets import FashionMNIST
from torchvision.transforms import ToTensor

import swanlab

# ResNetç½‘ç»œæ„å»º
class Basicblock(nn.Module):
    def __init__(self, in_planes, planes, stride=1):
        super(Basicblock, self).__init__()
        self.conv1 = nn.Sequential(
            nn.Conv2d(in_channels=in_planes, out_channels=planes, kernel_size=3, stride=stride, padding=1, bias=False),
            nn.BatchNorm2d(planes),
            nn.ReLU()
        )
        self.conv2 = nn.Sequential(
            nn.Conv2d(in_channels=planes, out_channels=planes, kernel_size=3, stride=1, padding=1, bias=False),
            nn.BatchNorm2d(planes),
        )

        if stride != 1 or in_planes != planes:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_channels=in_planes, out_channels=planes, kernel_size=3, stride=stride, padding=1),
                nn.BatchNorm2d(planes)
            )
        else:
            self.shortcut = nn.Sequential()

    def forward(self, x):
        out = self.conv1(x)
        out = self.conv2(out)
        out += self.shortcut(x)
        out = F.relu(out)
        return out


class ResNet(nn.Module):
    def __init__(self, block, num_block, num_classes):
        super(ResNet, self).__init__()
        self.in_planes = 16
        self.conv1 = nn.Sequential(
            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(16),
            nn.ReLU()
        )
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)

        self.block1 = self._make_layer(block, 16, num_block[0], stride=1)
        self.block2 = self._make_layer(block, 32, num_block[1], stride=2)
        self.block3 = self._make_layer(block, 64, num_block[2], stride=2)
        # self.block4 = self._make_layer(block, 512, num_block[3], stride=2)

        self.outlayer = nn.Linear(64, num_classes)

    def _make_layer(self, block, planes, num_block, stride):
        layers = []
        for i in range(num_block):
            if i == 0:
                layers.append(block(self.in_planes, planes, stride))
            else:
                layers.append(block(planes, planes, 1))
        self.in_planes = planes
        return nn.Sequential(*layers)

    def forward(self, x):
        x = self.maxpool(self.conv1(x))
        x = self.block1(x)  # [200, 64, 28, 28]
        x = self.block2(x)  # [200, 128, 14, 14]
        x = self.block3(x)  # [200, 256, 7, 7]
        # out = self.block4(out)
        x = F.avg_pool2d(x, 7)  # [200, 256, 1, 1]
        x = x.view(x.size(0), -1)  # [200,256]
        out = self.outlayer(x)
        return out


# æ•è·å¹¶å¯è§†åŒ–å‰20å¼ å›¾åƒ
def log_images(loader, num_images=16):
    images_logged = 0
    logged_images = []
    for images, labels in loader:
        # images: batch of images, labels: batch of labels
        for i in range(images.shape[0]):
            if images_logged < num_images:
                # ä½¿ç”¨swanlab.Imageå°†å›¾åƒè½¬æ¢ä¸ºwandbå¯è§†åŒ–æ ¼å¼
                logged_images.append(swanlab.Image(images[i], caption=f"Label: {labels[i]}", size=(128, 128)))
                images_logged += 1
            else:
                break
        if images_logged >= num_images:
            break
    swanlab.log({"Preview/MNIST": logged_images})


if __name__ == "__main__":
    # è®¾ç½®device
    try:
        use_mps = torch.backends.mps.is_available()
    except AttributeError:
        use_mps = False

    if torch.cuda.is_available():
        device = "cuda"
    elif use_mps:
        device = "mps"
    else:
        device = "cpu"

    # åˆå§‹åŒ–swanlab
    run = swanlab.init(
        project="FashionMNIST",
        experiment_name="Resnet34-Adam",
        config={
            "model": "Resnet34",
            "optim": "Adam",
            "lr": 0.001,
            "batch_size": 32,
            "num_epochs": 10,
            "train_dataset_num": 55000,
            "val_dataset_num": 5000,
            "device": device,
            "num_classes": 10,
        },
    )

    # è®¾ç½®è®­ç»ƒæœºã€éªŒè¯é›†å’Œæµ‹è¯•é›†
    dataset = FashionMNIST(os.getcwd(), train=True, download=True, transform=ToTensor())
    train_dataset, val_dataset = utils.data.random_split(
        dataset, [run.config.train_dataset_num, run.config.val_dataset_num]
    )

    train_loader = utils.data.DataLoader(train_dataset, batch_size=run.config.batch_size, shuffle=True)
    val_loader = utils.data.DataLoader(val_dataset, batch_size=1, shuffle=False)

    # åˆå§‹åŒ–æ¨¡å‹ã€æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    if run.config.model == "Resnet18":
        model = ResNet(Basicblock, [1, 1, 1, 1], 10)
    elif run.config.model == "Resnet34":
        model = ResNet(Basicblock, [2, 3, 5, 2], 10)
    elif run.config.model == "Resnet50":
        model = ResNet(Basicblock, [3, 4, 6, 3], 10)
    elif run.config.model == "Resnet101":
        model = ResNet(Basicblock, [3, 4, 23, 3], 10)
    elif run.config.model == "Resnet152":
        model = ResNet(Basicblock, [3, 8, 36, 3], 10)

    model.to(torch.device(device))

    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=run.config.lr)

    # ï¼ˆå¯é€‰ï¼‰çœ‹ä¸€ä¸‹æ•°æ®é›†çš„å‰16å¼ å›¾åƒ
    log_images(train_loader, 16)

    # å¼€å§‹è®­ç»ƒ
    for epoch in range(1, run.config.num_epochs+1):
        swanlab.log({"train/epoch": epoch}, step=epoch)
        # è®­ç»ƒå¾ªç¯
        for iter, batch in enumerate(train_loader):
            x, y = batch
            x, y = x.to(device), y.to(device)
            optimizer.zero_grad()
            output = model(x)
            loss = criterion(output, y)
            loss.backward()
            optimizer.step()

            if iter % 40 == 0:
                print(
                    f"Epoch [{epoch}/{run.config.num_epochs}], Iteration [{iter + 1}/{len(train_loader)}], Loss: {loss.item()}"
                )
                swanlab.log({"train/loss": loss.item()}, step=(epoch - 1) * len(train_loader) + iter)

        # æ¯4ä¸ªepochéªŒè¯ä¸€æ¬¡
        if epoch % 2 == 0:
            model.eval()
            correct = 0
            total = 0
            with torch.no_grad():
                for batch in val_loader:
                    x, y = batch
                    x, y = x.to(device), y.to(device)
                    output = model(x)
                    _, predicted = torch.max(output, 1)
                    total += y.size(0)
                    correct += (predicted == y).sum().item()

            accuracy = correct / total
            swanlab.log({"val/accuracy": accuracy}, step=epoch)
```

## åˆ‡æ¢å…¶ä»–ResNetæ¨¡å‹

ä¸Šé¢çš„ä»£ç æ”¯æŒåˆ‡æ¢ä»¥ä¸‹ResNetæ¨¡å‹ï¼š
- ResNet18
- ResNet34
- ResNet50
- ResNet101
- ResNet152

åˆ‡æ¢æ–¹å¼éå¸¸ç®€å•ï¼Œåªéœ€è¦å°†`config`çš„`model`å‚æ•°ä¿®æ”¹ä¸ºå¯¹åº”çš„æ¨¡å‹åç§°å³å¯ï¼Œå¦‚åˆ‡æ¢ä¸ºResNet50ï¼š

```python (5)
    # åˆå§‹åŒ–swanlab
    run = swanlab.init(
        ...
        config={
            "model": "Resnet50",
        ...
        },
    )
```

- `config`æ˜¯å¦‚ä½•å‘æŒ¥ä½œç”¨çš„ï¼Ÿ ğŸ‘‰ [è®¾ç½®å®éªŒé…ç½®](/zh/guide_cloud/experiment_track/set-experiment-config)

## æ•ˆæœæ¼”ç¤º

![](/assets/example-fashionmnist-show.jpg)