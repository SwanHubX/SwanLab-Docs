# ä½¿ç”¨Macbookå’ŒMå¾®è°ƒQwen3â€”â€”é€šè¿‡å¾®è°ƒç»™Qwenèµ·ä¸€ä¸ªæ–°åå­—ï¼ˆæ‰‹æŠŠæ‰‹æ•™å­¦ï¼‰

* GitHubä»£ç ï¼š<https://github.com/ShaohonChen/Finetune_Qwen3_on_MacBook>

* æ•°æ®é›†åœ°å€ï¼š<https://modelscope.cn/datasets/swift/self-cognition>

* æ¨¡å‹åœ°å€ï¼š<https://modelscope.cn/models/Qwen/Qwen3-0.6B>

* SwanLabè®­ç»ƒæ—¥å¿—ï¼š<https://swanlab.cn/@ShaohonChen/MLX-FT-Qwen3/charts>

## å†™åœ¨å‰é¢

æœ€è¿‘ç¬”è€…çš„GPUæœåŠ¡å™¨å‡ºäº†ç‚¹æ•…éšœï¼Œå› æ­¤å®éªŒåªèƒ½ä¾é ä¸€å°å°å°çš„MacBookè½»è–„æœ¬ã€‚ç»“æœå‘ç°æ„å¤–çš„èƒ½æ‰“ï¼Œè·‘ä¸€äº›æ·±åº¦å­¦ä¹ æ¨¡å‹æˆ–è€…å¤§æ¨¡å‹å±…ç„¶ä¹Ÿèƒ½æ­£å¸¸è¿è¡Œã€‚çœ‹æ¥ä¹°Macbookä¸å®Œå…¨æ˜¯æ³•å™¨åŒæ ·ä¹Ÿæ˜¯ç”Ÿäº§åŠ›;-)ã€‚

![img](./mlx_lm_finetune/apple-intelligence.png)

æœ¬ç¯‡æ•™ç¨‹å°†å¸¦å¤§å®¶äº†è§£ä¸‹å¦‚ä½•Macbookæ¥è¿›è¡ŒQwen3å¾®è°ƒï¼Œå¹¶ä¸”åˆ©ç”¨è‹¹æœè‡ªå®¶å‘çš„MLXæ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œè®©Macbookçš„æ€§èƒ½å‘æŒ¥åˆ°æè‡´ã€‚

## MLXæ¡†æ¶ç®€ä»‹

![img](./mlx_lm_finetune/mlx.png)

> MLXæ¡†æ¶GitHubåœ°å€ï¼š<https://github.com/ml-explore/mlx>ï¼Œä¸è¿‡è‹¹æœçš„å¼€æºé¡¹ç›®é¦–é¡µæ­£å¦‚å…¶äº§å“ä¸€æ ·ï¼Œç›¸å½“çš„â€œç®€ä»‹â€ã€‚æ–‡æ¡£å†™çš„è¿˜æ˜¯ä¸é”™çš„ã€‚

MLXæ¡†æ¶æ˜¯è‹¹æœå…¬å¸ä¸“ä¸ºæœºå™¨å­¦ä¹ ä»»åŠ¡è®¾è®¡çš„ä¸€ä¸ªé«˜æ•ˆã€çµæ´»çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œä¸»è¦é¢å‘Apple Siliconè¿›è¡Œä¼˜åŒ–ã€‚MLXå…è®¸å¼€å‘è€…åœ¨macOSå’ŒiOSè®¾å¤‡ä¸Šæ„å»ºã€è®­ç»ƒå’Œéƒ¨ç½²æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œå……åˆ†åˆ©ç”¨è‹¹æœç¡¬ä»¶çš„ç»Ÿä¸€å†…å­˜æ¶æ„ï¼Œå®ç°CPUä¸GPUä¹‹é—´çš„é›¶æ‹·è´æ•°æ®å…±äº«ï¼Œä»è€Œæå‡è®­ç»ƒå’Œæ¨ç†æ•ˆç‡ã€‚

ç¬”è€…ä¸ªäººæ„Ÿè§‰MLXç›¸æ¯”äºä½¿ç”¨torchçš„MPSåç«¯ï¼Œæ›´èƒ½å‘æŒ¥AppleèŠ¯ç‰‡çš„æ€§èƒ½ã€‚ä¸Šæ¬¡ç¬”è€…ä½¿ç”¨mpsåç«¯è®­ç»ƒrnnç½‘ç»œæ—¶è¿˜å‡ºç°äº†ç‰™è†å€’å¸ã€GPUæ‰“ä¸è¿‡CPUçš„æƒ…å†µã€‚ä¸è¿‡RNNæ¨¡å‹æœ¬èº«æ¯”è¾ƒå°ï¼Œä¸”ç»“æ„ä¹Ÿé€‚åˆäºå¹¶è¡Œè®¡ç®—ï¼Œå…·ä½“æ•ˆç‡ç­‰æœªæ¥ç¬”è€…ä¸“é—¨æµ‹è¯•ä¸‹ã€‚MLXæ¡†æ¶çš„APIæ•´ä½“ä¹Ÿéå¸¸åƒnumpyå’Œtorchï¼Œè¿ç§»å­¦ä¹ èµ·æ¥çš„é—¨æ§›ä¸é«˜ã€‚

å½“ç„¶ï¼Œç”±äºç°åœ¨å¼€æºLLMæ¨¡å‹ä¸€èˆ¬ä½¿ç”¨ğŸ¤—Huggingface Transformersæ¡†æ¶å¼€æºï¼ŒåŸºæœ¬éƒ½æ˜¯åŸºäºpytorchæ¡†æ¶ï¼Œå› æ­¤æƒ³ç›´æ¥ä½“éªŒåˆ°MLXå¸¦æ¥çš„æ€§èƒ½æå‡è¿˜æ˜¯å¾ˆéš¾çš„ã€‚å¥½åœ¨è‹¹æœåŒæ—¶å‘å¸ƒäº†ä¸€ä¸ªMLX-LMæ¡†æ¶ï¼ŒåŠŸèƒ½å®šä½ä¸Šç±»ä¼¼Transformers + vllmï¼Œèƒ½è®­ç»ƒä¹Ÿèƒ½æ¨ç†ã€‚å› æ­¤æœ¬ç¯‡æ•™ç¨‹å°±åŸºäºMLX-LMæ•™ç¨‹ç»™å¤§å®¶ä»‹ç»ä¸‹å¦‚ä½•ä½¿ç”¨Macbookå¾®è°ƒQwen3æ¨¡å‹ï¼

> MLX-LMå·²ç»æ”¯æŒä½¿ç”¨SwanLabè¿›è¡Œè®­ç»ƒè·Ÿè¸ªäº†ï¼

![img](./mlx_lm_finetune/mlx-swanlab.png)

## ä½¿ç”¨MLX-LMè®­ç»ƒQwen3æ¨¡å‹

### ç¯å¢ƒå®‰è£…

å®‰è£…MLXæ¡†æ¶éå¸¸æ–¹ä¾¿ï¼Œåªéœ€è¦ä¸€è¡Œå‘½ä»¤å³å¯ï¼Œç”±äºè¦ç”¨SwanLabåšå¾®è°ƒè·Ÿè¸ªï¼Œä¹Ÿé¢å¤–å®‰è£…SwanLabåŒ…ã€‚

```bash
pip install mlx-lm swanlab
```

### æ•°æ®é›†&æ¨¡å‹å‡†å¤‡

**æ•°æ®é›†å‡†å¤‡**

æœ¬ä»»åŠ¡é€šè¿‡å¯¹Qwen3å¾®è°ƒï¼Œè®©Qwen3å­¦ä¹ ä¸€ä¸ªæ–°çš„åå­—ï¼è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ç¬”è€…éå¸¸å–œæ¬¢çš„ä¸€ä¸ªæ•°æ®é›†â€”â€”MS-Swiftå›¢é˜Ÿå‘å¸ƒçš„â€œself-cognitionâ€æ•°æ®é›†ã€‚

![img](./mlx_lm_finetune/dataset.png)

> æ•°æ®é›†é“¾æ¥ï¼š<https://modelscope.cn/datasets/swift/self-cognition>

self-cognitionæ•°æ®é›†ä¸»è¦ç”¨äºåšæ¨¡å‹è‡ªæˆ‘è®¤çŸ¥å¾®è°ƒï¼Œæ•°æ®é›†ç”±108æ¡èº«ä»½é—®ç­”æ•°æ®ç»„æˆï¼ŒåŒ…æ‹¬ä¸­æ–‡å’Œè‹±æ–‡ã€‚æ•°æ®é›†é¢„ç•™äº†â€œæ¨¡å‹åç§°â€å’Œâ€œæ¨¡å‹ä½œè€…åç§°â€ä¸¤ä¸ªé¢„ç•™å­—æ®µã€‚æˆ‘ä»¬å¯ä»¥å°†å…¶æ›¿æ¢æˆå¸Œæœ›ç»™æ¨¡å‹èµ·çš„åç§°å’Œè‡ªå·±çš„åç§°ã€‚

ä½¿ç”¨å¦‚ä¸‹å‘½ä»¤ä¸‹è½½æ•°æ®é›†åˆ°æœ¬åœ°ï¼š

```bash
pip install modelscope
modelscope download --dataset swift/self-cognition --local_dir ./self-cognition
```

ç”±äºMLX-LMæ¡†æ¶çš„æ•°æ®æ ¼å¼è¿˜æœ‰ç‚¹å°åŒºåˆ«ï¼Œå†æ¥ä¹Ÿè¦æ›¿æ¢æ•°æ®é›†ä¸­çš„åç§°ï¼Œå¯ä»¥ä½¿ç”¨ç¬”è€…å®ç°çš„æ•°æ®è½¬æ¢è„šæœ¬è¿›è¡Œæ ¼å¼è½¬æ¢ï¼Œæ•°æ®è„šæœ¬å‘½åä¸º`trans_data.py`ï¼š

```bash
import os
import json
import argparse

def main(name="å°é¹…", author="SwanLabå›¢é˜Ÿ"):
    mlx_data = []

    with open("self-cognition/self_cognition.jsonl", "r") as fread:
        data_list = fread.readlines()

        for data in data_list:
            data = json.loads(data)
            user_text = data["query"]
            if data["tag"] == "zh":
                assistant_text = (
                    data["response"]
                    .replace("{{NAME}}", "åƒä»”")
                    .replace("{{AUTHOR}}", "åƒé—®ç²‰ä¸")
                )
            else:
                assistant_text = (
                    data["response"]
                    .replace("{{NAME}}", "Little-Q")
                    .replace("{{AUTHOR}}", "QFans")
                )
            mlx_data.append(
                {
                    "messages": [
                        {"role": "user", "content": user_text},
                        {"role": "assistant", "content": assistant_text},
                    ]
                }
            )

    # splite data
    val_data_num = len(mlx_data) // 5
    mlx_train_data = mlx_data[val_data_num:]
    mlx_val_data = mlx_data[:val_data_num]

    # write data
    os.makedirs("./mlx_data/", exist_ok=True)

    with open("./mlx_data/train.jsonl", "w", encoding="utf-8") as fwrite:
        for data in mlx_train_data:
            fwrite.write(json.dumps(data, ensure_ascii=False) + "\n")

    with open("./mlx_data/val.jsonl", "w", encoding="utf-8") as fwrite:
        for data in mlx_val_data:
            fwrite.write(json.dumps(data, ensure_ascii=False) + "\n")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="ä¸€ä¸ªç®€å•çš„è„šæœ¬ï¼Œæ¥å— name å’Œ author å‚æ•°ã€‚"
    )
    parser.add_argument("--name", type=str, required=True, help="æŒ‡å®šæ•°æ®é›†ä¸­æ¨¡å‹åç§°")
    parser.add_argument(
        "--author", type=str, required=True, help="æŒ‡å®šæ•°æ®é›†ä¸­æ¨¡å‹ä½œè€…åç§°"
    )
    args = parser.parse_args()

    main(args.name, args.author)
```

ä½¿ç”¨å¦‚ä¸‹å‘½ä»¤è¿›è¡Œè½¬æ¢ï¼š

```bash
# å¯ä»¥æ›¿æ¢æˆè‡ªå·±æœŸæœ›çš„æ¨¡å‹åå’Œä½œè€…å
python trans_data.py --name å°é¹… --author SwanLabå›¢é˜Ÿ --en_name little-swan --en_author SwanLab-Team    
```

> ä¹Ÿå¯ä»¥ä½¿ç”¨ç¬”è€…è½¬æ¢å¥½çš„æ•°æ®é›†ï¼šåœ¨<https://github.com/ShaohonChen/Finetune_Qwen3_on_MacBook>

è½¬æ¢åä¼šåœ¨æœ¬åœ°è·¯å¾„ç”Ÿæˆå¦‚ä¸‹ä¸¤ä¸ªæ–‡ä»¶ï¼š

```bash
Finetune_Qwen3_on_MacBook
â”œâ”€â”€ mlx_data
â”‚   â”œâ”€â”€ train.jsonl
â”‚   â””â”€â”€ val.jsonl
...
```

**æ¨¡å‹å‡†å¤‡**

![img](./mlx_lm_finetune/qwen3.png)

è¿™é‡Œç¬”è€…ä¸ºäº†è®¡ç®—æ•ˆç‡é€‰ç”¨Qwen3-0.6Bæ¨¡å‹ï¼Œå®é™…æµ‹è¯•ä¸‹æ¥ç¬”è€…M2 24Gçš„ç¬”è®°æœ¬ç”µè„‘å¯ä»¥è¿è¡ŒQwen3-4Bçš„æ¨¡å‹æ¨ç†ã€‚å¤§å®¶å¯ä»¥æ ¹æ®è‡ªå·±çš„ç”µè„‘å†…å­˜é€‰æ‹©åˆé€‚å¤§å°çš„æ¨¡å‹ã€‚

> âš ï¸æ³¨æ„ï¼šè¦é€‰æ‹©Instructæ¨¡å‹è€Œä¸æ˜¯Baseæ¨¡å‹ï¼

ä¸‹è½½æ¨¡å‹çš„å‘½ä»¤å¦‚ä¸‹ï¼š

```bash
pip install modelscope
modelscope download --model Qwen/Qwen3-0.6B --local_dir ./Qwen3-0.6B
```

### è®­ç»ƒæ¨¡å‹

å‚è€ƒMLX-LMå®˜æ–¹æ–‡æ¡£ï¼š<https://github.com/ml-explore/mlx-lm/blob/main/mlx_lm/LORA.md>

é¦–å…ˆè¦ç¡®ä¿MLX-LMå·²ç»æˆåŠŸå®‰è£…ï¼æˆ‘ä»¬ä½¿ç”¨Loraå¾®è°ƒæ¥å‡å°‘å†…å­˜æ¶ˆè€—ï¼Œåœ¨æœ¬åœ°åˆ›å»º`ft_qwen3_lora.yaml`ï¼ŒæŒ‰ç…§å¦‚ä¸‹è®¾ç½®å¾®è°ƒé…ç½®å‚æ•°ï¼š

```yaml
model: "Qwen3-0.6B" # æœ¬åœ°æ¨¡å‹ç›®å½•æˆ– Hugging Face ä»“åº“çš„è·¯å¾„ã€‚
train: true # æ˜¯å¦è¿›è¡Œè®­ç»ƒï¼ˆå¸ƒå°”å€¼ï¼‰
fine_tune_type: lora  # å¾®è°ƒæ–¹æ³•: "lora", "dora" æˆ– "full"ã€‚
optimizer: adamw # ä¼˜åŒ–å™¨åŠå…¶å¯èƒ½çš„è¾“å…¥
data: "mlx_data" # åŒ…å« {train, valid, test}.jsonl æ–‡ä»¶çš„ç›®å½•
seed: 0 # PRNG éšæœºç§å­
num_layers: 28 # éœ€è¦å¾®è°ƒçš„å±‚æ•°
batch_size: 1 # å°æ‰¹é‡å¤§å°ã€‚
iters: 500  # è®­ç»ƒè¿­ä»£æ¬¡æ•°ã€‚
val_batches: 25 # éªŒè¯æ‰¹æ¬¡æ•°ï¼Œ-1 è¡¨ç¤ºä½¿ç”¨æ•´ä¸ªéªŒè¯é›†ã€‚
learning_rate: 1e-4 # Adam å­¦ä¹ ç‡ã€‚
report_to: swanlab  # ä½¿ç”¨swanlabè®°å½•å®éªŒ
project_name: MLX-FT-Qwen3  # è®°å½•é¡¹ç›®å
steps_per_report: 10  # æ¯éš”å¤šå°‘è®­ç»ƒæ­¥æ•°æŠ¥å‘Šä¸€æ¬¡æŸå¤±ã€‚
steps_per_eval: 200 # æ¯éš”å¤šå°‘è®­ç»ƒæ­¥æ•°è¿›è¡Œä¸€æ¬¡éªŒè¯ã€‚
resume_adapter_file: null # åŠ è½½è·¯å¾„ï¼Œç”¨äºç”¨ç»™å®šçš„ adapter æƒé‡æ¢å¤è®­ç»ƒã€‚
adapter_path: "cog_adapters"  # è®­ç»ƒå adapter æƒé‡çš„ä¿å­˜/åŠ è½½è·¯å¾„ã€‚
save_every: 100 # æ¯ N æ¬¡è¿­ä»£ä¿å­˜ä¸€æ¬¡æ¨¡å‹ã€‚
test: true # è®­ç»ƒåæ˜¯å¦åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°
test_batches: 100 # æµ‹è¯•é›†æ‰¹æ¬¡æ•°ï¼Œ-1 è¡¨ç¤ºä½¿ç”¨æ•´ä¸ªæµ‹è¯•é›†ã€‚
max_seq_length: 512 # æœ€å¤§åºåˆ—é•¿åº¦ã€‚
grad_checkpoint: false  # æ˜¯å¦ä½¿ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ä»¥å‡å°‘å†…å­˜ä½¿ç”¨ã€‚
lora_parameters:  # LoRA å‚æ•°åªèƒ½åœ¨é…ç½®æ–‡ä»¶ä¸­æŒ‡å®š
  keys: ["self_attn.q_proj", "self_attn.v_proj"]
  rank: 8
  scale: 20.0
  dropout: 0.0
```

æ¥ä¸‹æ¥åœ¨å‘½ä»¤è¡Œå¯åŠ¨MLX-LMå¾®è°ƒï¼š

```bash
mlx_lm.lora --config ft_qwen3_lora.yaml
```

å¯åŠ¨æˆåŠŸåæ•ˆæœå¦‚ä¸‹

![img](./mlx_lm_finetune/train.png)

å¦‚æœå¼€å¯äº†SwanLabè·Ÿè¸ªï¼Œåˆ™ä¼šè‡ªåŠ¨è®°å½•è®­ç»ƒæŸå¤±å›¾åƒã€‚å¯ä»¥çœ‹åˆ°å¤§æ¦‚500æ­¥æ¨¡å‹è®­ç»ƒæŸå¤±å°±æ”¶æ•›äº†

![img](./mlx_lm_finetune/log.png)

å®éªŒè®°å½•å·²å…¬å¼€ï¼š<https://swanlab.cn/@ShaohonChen/MLX-FT-Qwen3/charts>

è®­ç»ƒé€Ÿåº¦éå¸¸å¿«ï¼Œåœ¨ç¬”è€…çš„è½»è–„æœ¬ä¸Šä¸åˆ°2åˆ†é’Ÿå°±å®Œæˆäº†è®­ç»ƒï¼Œä½¿ç”¨äº†ä¸åˆ°2Gå†…å­˜ï¼Œååå¿«400Token/Sã€‚

![img](./mlx_lm_finetune/runtime.png)

### è¯„ä¼°æ¨¡å‹æ•ˆæœ

mlx-lmæ”¯æŒç›´æ¥ç”¨chatæ¨¡å¼è¯„ä¼°æ¨¡å‹è®­ç»ƒæ•ˆæœï¼Œå‘½ä»¤å¦‚ä¸‹

```bash
mlx_lm.chat --model Qwen3-0.6B --adapter-path cog_adapters
```

å¯ä»¥ç›´æ¥åœ¨å‘½ä»¤è¡Œé‡Œä¸æ¨¡å‹èŠå¤©ï¼Œå¯ä»¥çœ‹åˆ°æ¨¡å‹å·²ç»å­¦ä¼šäº†ä»–çš„æ–°åå­—â€œå°é¹…â€ã€‚

![img](./mlx_lm_finetune/chat.png)

è‹±æ–‡èŠå¤©ä¹Ÿä¸åœ¨è¯ä¸‹ï¼

![img](./mlx_lm_finetune/eng_chat.png)

## éƒ¨ç½²QwenèŠå¤©æœåŠ¡

mlx-lmæ¡†æ¶ä¹Ÿæ”¯æŒä¸€è¡Œå‘½ä»¤éƒ¨ç½²æˆAPIæœåŠ¡ï¼å¯¹äºæ´—æ•°æ®æˆ–è€…ä½œä¸ºè‡ªç”¨çš„AIåŠ©æ‰‹æ¥è¯´éå¸¸å‹å¥½ï¼Œç°åœ¨æˆ‘ä»¬ä½¿ç”¨å‘½ä»¤æŠŠåˆšåˆšå¾®è°ƒå¥½çš„æ¨¡å‹éƒ¨ç½²æˆAPIæœåŠ¡ï¼š

```bash
mlx_lm.server --model Qwen3-0.6B --adapter-path cog_adapters --chat-template-args '{"enable_thinking":false}'
```

> `--chat-template-args '{"enable_thinking":false}'` ç”¨äºå…³é—­Qwen3çš„æ¨ç†æ¨¡å¼ï¼Œå¦‚æœä½ æ›´å–œæ¬¢æ¨ç†ä¹Ÿå¯ä»¥åˆ æ‰è¿™ä¸€è¡Œæ¥å¼€å¯æ·±åº¦æ€è€ƒã€‚

è¿è¡ŒæˆåŠŸåä¼šæ˜¾ç¤ºï¼š

```bash
2025-09-18 15:51:42,639 - INFO - Starting httpd at 127.0.0.1 on port 8080...
```

å¯ä»¥ä½¿ç”¨å¦‚ä¸‹å‘½ä»¤æµ‹è¯•æ˜¯å¦æˆåŠŸï¼š

```bash
curl localhost:8080/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
     "messages": [{"role": "user", "content": "Say this is a test!"}],
     "temperature": 0.7
   }'
```

çœ‹åˆ°æ¨¡å‹æ­£å¸¸è¿”å›åï¼Œè¯´æ˜APIéƒ¨ç½²æˆåŠŸï¼š

```bash
{"id": "chatcmpl-bdfd6f0c-72db-418e-a35a-ecf13cd98ee0", "system_fingerprint": "0.28.0-0.29.1-macOS-15.6.1-arm64-arm-64bit-applegpu_g14g", "object": "chat.completion", "model": "default_model", "created": 1758181778, "choices": [{"index": 0, "finish_reason": "stop", "logprobs": {"token_logprobs": [-1.125, -0.875, -1.5, 0.0, -0.125, 0.0, -0.375, -2.75, -0.25, -0.375, 0.0, 0.0, -0.125, 0.0, -0.5, 0.0, -0.625, 0.0, 0.0, 0.0, -1.25, 0.0], "top_logprobs": [], "tokens": [9707, 11, 419, 374, 264, 1273, 0, 1416, 498, 614, 894, 4755, 476, 1184, 1492, 11, 2666, 1910, 311, 2548, 0, 151645]}, "message": {"role": "assistant", "content": "Hello, this is a test! If you have any questions or need help, feel free to ask!", "tool_calls": []}}], "usage": {"prompt_tokens": 18, "completion_tokens": 22, "total_tokens": 40}}% 
```

**éƒ¨ç½²æ€§èƒ½æµ‹è¯•**

ç¬”è€…ä½¿ç”¨evalscopeè¿›è¡Œé€Ÿåº¦æµ‹è¯•ï¼Œå‘½ä»¤å¦‚ä¸‹ï¼š

> âš ï¸æ³¨æ„éœ€è¦å¼€å¯APIæœåŠ¡ï¼Œå¦åˆ™ä¼šè¿è¡Œå¤±è´¥

```bash
evalscope perf \
  --parallel 1 10 50 \
  --number 10 20 100 \
  --model Qwen3-0.6B \
  --url http://127.0.0.1:8080/v1/chat/completions \
  --api openai \
  --dataset random \
  --max-tokens 128 \
  --min-tokens 128 \
  --prefix-length 0 \
  --min-prompt-length 128 \
  --max-prompt-length 128 \
  --tokenizer-path Qwen3-0.6B \
  --extra-args '{"ignore_eos": true}' \
  --swanlab-api-key ttsGKza0SNOiPFCfQWspm \
  --name 'qwen3-inference-stress-test'
```

å¯ä»¥çœ‹åˆ°å•è¯·æ±‚èƒ½è¾¾åˆ°å¹³å‡10toks/sçš„é€Ÿåº¦ã€‚è¿˜æ˜¯å¾ˆå¿«çš„ï¼Œä¸è¿‡å¹¶å‘é€Ÿåº¦å°±ä¸‹æ¥äº†ã€‚

![img](./mlx_lm_finetune/infer_test.png)

ä½¿ç”¨SwanLabè¿›è¡Œæ€§èƒ½è·Ÿè¸ªå¯ä»¥çœ‹åˆ°ï¼Œéšç€å¹¶å‘æ•°ä»10->20->50ï¼Œéƒ¨ç½²æ€§èƒ½å¿«é€Ÿä¸‹é™ã€‚ä¸è¿‡è¿™ä¹Ÿæ˜¯ç”±äºç¬”è€…æœ¬èº«åœ¨æµ‹è¯•æ—¶ä¹Ÿåœ¨ä½¿ç”¨è¿™å°ç¬”è®°æœ¬ç”µè„‘ï¼Œç³»ç»Ÿå†…å­˜å·²ç»ä½¿ç”¨åˆ°äº†80%çš„åŸå› ã€‚ä»¥è‡ªç”¨æˆ–è€…å°å®éªŒå®¤ä½¿ç”¨æ¥è¯´è¿™ä¸ªé€Ÿåº¦éå¸¸å¯è§‚

> å¯ä»¥åœ¨SwanLabä¸ŠæŸ¥çœ‹è®°å½•ï¼š<https://swanlab.cn/@ShaohonChen/MLX-FT-Qwen3/runs/lqitoakl4gnswhk15xmp3/chart>

![img](./mlx_lm_finetune/infer_lab.png)

![img](./mlx_lm_finetune/infer_system.png)
