# ä¸€æ–‡å¸¦ä½ ç†Ÿæ‚‰loraå¾®è°ƒå„ç±»å‚æ•°ï¼Œè½»æ¾ä¸Šæ‰‹deepseekæ¨¡å‹å¾®è°ƒ(å…¨è¿‡ç¨‹ä»£ç +ç»“æœå¯¹æ¯”)


## ğŸ“ç®€ä»‹

åœ¨å¤§æ¨¡å‹çš„å¾®è°ƒè¿‡ç¨‹ä¸­ï¼Œ`LoRA`ï¼ˆä½ç§©é€‚é…ï¼‰å‚æ•°è®¾ç½®æ˜¯æå‡è®­ç»ƒæ•ˆç‡å’Œæ€§èƒ½çš„å…³é”®ã€‚é€šè¿‡å‡å°‘éœ€æ›´æ–°çš„å‚æ•°é‡ï¼Œ`LoRA`èƒ½å¤Ÿåœ¨ç»´æŒæ¨¡å‹æ€§èƒ½çš„åŒæ—¶æ˜¾è‘—é™ä½è®¡ç®—æˆæœ¬ã€‚ç„¶è€Œï¼Œ`LoRA`å¹¶éå”¯ä¸€å½±å“è®­ç»ƒæ•ˆæœçš„å› ç´ ã€‚è¯¸å¦‚å­¦ä¹ ç‡ã€æ‰¹æ¬¡å¤§å°ä»¥åŠä¼˜åŒ–å™¨ï¼ˆå¦‚AdamWï¼‰ç­‰å‚æ•°åŒæ ·åœ¨å¾®è°ƒè¿‡ç¨‹ä¸­èµ·ç€è‡³å…³é‡è¦çš„ä½œç”¨ã€‚å­¦ä¹ ç‡å†³å®šäº†æ¨¡å‹æ¯æ¬¡æ›´æ–°çš„å¹…åº¦ï¼Œæ‰¹æ¬¡å¤§å°åˆ™å½±å“äº†æ¯æ¬¡è®­ç»ƒä¸­æ ·æœ¬çš„å¤„ç†é‡ï¼Œè€Œä¼˜åŒ–å™¨åˆ™ç¡®ä¿æ¨¡å‹å‚æ•°çš„å¹³ç¨³æ›´æ–°ã€‚
äº†è§£å¹¶çµæ´»è°ƒæ•´è¿™äº›è®­ç»ƒå‚æ•°ï¼Œä¸ä»…èƒ½å¸®åŠ©ä½ åœ¨å¾®è°ƒè¿‡ç¨‹ä¸­å¾—å¿ƒåº”æ‰‹ï¼Œæ›´èƒ½å¿«é€Ÿæå‡è®­ç»ƒæ•ˆæœã€‚æœ¬æ–‡å°†é€šè¿‡ä½¿ç”¨å¤šè½®å¯¹è¯æ•°æ®é›†è¿›è¡Œå¾®è°ƒå®éªŒï¼Œå¸®åŠ©ä½ æ·±å…¥äº†è§£å¾®è°ƒçš„æ ¸å¿ƒåŸç†ï¼Œå¹¶æä¾›ä¸€å¥—å®Œæ•´çš„æ“ä½œæŒ‡å—ã€‚
åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œä½ å°†å­¦ä¹ åˆ°ï¼š

1. å¦‚ä½•è¿›è¡Œ`LoRAå‚æ•°`çš„è®¾ç½®ï¼Œå¹¶æŒæ¡åœ¨ä¸åŒä»»åŠ¡ä¸­çš„åº”ç”¨ã€‚
2. è®­ç»ƒè¿‡ç¨‹ä¸­å¦‚ä½•åˆç†è°ƒæ•´å­¦ä¹ ç‡ã€æ‰¹æ¬¡å¤§å°ç­‰å…³é”®å‚æ•°ï¼Œä»¥ä¼˜åŒ–æ¨¡å‹æ€§èƒ½ã€‚
3. å¤šè½®å¯¹è¯æ•°æ®é›†çš„å¾®è°ƒæ–¹æ³•å’ŒåŸç†ï¼Œä¸ºä½ æä¾›å®è·µçš„åŸºç¡€ã€‚

æœ¬å®éªŒåŸºäºtransformerså’ŒopenMindå‡å·²å®ç°æœ¬æ¬¡å¾®è°ƒï¼Œä»£ç å‡å¯åœ¨githubé“¾æ¥ä¸ŠæŸ¥çœ‹ã€‚

é€šè¿‡æœ¬æ¬¡å®éªŒï¼Œä½ ä¸ä»…èƒ½å¤Ÿå®Œæˆå¤šè½®å¯¹è¯æ•°æ®çš„å¾®è°ƒï¼Œè¿˜èƒ½æŒæ¡è¿™äº›æ–¹æ³•ï¼Œå¹¶å°†å…¶è¿ç§»åˆ°å…¶ä»–å¾®è°ƒå®éªŒä¸­ï¼Œç‹¬ç«‹è¿›è¡Œé«˜æ•ˆçš„æ¨¡å‹è°ƒä¼˜ã€‚

---

## ğŸ“šé“¾æ¥èµ„æ–™

ä½œè€…ä¿¡æ¯ï¼šæƒ…æ„Ÿæœºå™¨å®éªŒå®¤ç ”ç©¶å‘˜-æé¦¨é›¨  é‚®ç®±ï¼š[wind.340171@gmail.com](wind.340171@gmail.com)

æ•°æ®é›†ï¼š[å¿ƒç†å¤§æ¨¡å‹å¾®è°ƒæ•°æ®é›†åœ°å€](https://github.com/SmartFlowAI/EmoLLM/blob/main/datasets/data_pro.json)

æ¨¡å‹åœ°å€ï¼š[deepseek-llm-chat-7B](https://www.modelscope.cn/models/deepseek-ai/deepseek-llm-7b-chat)

ä»£ç åœ°å€ï¼š[github](https://github.com/828Tina/deepseek-llm-7B-chat-lora-ft)

å¯è§†åŒ–å·¥å…·SwanLabé¡¹ç›®åœ°å€ï¼š[SwanLabç»“æœå¯è§†åŒ–](https://swanlab.cn/@LiXinYu/deepseek-llm-7b-chat-finetune/overview)

é­”ä¹ç¤¾åŒºå‹æƒ…é“¾æ¥ï¼š[https://modelers.cn/](https://modelers.cn/)

> é­”ä¹ç¤¾åŒºæ˜¯ä¸€ä¸ªç»¼åˆæ€§çš„äººå·¥æ™ºèƒ½å¹³å°ï¼Œå®ƒæä¾›äº†åº”ç”¨ä½¿èƒ½å¼€å‘å¥—ä»¶ï¼Œæ”¯æŒå„å¤§æ¨¡å‹ç¤¾åŒºï¼Œå…·å¤‡æµ·é‡æ¨¡å‹/æ•°æ®æ‰˜ç®¡èƒ½åŠ›ï¼Œå¹¶æä¾›åœ¨çº¿æ¨ç†ä½“éªŒæœåŠ¡ã€‚è¯¥å¹³å°è¿˜æ”¯æŒæ¥å…¥å†…å®¹å®¡æ ¸ã€ç—…æ¯’æ‰«æç­‰æœåŠ¡ï¼ŒåŠ©åŠ›å¹³å°ä¼™ä¼´å¿«é€Ÿæ„å»ºç¤¾åŒºï¼Œå¹¶å¯¹å¤–æä¾›æ¨¡å‹/æ•°æ®é›†æ‰˜ç®¡å’Œåœ¨çº¿æ¨ç†ä½“éªŒæœåŠ¡ã€‚openMindå¼€å‘å¥—ä»¶æä¾›æ¨¡å‹è®­ç»ƒã€å¾®è°ƒã€è¯„ä¼°ã€æ¨ç†ç­‰å…¨æµç¨‹å¼€å‘èƒ½åŠ›ï¼Œå¼€å‘è€…å¯ä»¥é€šè¿‡ç®€å•çš„APIæ¥å£å®ç°å¾®è°ƒã€æ¨ç†ç­‰ä»»åŠ¡ï¼Œæ˜¾è‘—ç¼©çŸ­å¼€å‘å‘¨æœŸã€‚


![openMind+swanlab](./example/modelspcoe.png)

---
ğŸ‘‰ **SwanLabå®˜æ–¹æ–‡æ¡£ï¼š**

ç”¨æˆ·æŒ‡å—ï¼Œå¯ä»¥å¿«é€Ÿä¸Šæ‰‹<span style="color: #0000FF;">SwanLab</span>ï¼šğŸš€[å¿«é€Ÿå¼€å§‹ | SwanLabå®˜æ–¹æ–‡æ¡£](https://docs.swanlab.cn/guide_cloud/general/quick-start.html)

åº”ç”¨æ¡ˆä¾‹ï¼š[å…¥é—¨å®éªŒ | SwanLabå®˜æ–¹æ–‡æ¡£](https://docs.swanlab.cn/examples/mnist.html)

---

## ğŸ’»å¤šè½®å¯¹è¯æ•°æ®æ„å»º

å¤šè½®å¯¹è¯å¾®è°ƒå…¶å®å’Œå•è½®å¯¹è¯(æˆ–è€…è¯´æŒ‡ä»¤æ•°æ®)å·®ä¸å¤šï¼Œåœ¨æˆ‘çœ‹æ¥å…¶å®ç±»ä¼¼äºå¤šä¸ªæŒ‡ä»¤æ•°æ®çš„ç»„åˆï¼Œå•è½®å¯¹è¯æ•°æ®å¤„ç†çš„æ—¶å€™åªéœ€è¦å¤„ç†è¾“å…¥å’Œè¾“å‡ºå³å¯ï¼Œè®­ç»ƒçš„æ—¶å€™è¾“å…¥ç½®ä¸º-100ï¼Œè¾“å‡ºä¸å˜ï¼Œè€Œå¤šè½®å¯¹è¯å¾®è°ƒæ•°æ®é›†ä»¥åŠæ ‡ç­¾çš„æ„é€ æ–¹æ³•ï¼Œæœ‰ä¸‰ç§å¸¸è§æ–¹æ³•ï¼Œä¸‹é¢å°†è¯¦ç»†ä»‹ç»ã€‚

**è®­ç»ƒä¸å……åˆ†**

ç¬¬ä¸€ç§æ–¹æ³•æ˜¯ï¼ŒåªæŠŠæœ€åä¸€è½®æœºå™¨äººçš„å›å¤ä½œä¸ºè¦å­¦ä¹ çš„æ ‡ç­¾ï¼Œå…¶å®ƒåœ°æ–¹ä½œä¸ºè¯­è¨€æ¨¡å‹æ¦‚ç‡é¢„æµ‹çš„conditionï¼Œæ— éœ€å­¦ä¹ ï¼Œèµ‹å€¼ä¸º-100ï¼Œå¿½ç•¥è¿™äº›åœ°æ–¹çš„lossã€‚

![åªé¢„æµ‹æœ€åå›å¤](./example/multi-data-1.png)

```python
inputs = <user1> <assistant1> <user2> <assistant2> <user3> <assistant3>
labels = <-100> <-100> <-100> <-100> <-100> <assistant3>
```

è¿™ç§æ–¹æ³•ç”±äºæ²¡æœ‰å¯¹ä¸­é—´è½®æ¬¡æœºå™¨äººå›å¤çš„ä¿¡æ¯è¿›è¡Œå­¦ä¹ ï¼Œå› æ­¤å­˜åœ¨ç€ä¸¥é‡çš„ä¿¡æ¯ä¸¢å¤±ï¼Œæ˜¯éå¸¸ä¸å¯å–çš„ã€‚

**è®­ç»ƒä¸é«˜æ•ˆ**

ç¬¬äºŒç§æ–¹æ³•æ˜¯ï¼ŒæŠŠä¸€ä¸ªå¤šè½®å¯¹è¯æ‹†è§£ï¼Œæ„é€ æˆå¤šæ¡æ ·æœ¬ï¼Œä»¥ä¾¿å¯¹æœºå™¨äººçš„æ¯è½®å›å¤éƒ½èƒ½å­¦ä¹ ã€‚

![å¤šæ¬¡é¢„æµ‹](./example/multi-data-2.png)

```python
inputs1 = <user1> <assistant1> 
labels1 = <-100> <assistant1>

inputs2 = <user1> <assistant1> <user2> <assistant2> 
labels2 = <-100> <-100> <-100> <assistant2> 

inputs3 = <user1> <assistant1> <user2> <assistant2> <user3> <assistant3>
labels3 = <-100> <-100> <-100> <-100> <-100> <assistant3>
```

è¿™ç§æ–¹æ³•å……åˆ†åœ°åˆ©ç”¨äº†æ‰€æœ‰æœºå™¨äººçš„å›å¤ä¿¡æ¯ï¼Œä½†æ˜¯éå¸¸ä½æ•ˆï¼Œæ¨¡å‹ä¼šæœ‰å¤§é‡çš„é‡å¤è®¡ç®—ã€‚

**åˆé€‚çš„æ•°æ®ç»„åˆæ–¹å¼**

ç¬¬ä¸‰ç§æ–¹æ³•æ˜¯ï¼Œç›´æ¥æ„é€ åŒ…æ‹¬å¤šè½®å¯¹è¯ä¸­æ‰€æœ‰æœºå™¨äººå›å¤å†…å®¹çš„æ ‡ç­¾ï¼Œå……åˆ†åœ°åˆ©ç”¨äº†æ‰€æœ‰æœºå™¨äººçš„å›å¤ä¿¡æ¯ï¼ŒåŒæ—¶ä¹Ÿä¸å­˜åœ¨æ‹†é‡å¤è®¡ç®—ï¼Œéå¸¸é«˜æ•ˆã€‚ç›®å‰å¤§éƒ¨åˆ†å¾®è°ƒæ¡†æ¶ç”¨çš„éƒ½æ˜¯è¿™ä¸ªç»„åˆæ–¹å¼ã€‚

![åˆ†å¼€é¢„æµ‹](./example/multi-data-3.png)

```python
inputs = <user1> <assistant1> <user2> <assistant2> <user3> <assistant3>
labels = <-100> <assistant1> <-100> <assistant2> <-100> <assistant3>
```

æˆ‘ä»¬ä¸ºä»€ä¹ˆå¯ä»¥ç›´æ¥æ„é€ å¤šè½®å¯¹è¯æ ·æœ¬ï¼Ÿéš¾é“å°†ç¬¬äºŒè½®å’Œç¬¬ä¸‰è½®å¯¹è¯å†…å®¹åŠ å…¥ inputs ä¸­ä¸ä¼šå¹²æ‰°æ¨¡å‹å¯¹ç¬¬ä¸€è½®å¯¹è¯çš„å­¦ä¹ å—ï¼Ÿ

ç­”æ¡ˆæ˜¯ï¼šä¸ä¼šã€‚åŸå› åœ¨äºï¼Œä½œä¸ºä¸€ç§è¯­è¨€æ¨¡å‹ï¼ŒLLMï¼ˆå¤§è¯­è¨€æ¨¡å‹ï¼‰é‡‡ç”¨çš„æ˜¯åŸºäºæ³¨æ„åŠ›æœºåˆ¶çš„ç»“æ„ï¼Œå…¶ä¸­çš„è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼ˆSelf-Attentionï¼‰ åœ¨å¤„ç†è¾“å…¥æ—¶ï¼Œå…·æœ‰å¤©ç„¶çš„å±€éƒ¨æ€§çº¦æŸã€‚å…·ä½“æ¥è¯´ï¼ŒLLM åœ¨å¤„ç†æ¯ä¸€ä¸ªè¾“å…¥æ—¶ï¼Œä½¿ç”¨æ©ç æ³¨æ„åŠ›ï¼ˆMasked Attentionï¼‰æ¥ç¡®ä¿æ¯ä¸ªä½ç½®çš„é¢„æµ‹åªä¾èµ–äºå‰é¢å·²ç»ç”Ÿæˆçš„å†…å®¹ï¼Œè€Œä¸ä¼šæå‰â€œçœ‹åˆ°â€åç»­çš„å¯¹è¯è½®æ¬¡ã€‚

ä¹Ÿå°±æ˜¯è¯´ï¼Œå°½ç®¡è¾“å…¥æ•°æ®ä¸­åŒ…å«äº†å¤šè½®å¯¹è¯çš„ä¿¡æ¯ï¼Œæ¨¡å‹åœ¨è¿›è¡Œæ¯ä¸€è½®å¯¹è¯çš„ç”Ÿæˆæ—¶ï¼Œä»…ä¼šå…³æ³¨å½“å‰å›åˆçš„ä¸Šä¸‹æ–‡ï¼Œè€Œä¸å—åç»­è½®æ¬¡å†…å®¹çš„å½±å“ã€‚è¿™æ ·ï¼Œç¬¬ä¸€è½®çš„å¯¹è¯å†…å®¹ä¸åç»­è½®æ¬¡çš„å¯¹è¯å¹¶ä¸ä¼šç›¸äº’å¹²æ‰°ï¼Œä»è€Œä¿æŒäº†å­¦ä¹ çš„çº¯ç²¹æ€§ã€‚é€šè¿‡è¿™ç§æœºåˆ¶ï¼Œæ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆåœ°åœ¨å¤šè½®å¯¹è¯çš„æ¡†æ¶ä¸‹è¿›è¡Œè®­ç»ƒï¼ŒåŒæ—¶ä¿è¯æ¯è½®å¯¹è¯çš„ç‹¬ç«‹æ€§å’Œå‡†ç¡®æ€§ã€‚

> ç®€è€Œè¨€ä¹‹ï¼ŒLLM èƒ½å¤Ÿé€šè¿‡å…¶æ©ç æœºåˆ¶åœ¨å¤šè½®å¯¹è¯ä¸­è¿›è¡Œâ€œå±€éƒ¨â€å­¦ä¹ ï¼Œæ¯æ¬¡ç”Ÿæˆçš„å†…å®¹éƒ½ä»…ä¸å½“å‰ä¸Šä¸‹æ–‡ç›¸å…³ï¼Œè€Œä¸ä¼šå—åˆ°å…¶ä»–è½®æ¬¡çš„å¹²æ‰°ã€‚

---
## âš™ï¸å„å®éªŒå‚æ•°åŸç†

### ğŸ“Œloraå‚æ•°

LoRAï¼ˆLow-Rank Adaptationï¼‰æ˜¯ä¸€ç§é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹çš„å¾®è°ƒæŠ€æœ¯ï¼Œæ—¨åœ¨é™ä½å¾®è°ƒè¿‡ç¨‹ä¸­çš„è®¡ç®—å’Œå†…å­˜éœ€æ±‚ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡å¼•å…¥ä½ç§©çŸ©é˜µæ¥è¿‘ä¼¼åŸå§‹æ¨¡å‹çš„å…¨ç§©çŸ©é˜µï¼Œä»è€Œå‡å°‘å‚æ•°æ•°é‡å’Œè®¡ç®—å¤æ‚åº¦ã€‚

åœ¨LoRAä¸­ï¼ŒåŸå§‹æ¨¡å‹çš„å…¨ç§©çŸ©é˜µè¢«åˆ†è§£ä¸ºä½ç§©çŸ©é˜µçš„ä¹˜ç§¯ã€‚å…·ä½“æ¥è¯´ï¼Œå¯¹äºä¸€ä¸ªå…¨ç§©çŸ©é˜µWï¼ŒLoRAå°†å…¶åˆ†è§£ä¸ºä¸¤ä¸ªä½ç§©çŸ©é˜µAå’ŒBçš„ä¹˜ç§¯ï¼Œå³W â‰ˆ A * Bã€‚å…¶ä¸­ï¼ŒAå’ŒBçš„ç§©è¿œå°äºWçš„ç§©ï¼Œä»è€Œæ˜¾è‘—å‡å°‘äº†å‚æ•°æ•°é‡ã€‚

<img src="./example/lora.PNG" alt="loraåŸç†å›¾" style="zoom:70%;" />

ä¸Šå›¾ä¸º LoRA çš„å®ç°åŸç†ï¼Œå…¶å®ç°æµç¨‹ä¸ºï¼š
1. åœ¨åŸå§‹é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹æ—è¾¹å¢åŠ ä¸€ä¸ªæ—è·¯ï¼Œåšé™ç»´å†å‡ç»´çš„æ“ä½œæ¥æ¨¡æ‹Ÿå†…åœ¨ç§©ï¼›
2. ç”¨éšæœºé«˜æ–¯åˆ†å¸ƒåˆå§‹åŒ– Aï¼Œç”¨é›¶çŸ©é˜µåˆå§‹åŒ–Bï¼Œè®­ç»ƒæ—¶å›ºå®šé¢„è®­ç»ƒæ¨¡å‹çš„å‚æ•°ï¼Œåªè®­ç»ƒçŸ©é˜µ A ä¸çŸ©é˜µ B ï¼›
3. è®­ç»ƒå®Œæˆåï¼Œå°† B çŸ©é˜µä¸ A çŸ©é˜µç›¸ä¹˜ååˆå¹¶é¢„è®­ç»ƒæ¨¡å‹å‚æ•°ä½œä¸ºå¾®è°ƒåçš„æ¨¡å‹å‚æ•°ã€‚

å…¬å¼è¡¨ç¤ºä¸ºï¼š

![loraå…¬å¼1](./example/lora-gongshi1.png)

å…¶ä¸­ï¼ŒWæ˜¯åŸå§‹çš„æƒé‡çŸ©é˜µï¼ŒAæ˜¯ä¸€ä¸ªå°ºå¯¸ä¸ºd*rçš„çŸ©é˜µï¼ŒBæ˜¯ä¸€ä¸ªå°ºå¯¸ä¸ºr*d'çš„çŸ©é˜µï¼Œræ˜¯ä½ç§©çŸ©é˜µçš„ç§©ã€‚é€šè¿‡è¿™ç§åˆ†è§£ï¼ŒåŸå§‹çŸ©é˜µWçš„æ›´æ–°ä»…ç”±Aå’ŒBçš„ä¹˜ç§¯å†³å®šã€‚è¿›ä¸€æ­¥åœ°ï¼ŒLoRAå¼•å…¥äº†ä¸€ä¸ªç¼©æ”¾å› å­Î±ï¼Œä½¿å¾—æ›´æ–°å…¬å¼ä¸ºï¼š

![loraå…¬å¼2](./example/lora-gongshi2.png)

é‚£ä¹ˆåœ¨å®é™…ä½¿ç”¨çš„æ—¶å€™ï¼Œæˆ‘ä»¬å¦‚ä½•ç¡®å®šloraå‚æ•°ï¼Ÿè¿™äº›å‚æ•°çš„å˜åŒ–å¯¹å®éªŒç»“æœäº§ç”Ÿä»€ä¹ˆå½±å“ï¼Ÿæ¨¡å‹å…·ä½“å“ªäº›éƒ¨åˆ†å‚æ•°éœ€è¦ä½¿ç”¨loraï¼Ÿç­‰ç­‰è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬åº”è¯¥å¦‚ä½•åº”å¯¹ï¼Ÿä¸‹é¢æˆ‘å°†è¯¦ç»†ä»‹ç»ã€‚

**LoraConfigå„ä¸ªå‚æ•°è®¾ç½®**

`peft`ï¼ˆParameter-Efficient Fine-Tuningï¼‰åº“æ˜¯ä¸€ä¸ªç”¨äºé«˜æ•ˆå¾®è°ƒå¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹çš„å·¥å…·ï¼Œæ—¨åœ¨å‡å°‘è®­ç»ƒæ—¶çš„è®¡ç®—å’Œå­˜å‚¨æˆæœ¬ï¼ŒåŒæ—¶ä¿æŒæ¨¡å‹æ€§èƒ½ã€‚å®ƒé€šè¿‡å¼•å…¥LoRAã€Adapterç­‰æŠ€æœ¯ï¼Œä½¿å¾—åªéœ€è°ƒæ•´éƒ¨åˆ†å‚æ•°å³å¯å®ç°æœ‰æ•ˆçš„å¾®è°ƒã€‚`LoraConfig`æ˜¯`peft`åº“ä¸­çš„ä¸€ä¸ªé…ç½®ç±»ï¼Œç”¨äºè®¾ç½®LoRAç›¸å…³çš„è¶…å‚æ•°ï¼Œå¦‚ä½ç§©çŸ©é˜µçš„ç§©ã€ç¼©æ”¾å› å­ç­‰ï¼Œå®ƒå¸®åŠ©ç”¨æˆ·å®šåˆ¶LoRAå¾®è°ƒçš„ç»†èŠ‚ï¼Œä¼˜åŒ–è®­ç»ƒè¿‡ç¨‹çš„æ•ˆç‡å’Œæ•ˆæœã€‚

```python
from peft import LoraConfig, TaskType

lora_config = LoraConfig(
        r=16,
        lora_alpha=32,
        lora_dropout=0.05,
        bias="none",
        target_modules=['up_proj', 'gate_proj', 'q_proj', 'o_proj', 'down_proj', 'v_proj', 'k_proj'],
        task_type=TaskType.CAUSAL_LM,
        inference_mode=False  # è®­ç»ƒæ¨¡å¼
    )
```

**1. target_modules**

`target_modules`æ˜¯ LoRAï¼ˆLow-Rank Adaptationï¼‰ä¸­çš„å…³é”®å‚æ•°ï¼Œç”¨äºæŒ‡å®šæ¨¡å‹ä¸­éœ€è¦æ’å…¥ä½ç§©çŸ©é˜µè°ƒæ•´çš„æ¨¡å—ã€‚LoRA çš„æ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡å¯¹é¢„è®­ç»ƒæ¨¡å‹ä¸­çš„ç‰¹å®šå±‚è¿›è¡Œä½ç§©çŸ©é˜µæ’å…¥ï¼Œå®ç°å‚æ•°é«˜æ•ˆå¾®è°ƒè€Œæ— éœ€ä¿®æ”¹åŸå§‹æƒé‡ã€‚å¯¹äºè¯­è¨€æ¨¡å‹ï¼Œé€šå¸¸é€‰æ‹©å½±å“æƒé‡æ›´æ–°è¾ƒå¤§çš„æ¨¡å—ï¼Œä¾‹å¦‚`q_proj`å’Œ`k_proj`ï¼ˆè´Ÿè´£æŸ¥è¯¢å’Œé”®çš„å˜æ¢ï¼‰ï¼Œ`v_proj`ï¼ˆå€¼çš„å˜æ¢ï¼‰ï¼Œä»¥åŠ`o_proj`ï¼ˆè¾“å‡ºæŠ•å½±ï¼‰ç­‰ã€‚è¿™äº›æ¨¡å—ä¸»è¦é›†ä¸­åœ¨è‡ªæ³¨æ„åŠ›å’Œå‰é¦ˆç½‘ç»œä¸­ï¼Œé€šè¿‡æ’å…¥çš„ä½ç§©çŸ©é˜µè°ƒæ•´è¿™äº›æ¨¡å—çš„æƒé‡ï¼Œä½¿æ¨¡å‹åœ¨ä¿æŒåŸå§‹èƒ½åŠ›çš„åŒæ—¶é€‚åº”æ–°ä»»åŠ¡ï¼Œæå¤§å‡å°‘å¾®è°ƒçš„è®¡ç®—å’Œå­˜å‚¨å¼€é”€ã€‚

å…·ä½“å¦‚ä¸‹ï¼Œæˆ‘ä»¬ä½¿ç”¨deepseekè§‚å¯Ÿæ¨¡å‹æ¯ä¸€å±‚å…·ä½“éƒ½æ˜¯ä»€ä¹ˆï¼š

```python
# æŸ¥çœ‹æ¨¡å‹å±‚çš„ä»£ç å¦‚ä¸‹
# æœ¬æ–‡ä½¿ç”¨çš„æ˜¯å¤§æ¨¡å‹çš„é€šç”¨å¯¹è¯åŠŸèƒ½ï¼Œå› æ­¤å¯¼å…¥AutoModelForCausalLMæŸ¥çœ‹

from transformers import AutoModelForCausalLM

model = AutoModelForCausalLM.from_pretrained(model_name)
print(model)
```

```python
LlamaForCausalLM(
  (model): LlamaModel(
    (embed_tokens): Embedding(102400, 4096)
    (layers): ModuleList(
      (0-29): 30 x LlamaDecoderLayer(
        (self_attn): LlamaSdpaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LlamaMLP(
          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-06)
        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-06)
      )
    )
    (norm): LlamaRMSNorm((4096,), eps=1e-06)
    (rotary_emb): LlamaRotaryEmbedding()
  )
  (lm_head): Linear(in_features=4096, out_features=102400, bias=False)
)
```

å¯ä»¥çœ‹åˆ°deepseekæ¨¡å‹ä¹Ÿæ˜¯é‡‡å–çš„Llamaæ¨¡å‹ç»“æ„ï¼Œé‚£ä¹ˆå…·ä½“å“ªäº›å±‚ä¼šå‚ä¸loraå¾®è°ƒå‘¢ï¼Ÿä¸‹é¢å°†è¯¦ç»†ä»‹ç»

**1. Attentionå±‚**

- **Self-attentionå±‚**: è¿™äº›å±‚é€šå¸¸å¯¹æ¨¡å‹æ€§èƒ½å½±å“è¾ƒå¤§ã€‚LoRAä¼šè¢«åº”ç”¨äºè‡ªæ³¨æ„åŠ›çš„æŸ¥è¯¢ï¼ˆq_projï¼‰ã€é”®ï¼ˆk_projï¼‰ã€å€¼ï¼ˆv_projï¼‰å’Œè¾“å‡ºï¼ˆo_projï¼‰æŠ•å½±çŸ©é˜µã€‚è¿™äº›çŸ©é˜µåŒ…å«äº†å¤§é‡çš„å¯è®­ç»ƒå‚æ•°ï¼Œå› æ­¤æ˜¯LoRAå¾®è°ƒçš„ç†æƒ³ç›®æ ‡ã€‚

- **LlamaSdpaAttentionä¸­çš„çŸ©é˜µï¼š**
  
  - `q_proj`:æŸ¥è¯¢æŠ•å½±
  - `k_proj`:é”®æŠ•å½±
  - `v_proj`:å€¼æŠ•å½±
  - `o_proj`:è¾“å‡ºæŠ•å½±

- **Rotary Embedding**ï¼šè™½ç„¶åœ¨ä¸€äº›å®ç°ä¸­ä¼šå¯¹åµŒå…¥è¿›è¡Œå¾®è°ƒï¼Œä½†é€šå¸¸LoRAä¸ä¼šç›´æ¥ç”¨äºrotary_embï¼Œå› ä¸ºå®ƒé€šå¸¸æ˜¯å›ºå®šçš„ã€‚

**2. MLPå±‚**

- **MLPå±‚ä¸­çš„Gateã€Upå’ŒDownæŠ•å½±**ï¼š
  - `gate_proj`ï¼šæ§åˆ¶é—¨æŠ•å½±
  - `up_proj`ï¼šä¸Šå‡æŠ•å½±
  - `down_proj`ï¼šä¸‹é™æŠ•å½±
- MLPå±‚çš„Gateã€Upå’ŒDownæŠ•å½±é€šå¸¸æ¶‰åŠå¤§é‡çš„å¯è®­ç»ƒå‚æ•°ï¼Œå› æ­¤å¯¹è¿™äº›æŠ•å½±è¿›è¡ŒLoRAå¾®è°ƒï¼Œå¯ä»¥åœ¨ä¸æ˜¾è‘—å¢åŠ è®¡ç®—è´Ÿæ‹…çš„æƒ…å†µä¸‹ä¼˜åŒ–æ¨¡å‹è¡¨ç°ã€‚é€šè¿‡ä½ç§©é€‚åº”ï¼ŒLoRAèƒ½å¤Ÿåœ¨å‡å°‘å‚æ•°é‡çš„åŒæ—¶ï¼Œå¢å¼ºæ¨¡å‹å¯¹å¤æ‚æ¨¡å¼çš„é€‚åº”èƒ½åŠ›ã€‚è¿™äº›æ›¾åœ¨**å¤„ç†éçº¿æ€§å˜æ¢æ—¶èµ·åˆ°é‡è¦ä½œç”¨**ï¼Œé€šå¸¸ä¹Ÿæ˜¯LoRAå¾®è°ƒçš„ç›®æ ‡ã€‚

**3. LayerNormå±‚**

- **RMSNorm**: åœ¨Llamaä¸­ä½¿ç”¨çš„æ˜¯LlamaRMSNormï¼ˆRoot Mean Square Layer Normalizationï¼‰ï¼Œå®ƒä¸æ ‡å‡†çš„LayerNormä¸åŒï¼Œä½†ä¹Ÿå¯ä»¥é€šè¿‡LoRAå¾®è°ƒã€‚è™½ç„¶è¿™éƒ¨åˆ†å¸¸å¸¸ä¸ä¼šè¿›è¡Œå¾®è°ƒï¼Œä½†å¦‚æœéœ€è¦å¾®è°ƒï¼Œé€šå¸¸ä¼šé›†ä¸­åœ¨æ³¨æ„åŠ›å±‚å’ŒMLPå±‚ä¸Šã€‚

**4.Embeddingå±‚**

- `embed_tokens`ï¼šå¦‚æœå¯¹è¯åµŒå…¥æœ‰éœ€è¦è¿›è¡Œå¾®è°ƒï¼ŒLoRAä¹Ÿå¯ä»¥åº”ç”¨äºåµŒå…¥çŸ©é˜µã€‚å°¤å…¶åœ¨è¯æ±‡é‡è¾ƒå¤§çš„æƒ…å†µä¸‹ï¼ŒåµŒå…¥çŸ©é˜µçš„å‚æ•°é‡éå¸¸åºå¤§ï¼Œè¿™æ ·è¿›è¡ŒLoRAå¾®è°ƒä¹Ÿå¯ä»¥è·å¾—ä¸€å®šçš„æ€§èƒ½æå‡ã€‚

**5. çº¿æ€§å±‚ï¼ˆlm_headï¼‰**

- `lm_head`ï¼šåœ¨æ¨¡å‹è¾“å‡ºæ—¶ï¼Œ`lm_head`æ˜¯ä»éšè—å±‚åˆ°è¯æ±‡è¡¨çš„æœ€åä¸€å±‚çº¿æ€§è½¬æ¢ã€‚é€šå¸¸ï¼ŒLoRAä¸ä¼šç›´æ¥åº”ç”¨äºè¾“å‡ºå±‚ï¼Œä½†åœ¨æŸäº›å¾®è°ƒåœºæ™¯ä¸‹ï¼Œå¯ä»¥å°†LoRAåº”ç”¨äºè¯¥å±‚ä»¥è°ƒæ•´æ¨¡å‹è¾“å‡ºã€‚

> **ğŸ“**æ€»ç»“**ï¼š
>
> ä¸€èˆ¬æ¥è¯´ï¼ŒLoRAå¾®è°ƒä¼šé›†ä¸­åœ¨ä»¥ä¸‹å±‚ï¼š
> 
> - Attentionå±‚çš„æŸ¥è¯¢ã€é”®ã€å€¼å’Œè¾“å‡ºæŠ•å½±ï¼ˆ`q_proj`, `k_proj`, `v_proj`, `o_proj`ï¼‰
> - MLPå±‚çš„`gate_proj`ã€`up_proj`å’Œ`down_proj`
> - å¯èƒ½åœ¨æŸäº›åœºæ™¯ä¸‹å¾®è°ƒ`embed_tokens`å’Œ`lm_head`
> 
> é€šè¿‡è¿™ç§æ–¹å¼ï¼ŒLoRAèƒ½å¤Ÿæœ‰æ•ˆå‡å°‘å‚æ•°é‡å’Œè®¡ç®—æˆæœ¬ï¼ŒåŒæ—¶ä¿æŒå¾®è°ƒçš„æ•ˆæœã€‚

### rã€alphaã€dropout

åœ¨æ¨¡å‹å¾®è°ƒçš„è¿‡ç¨‹ä¸­ï¼Œrã€alphaå’Œdropoutæ˜¯å¸¸è§çš„è¶…å‚æ•°ï¼Œç”¨äºä¼˜åŒ–æ¨¡å‹è®­ç»ƒå’Œæå‡å…¶æ³›åŒ–èƒ½åŠ›ã€‚
- `r`ï¼šé€šå¸¸ç”¨äºLoRAï¼ˆLow-Rank Adaptationï¼‰æ–¹æ³•ä¸­ï¼Œè¡¨ç¤ºä½ç§©çŸ©é˜µçš„ç§©å€¼ã€‚rå†³å®šäº†å¾®è°ƒæ—¶ä½¿ç”¨çš„ä½ç§©çŸ©é˜µçš„ç»´åº¦ï¼Œè¾ƒå°çš„rå¯ä»¥å‡å°‘å‚æ•°æ•°é‡ï¼Œä»è€Œæé«˜è®­ç»ƒæ•ˆç‡ï¼Œä½†å¯èƒ½ç‰ºç‰²ä¸€å®šçš„æ¨¡å‹è¡¨ç°ã€‚è¾ƒå°çš„rï¼ˆä¾‹å¦‚ 8-32ï¼‰é€‚ç”¨äºè¾ƒå°æ¨¡å‹æˆ–éœ€è¦è¾ƒä½èµ„æºçš„æƒ…å†µï¼Œè€Œè¾ƒå¤§çš„rï¼ˆä¾‹å¦‚ 64-128ï¼‰é€‚ç”¨äºæ›´å¤§è§„æ¨¡çš„æ¨¡å‹ã€‚
- `alpha`ï¼šæ˜¯LoRAä¸­çš„ä¸€ä¸ªè¶…å‚æ•°ï¼Œç”¨æ¥æ§åˆ¶ä½ç§©çŸ©é˜µçš„ç¼©æ”¾å› å­ã€‚é€šè¿‡è°ƒæ•´alphaï¼Œå¯ä»¥å¹³è¡¡ä½ç§©çŸ©é˜µçš„å½±å“ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿåœ¨å¾®è°ƒè¿‡ç¨‹ä¸­ä¿æŒè¶³å¤Ÿçš„è¡¨è¾¾èƒ½åŠ›ã€‚16-32 æ˜¯æ¯”è¾ƒå¸¸è§çš„é€‰æ‹©ï¼Œè¾ƒå¤§çš„alphaå€¼é€šå¸¸ä¼šå¢åŠ æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›ï¼Œä½†ä¹Ÿå¯èƒ½å¢åŠ è®­ç»ƒéš¾åº¦ã€‚
- `Dropout`ï¼šæ˜¯ä¸€ç§æ­£åˆ™åŒ–æŠ€æœ¯ï¼Œé€šè¿‡åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­éšæœºä¸¢å¼ƒç¥ç»ç½‘ç»œä¸­çš„éƒ¨åˆ†ç¥ç»å…ƒæ¥é˜²æ­¢è¿‡æ‹Ÿåˆã€‚dropoutç‡æ§åˆ¶ä¸¢å¼ƒçš„æ¦‚ç‡ï¼Œè¾ƒé«˜çš„dropoutç‡æœ‰åŠ©äºå‡å°‘æ¨¡å‹çš„å¤æ‚åº¦ï¼Œä»è€Œæå‡å…¶åœ¨æ–°æ•°æ®ä¸Šçš„æ³›åŒ–èƒ½åŠ›ã€‚å¯¹äºå¤§å¤šæ•°ä»»åŠ¡ï¼Œ0.2-0.3 æ˜¯æ¯”è¾ƒå¸¸è§çš„å–å€¼ï¼Œè¾ƒä½çš„dropoutå€¼ï¼ˆå¦‚ 0.1ï¼‰é€‚åˆäºè¾ƒå°çš„æ¨¡å‹ï¼Œè€Œè¾ƒé«˜çš„dropoutå€¼ï¼ˆå¦‚ 0.4-0.5ï¼‰é€‚åˆäºè¾ƒå¤§çš„ç½‘ç»œï¼Œå°¤å…¶æ˜¯åœ¨é˜²æ­¢è¿‡æ‹Ÿåˆæ—¶ã€‚


> **ğŸ“**æ€»ç»“**ï¼š
> 
> - rï¼šé€šå¸¸é€‰æ‹© **8-128**ï¼Œæ ¹æ®ä»»åŠ¡å’Œæ¨¡å‹è§„æ¨¡è°ƒæ•´ã€‚
> - alphaï¼šå¸¸è§å€¼åœ¨ **16-64**ï¼Œæ¨è **16-32**ã€‚
> - Dropoutï¼šå¸¸è§å€¼åœ¨ **0.1-0.5**ï¼Œæ¨è **0.2-0.3**ã€‚

### task_type

åœ¨`LoraConfig`ä¸­çš„`task_type`æ˜¯ä¸€ä¸ªæŒ‡å®šæ¨¡å‹ä»»åŠ¡ç±»å‹çš„å‚æ•°ï¼Œå®ƒå¸®åŠ©LoRAé…ç½®ä¸åŒçš„å¾®è°ƒç­–ç•¥ï¼Œä»¥é€‚åº”ç‰¹å®šçš„ä»»åŠ¡éœ€æ±‚ã€‚`task_type`å¯ä»¥æœ‰å¤šä¸ªé€‰é¡¹ï¼Œé€šå¸¸åŒ…æ‹¬ä»¥ä¸‹å‡ ç§ç±»å‹ï¼š

**1ã€CAUSAL_LM**

è‡ªå›å½’è¯­è¨€å»ºæ¨¡ä»»åŠ¡ï¼Œæ¨¡å‹åŸºäºè¾“å…¥çš„éƒ¨åˆ†æ–‡æœ¬ï¼ˆä¸Šä¸‹æ–‡ï¼‰æ¥é¢„æµ‹ä¸‹ä¸€ä¸ªè¯ï¼Œé€‚ç”¨äºç”Ÿæˆä»»åŠ¡ï¼Œå¦‚æ–‡æœ¬ç”Ÿæˆå’Œè¯­è¨€å»ºæ¨¡ã€‚

**2ã€SEQ_CLS**

æ–‡æœ¬åˆ†ç±»ä»»åŠ¡ï¼Œæ¨¡å‹å°†æ•´ä¸ªè¾“å…¥æ–‡æœ¬åˆ†ç±»åˆ°æŸä¸ªç±»åˆ«ã€‚å¸¸è§çš„åº”ç”¨åŒ…æ‹¬æƒ…æ„Ÿåˆ†æã€åƒåœ¾é‚®ä»¶æ£€æµ‹ã€æ–°é—»åˆ†ç±»ç­‰ã€‚

**3ã€SEQ_2_SEQ_LM**

åºåˆ—åˆ°åºåˆ—çš„è¯­è¨€å»ºæ¨¡ä»»åŠ¡ã€‚è¯¥ä»»åŠ¡ç±»å‹å¤„ç†è¾“å…¥åºåˆ—å¹¶ç”Ÿæˆä¸€ä¸ªè¾“å‡ºåºåˆ—ã€‚é€šå¸¸ç”¨äºæœºå™¨ç¿»è¯‘ã€æ–‡æœ¬æ‘˜è¦ç­‰ä»»åŠ¡ã€‚

**4ã€TOKEN_CLS**

æ ‡è®°åˆ†ç±»ä»»åŠ¡ï¼Œæ¨¡å‹ä¸ºè¾“å…¥æ–‡æœ¬çš„æ¯ä¸ªæ ‡è®°ï¼ˆé€šå¸¸æ˜¯è¯æˆ–å­è¯ï¼‰åˆ†é…ä¸€ä¸ªç±»åˆ«æ ‡ç­¾ã€‚å¸¸è§åº”ç”¨åŒ…æ‹¬å‘½åå®ä½“è¯†åˆ«ï¼ˆNERï¼‰ã€è¯æ€§æ ‡æ³¨ï¼ˆPOSï¼‰ã€ä¾å­˜å¥æ³•åˆ†æç­‰ã€‚

**5ã€QUESTION_ANS**

é—®ç­”ä»»åŠ¡ï¼Œæ¨¡å‹æ ¹æ®è¾“å…¥çš„é—®é¢˜å’Œä¸Šä¸‹æ–‡ï¼Œæå–ç­”æ¡ˆã€‚å¸¸è§åº”ç”¨åŒ…æ‹¬é˜…è¯»ç†è§£ã€åŸºäºæ–‡æ¡£çš„é—®ç­”ç­‰ã€‚

**6ã€FEATURE_EXTRACTION**

ç‰¹å¾æå–ä»»åŠ¡ï¼Œæ¨¡å‹æå–è¾“å…¥æ•°æ®çš„éšè—çŠ¶æ€ï¼ˆé€šå¸¸æ˜¯ç¼–ç å™¨çš„è¾“å‡ºï¼‰ï¼Œè¿™äº›éšè—çŠ¶æ€å¯ä»¥ç”¨äºä¸‹æ¸¸ä»»åŠ¡ï¼Œå¦‚èšç±»ã€åˆ†ç±»æˆ–ä½œä¸ºå…¶ä»–ä»»åŠ¡çš„è¾“å…¥ç‰¹å¾ã€‚æ¯”å¦‚ç»™å®šä¸€æ®µæ–‡æœ¬ï¼Œæ¨¡å‹è¾“å‡ºè¯¥æ–‡æœ¬çš„å‘é‡è¡¨ç¤ºï¼Œè¿™äº›å‘é‡å¯ä»¥ç”¨äºæƒ…æ„Ÿåˆ†æã€æ¨èç³»ç»Ÿæˆ–ç›¸ä¼¼åº¦è®¡ç®—ç­‰ä»»åŠ¡ã€‚

### bias

åœ¨`LoraConfig` é…ç½®ä¸­ï¼Œ`bias`å‚æ•°ç”¨äºæŒ‡å®š LoRA å¾®è°ƒæ—¶å¦‚ä½•å¤„ç†åç½®ï¼ˆbiasï¼‰é¡¹ã€‚å…·ä½“æ¥è¯´ï¼Œè¿™ä¸ªå‚æ•°æ§åˆ¶äº†åœ¨ä½ç§©é€‚åº”ä¸­ï¼Œæ˜¯å¦ä¿ç•™æˆ–è€…ä¿®æ”¹åç½®é¡¹ã€‚LoRAå¾®è°ƒä¸€èˆ¬ä¼šå°†æƒé‡çŸ©é˜µæ‹†åˆ†æˆä½ç§©çŸ©é˜µæ¥å‡å°‘è®­ç»ƒæ—¶çš„è®¡ç®—å¼€é”€ï¼Œä½†åç½®é¡¹é€šå¸¸ä¼šä¿ç•™æˆ–å¤„ç†å¾—ä¸åŒã€‚

`bias`å‚æ•°çš„å¸¸è§é€‰é¡¹ï¼š

1. **"none"**ï¼šä¸å¯¹åç½®é¡¹è¿›è¡Œå¾®è°ƒï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œåç½®é¡¹ä¿æŒåŸæ ·ï¼Œä¸å‚ä¸LoRAçš„ä½ç§©é€‚åº”è¿‡ç¨‹ã€‚è¿™æ˜¯é»˜è®¤é€‰é¡¹ï¼Œè¡¨ç¤ºä¸ä¿®æ”¹åç½®é¡¹ï¼Œä¿æŒåŸæœ‰æƒé‡ã€‚
2. **"all"**ï¼šå¯¹æ‰€æœ‰çš„åç½®é¡¹è¿›è¡Œå¾®è°ƒï¼Œè¿™æ„å‘³ç€LoRAä¸ä»…ä¼šå¯¹æƒé‡çŸ©é˜µè¿›è¡Œä½ç§©é€‚åº”ï¼Œè¿˜ä¼šå¯¹åç½®é¡¹è¿›è¡Œç›¸åº”çš„è°ƒæ•´ã€‚
3. **"lora_only"**ï¼šä»…å¯¹LoRAå¼•å…¥çš„ä½ç§©çŸ©é˜µä¸­çš„åç½®é¡¹è¿›è¡Œå¾®è°ƒã€‚å³åœ¨LoRAçš„ä½ç§©å˜æ¢éƒ¨åˆ†ï¼Œåç½®é¡¹ä¼šè¢«åŒ…å«åœ¨å†…ï¼Œå¹¶è¿›è¡Œä¼˜åŒ–ã€‚

> **ä¸ºä»€ä¹ˆé€‰æ‹© "none" ä½œä¸º bias çš„å€¼ï¼Ÿ**
> 
> åœ¨è®¸å¤šLoRAå¾®è°ƒçš„å®ç°ä¸­ï¼Œåç½®é¡¹é€šå¸¸è¢«è®¤ä¸ºæ˜¯æ¨¡å‹çš„ä¸€ä¸ªç¨³å®šéƒ¨åˆ†ï¼Œå°¤å…¶æ˜¯åœ¨è¿›è¡Œä½ç§©å¾®è°ƒæ—¶ï¼Œå¯èƒ½å¹¶ä¸éœ€è¦å¯¹å®ƒä»¬è¿›è¡Œè°ƒæ•´ã€‚ä½¿ç”¨ "none" çš„é€‰æ‹©æ„å‘³ç€å¾®è°ƒè¿‡ç¨‹åªä¼šé›†ä¸­åœ¨æƒé‡çŸ©é˜µçš„ä½ç§©éƒ¨åˆ†ï¼Œè€Œä¸æ¶‰åŠåç½®é¡¹çš„å˜åŠ¨ï¼Œè¿™æœ‰åŠ©äºå‡å°‘é¢å¤–çš„è®¡ç®—å’Œå‚æ•°è°ƒèŠ‚ï¼Œä¿æŒæ¨¡å‹çš„åŸå§‹ç»“æ„ã€‚

### å…¶ä»–å‚æ•°

1ã€æ ¹æ®ä»»åŠ¡é…ç½®
- use_rslora (bool): æ˜¯å¦ä½¿ç”¨Rank-Stabilized LoRAã€‚è¿™ä¸ªæ–¹æ³•æœ‰æ—¶å¯ä»¥æé«˜è®­ç»ƒæ•ˆæœï¼Œå°¤å…¶æ˜¯åœ¨ä½ç§©æƒ…å†µä¸‹ã€‚è‹¥ä¸éœ€è¦ï¼Œå¯ä»¥ä¿æŒFalseã€‚
- init_lora_weights (bool | Literal["gaussian", "olora", "pissa", "loftq"]): åˆå§‹åŒ–LoRAæƒé‡çš„æ–¹å¼ã€‚å¸¸ç”¨çš„åˆå§‹åŒ–æ–¹å¼æ˜¯"gaussian"ï¼Œä½†å¦‚æœæœ‰ç‰¹æ®Šéœ€æ±‚ï¼Œä¹Ÿå¯ä»¥é€‰æ‹©å…¶ä»–é€‰é¡¹ã€‚
- modules_to_save (list[str]): é™¤LoRAå±‚å¤–éœ€è¦ä¿å­˜çš„å…¶ä»–æ¨¡å—ï¼Œé€šå¸¸ç”¨äºåœ¨åˆ†ç±»ä»»åŠ¡ä¸­ä¿å­˜æœ€åçš„åˆ†ç±»å±‚ç­‰ã€‚
- layers_to_transform (list[int] | int): é€‰æ‹©è¦è½¬æ¢çš„å±‚ï¼Œé€‚ç”¨äºå¤§è§„æ¨¡æ¨¡å‹ï¼Œå¯ä»¥é€‰æ‹©ç‰¹å®šå±‚è¿›è¡Œå¾®è°ƒã€‚é»˜è®¤ä¼šé€‰æ‹©æ•´ä¸ªæ¨¡å‹è¿›è¡ŒLoRAå¾®è°ƒã€‚
- layers_pattern (list[str] | str): ç”¨äºæŒ‡å®šå±‚æ¨¡å¼åç§°ï¼Œä¸layers_to_transformç»“åˆä½¿ç”¨ï¼Œç”¨äºé€‰æ‹©æ¨¡å‹ä¸­çš„ç‰¹å®šå±‚ã€‚

2ã€ç‰¹å®šéœ€æ±‚ä½¿ç”¨

- use_dora (bool): å¯ç”¨Weight-Decomposed LoRAï¼ˆDoRAï¼‰ã€‚è¿™ä¸ªé€‰é¡¹é€šå¸¸ç”¨äºè¿›ä¸€æ­¥ä¼˜åŒ–ä½ç§©é€‚åº”ï¼Œä½†ä¼šå¼•å…¥é¢å¤–çš„è®¡ç®—å¼€é”€ã€‚å¦‚æœä¸éœ€è¦ï¼Œå¯ä»¥ä¿æŒFalseã€‚
- layer_replication (list[tuple[int, int]]): ç”¨äºå±‚æ‰©å±•ï¼Œé€‚ç”¨äºå¸Œæœ›é€šè¿‡å¤åˆ¶å±‚æ¥æ‰©å±•æ¨¡å‹çš„æƒ…å†µã€‚å¦‚æœä¸æ¶‰åŠæ­¤ç±»æ“ä½œï¼Œå¯ä»¥å¿½ç•¥ã€‚
- runtime_config (LoraRuntimeConfig): ç”¨äºè®¾ç½®è¿è¡Œæ—¶é…ç½®ï¼Œé€šå¸¸æ˜¯è‡ªåŠ¨å¤„ç†çš„ï¼Œé™¤éæœ‰ç‰¹æ®Šéœ€è¦ï¼Œå¦åˆ™ä¸éœ€è¦æ›´æ”¹ã€‚

3ã€ä¸å¸¸ç”¨

- megatron_config (dict): ä»…å½“ä½¿ç”¨Megatronæ¶æ„æ—¶éœ€è¦ï¼Œè‹¥ä¸ä½¿ç”¨Megatronæ¡†æ¶ï¼Œé€šå¸¸ä¸éœ€è¦è®¾ç½®ã€‚
- megatron_core (str): åŒä¸Šï¼Œé€‚ç”¨äºMegatronæ ¸å¿ƒæ¨¡å—ã€‚

## ğŸ“Œè®­ç»ƒå‚æ•°

### Trainer

ä¸€èˆ¬æ¥è¯´ï¼Œæˆ‘ä»¬åœ¨è®­ç»ƒçš„æ—¶å€™å¯ä»¥ç›´æ¥ä½¿ç”¨transformersæˆ–è€…å…¶ä»–çš„æ¯”å¦‚PyTorchçš„Lightningçš„è®­ç»ƒå™¨é…ç½®ï¼Œå½“ç„¶ä¹Ÿæœ‰äº›githubä¸Šè‡ªå·±å°è£…çš„æˆ–è€…åŸºäºè¿™ä¸¤ä¸ªç»§ç»­å°è£…çš„Trainerï¼Œé‚£ä¹ˆå…·ä½“æˆ‘ä»¬åº”è¯¥ä½¿ç”¨å“ªç§æ¯”è¾ƒå¥½å‘¢ï¼Ÿ

å…¶å®å•ä»ä½¿ç”¨é‡æ¥çœ‹çš„è¯ï¼Œåº”è¯¥æ˜¯HuggingFaceçš„Transformersæ›´èƒœä¸€ç­¹ï¼Œç¤¾åŒºæ›´æ´»è·ƒï¼Œå¾ˆå¤šçš„å¼€æºå¾®è°ƒå¤§æ¨¡å‹ç”¨çš„ä¹Ÿéƒ½æ˜¯HuggingFaceçš„Transformersï¼Œå®ƒä¹Ÿæ˜¯ç‡å…ˆæ”¯æŒå¾®è°ƒLLaMaæ¨¡å‹ã€‚ä¸è¿‡ç”±äºå…¶æ›´æ–°çš„æ—¶å€™å˜åŒ–æ¯”è¾ƒå¤šï¼Œå½“ç‰ˆæœ¬å·®çš„æœ‰ç‚¹å¤šçš„æ—¶å€™å¯èƒ½ä¼šå‡ºç°bugï¼Œåº”è¯¥æ˜¯è€ç‰ˆæœ¬çš„å…¼å®¹ä¸äº†æ–°çš„ä¸€äº›åº“å§ã€‚

Trainer ç®€å•æ¥è¯´å°±æ˜¯å°è£…äº† PyTorch çš„è®­ç»ƒè¿‡ç¨‹ï¼ŒåŒ…æ‹¬å‰å‘ä¼ æ’­ã€åå‘ä¼ æ’­å’Œå‚æ•°æ›´æ–°ç­‰ç­‰æ­¥éª¤ï¼Œå’±ä»¬åªéœ€è¦è®¾è®¡æ¨¡å‹ï¼ˆcopyï¼‰ï¼Œè°ƒå‚ï¼ˆç‚¼ä¸¹ï¼‰å°±è¡Œï¼Œé«˜çº§ç‚¹çš„Trainerå°±æ˜¯åŠ ä¸Šäº†å„ç§çš„åŠŸèƒ½ï¼Œæ¯”å¦‚æ—¥å¿—è®°å½•ï¼Œæ–­ç‚¹é‡è®­ï¼Œè®­ç»ƒæ–¹å¼ä¸ç²¾åº¦ï¼Œæ”¯æŒå„ç§åˆ†å¸ƒå¼è®­ç»ƒæ¡†æ¶åƒåŸç”Ÿã€Apexã€Deepspeedå’ŒFairscaleï¼Œæ”¯æŒè‡ªå®šçš„å›è°ƒå‡½æ•°ç­‰ç­‰ã€‚
å¸¸ç”¨çš„å‚æ•°å¦‚ä¸‹ï¼š

```python
trainer = Trainer(
        model=model,
        args=train_args,
        train_dataset=train_dataset,
        data_collator=data_collator,
        callbacks=[swanlab_callback],
        )
```

**å¸¸ç”¨çš„å‚æ•°ï¼š**

1. model (PreTrainedModel æˆ– torch.nn.Module, å¯é€‰)ï¼šè¦è¿›è¡Œè®­ç»ƒã€è¯„ä¼°æˆ–é¢„æµ‹çš„å®ä¾‹åŒ–åæ¨¡å‹ï¼Œå¦‚æœä¸æä¾›ï¼Œå¿…é¡»ä¼ é€’ä¸€ä¸ª model_initæ¥åˆå§‹åŒ–ä¸€ä¸ªæ¨¡å‹ã€‚
2. **args (TrainingArguments, å¯é€‰)ï¼šè®­ç»ƒçš„å‚æ•°**ï¼Œå¦‚æœä¸æä¾›ï¼Œå°±ä¼šä½¿ç”¨é»˜è®¤çš„TrainingArguments é‡Œé¢çš„å‚æ•°ï¼Œå…¶ä¸­ output_dir è®¾ç½®ä¸ºå½“å‰ç›®å½•ä¸­çš„åä¸º "tmp_trainer" çš„ç›®å½•ã€‚
3. train_dataset (torch.utils.data.Dataset æˆ– torch.utils.data.IterableDataset, å¯é€‰)ï¼šç”¨äºè®­ç»ƒçš„æ•°æ®é›†ï¼Œå¦‚æœæ˜¯torch.utils.data.Datasetï¼Œåˆ™ä¼šè‡ªåŠ¨åˆ é™¤æ¨¡å‹çš„ forward() æ–¹æ³•ä¸æ¥å—çš„åˆ—ã€‚
4. eval_dataset (Union[torch.utils.data.Dataset, Dict[str, torch.utils.data.Dataset]), å¯é€‰)ï¼šåŒä¸Šï¼Œç”¨äºè¯„ä¼°çš„æ•°æ®é›†ï¼Œå¦‚æœæ˜¯å­—å…¸ï¼Œå°†å¯¹æ¯ä¸ªæ•°æ®é›†è¿›è¡Œè¯„ä¼°ï¼Œå¹¶åœ¨æŒ‡æ ‡åç§°å‰é™„åŠ å­—å…¸çš„é”®å€¼ã€‚
5. data_collator (DataCollator, å¯é€‰)ï¼šç”¨äºä» train_dataset æˆ– eval_dataset ä¸­æ„æˆbatchçš„å‡½æ•°ï¼Œå¦‚æœæœªæä¾›tokenizerï¼Œå°†é»˜è®¤ä½¿ç”¨ default_data_collator()ï¼›å¦‚æœæä¾›ï¼Œå°†ä½¿ç”¨ DataCollatorWithPadding ã€‚
6. callbacks (TrainerCallback åˆ—è¡¨, å¯é€‰)ï¼šè‡ªå®šä¹‰å›è°ƒå‡½æ•°ï¼Œå¦‚æœè¦åˆ é™¤ä½¿ç”¨çš„é»˜è®¤å›è°ƒå‡½æ•°ï¼Œè¦ä½¿ç”¨ Trainer.remove_callback() æ–¹æ³•ã€‚è¿™é‡Œå¯ä»¥é€‰æ‹©å¯è§†åŒ–å·¥å…·å›è°ƒå‡½æ•°æ¥è§‚æµ‹å®éªŒè¿‡ç¨‹ã€‚

**ä¸å¸¸ç”¨çš„å‚æ•°ï¼š**

1. model_init (Callable[[], PreTrainedModel], å¯é€‰)ï¼šç”¨äºå®ä¾‹åŒ–è¦ä½¿ç”¨çš„æ¨¡å‹çš„å‡½æ•°ï¼Œå¦‚æœæä¾›ï¼Œæ¯æ¬¡è°ƒç”¨ train() æ—¶éƒ½ä¼šä»æ­¤å‡½æ•°ç»™å‡ºçš„æ¨¡å‹çš„æ–°å®ä¾‹å¼€å§‹ã€‚
2. preprocess_logits_for_metrics (Callable[[torch.Tensor, torch.Tensor], torch.Tensor], å¯é€‰)ï¼šç”¨äºæŒ‡å®šä¸€ä¸ªå‡½æ•°ï¼Œè¿™ä¸ªå‡½æ•°åœ¨æ¯æ¬¡è¯„ä¼°æ­¥éª¤ï¼ˆevaluation stepï¼‰å‰ï¼Œå…¶å®å°±æ˜¯åœ¨è¿›å…¥compute_metricså‡½æ•°å‰å¯¹æ¨¡å‹çš„è¾“å‡º logits è¿›è¡Œé¢„å¤„ç†ã€‚æ¥å—ä¸¤ä¸ªå¼ é‡ï¼ˆtensorsï¼‰ä½œä¸ºå‚æ•°ï¼Œä¸€ä¸ªæ˜¯æ¨¡å‹çš„è¾“å‡º logitsï¼Œå¦ä¸€ä¸ªæ˜¯çœŸå®æ ‡ç­¾ï¼ˆlabelsï¼‰ã€‚ç„¶åè¿”å›ä¸€ä¸ªç»è¿‡é¢„å¤„ç†åçš„ logits å¼ é‡ï¼Œç»™åˆ°compute_metricså‡½æ•°ä½œä¸ºå‚æ•°ã€‚
3. compute_metrics (Callable[[EvalPrediction], Dict], å¯é€‰)ï¼šç”¨äºåœ¨è¯„ä¼°æ—¶è®¡ç®—æŒ‡æ ‡çš„å‡½æ•°ï¼Œå¿…é¡»æ¥å— EvalPrediction ä½œä¸ºå…¥å‚ï¼Œå¹¶è¿”å›ä¸€ä¸ªå­—å…¸ï¼Œå…¶ä¸­åŒ…å«äº†ä¸åŒæ€§èƒ½æŒ‡æ ‡çš„åç§°å’Œç›¸åº”çš„æ•°å€¼ï¼Œä¸€èˆ¬æ˜¯å‡†ç¡®åº¦ã€ç²¾ç¡®åº¦ã€å¬å›ç‡ã€F1 åˆ†æ•°ç­‰ã€‚
4. optimizers (Tuple[torch.optim.Optimizer, torch.optim.lr_scheduler.LambdaLR], å¯é€‰)ï¼šç”¨äºæŒ‡å®šä¸€ä¸ªåŒ…å«ä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡è°ƒåº¦å™¨çš„å…ƒç»„ï¼ˆTupleï¼‰ï¼Œè¿™ä¸ªå…ƒç»„çš„ä¸¤ä¸ªå…ƒç´ åˆ†åˆ«æ˜¯ä¼˜åŒ–å™¨
ï¼ˆtorch.optim.Optimizerï¼‰å’Œå­¦ä¹ ç‡è°ƒåº¦å™¨ï¼ˆtorch.optim.lr_scheduler.LambdaLRï¼‰ï¼Œé»˜è®¤ä¼šåˆ›å»ºä¸€ä¸ªåŸºäºAdamWä¼˜åŒ–å™¨çš„å®ä¾‹ï¼Œå¹¶ä½¿ç”¨ get_linear_schedule_with_warmup() å‡½æ•°åˆ›å»ºä¸€ä¸ªå­¦ä¹ ç‡è°ƒåº¦å™¨ã€‚

å…¶ä¸­**args (TrainingArguments, å¯é€‰)**éœ€è¦é¢å¤–æ³¨æ„ï¼Œå› ä¸ºå®ƒåŒ…å«äº†epochsã€batch_sizeç­‰å„ç§è®­ç»ƒå‚æ•°è®¾ç½®ï¼Œæ˜¯éå¸¸é‡è¦çš„ç¯èŠ‚ï¼Œæ¯”å¦‚æœ¬æ–‡åœ¨è¿›è¡Œå®éªŒçš„æ—¶å€™å¯¹è¿™äº›å‚æ•°åŠ ä»¥è®¾ç½®ï¼š

```python
train_args = TrainingArguments(
    output_dir=output_dir,
    per_device_train_batch_size=2,
    gradient_accumulation_steps=8,
    logging_steps=1,
    num_train_epochs=3,
    save_steps=5000,
    learning_rate=2e-5,
    save_on_each_node=True,
    gradient_checkpointing=True,
    report_to=None,
    seed=42,
    optim="adamw_torch",
    fp16=True,
    bf16=False,
    remove_unused_columns=False,
)
```

å…¶ä¸­fp16ã€gradient_checkpointingã€gradient_accumulation_stepsç­‰éƒ½å¯ä»¥å‡å°‘æ˜¾å­˜å‹åŠ›ï¼Œè€Œper_device_train_batch_sizeå¯èƒ½ä¼šå¢åŠ æ˜¾å­˜å‹åŠ›ï¼Œä½†æ˜¯è®­ç»ƒå®Œåçš„æ•ˆæœå¯èƒ½ä¼šæ›´å¥½ï¼Œåœ¨è®¾ç½®è¿™äº›å‚æ•°çš„æ—¶å€™éœ€è¦æ ¹æ®è‡ªèº«æ¡ä»¶åˆç†åˆ†é…ã€‚ä¸‹é¢æˆ‘å°†è¯¦ç»†åˆ—ä¸¾è¿™äº›å‚æ•°çš„å«ä¹‰ï¼Œå¹¶ä¸”åˆ—ä¸¾å‡ºæ¯”è¾ƒé‡è¦çš„å‚æ•°ã€‚

### TrainingArgumentsï¼ˆå¸¸ç”¨çš„å‚æ•°ï¼‰

#### å½±å“æ˜¾å­˜çš„å‚æ•°è®¾ç½®

1. **per_device_train_batch_size**ï¼šç”¨äºæŒ‡å®šè®­ç»ƒçš„æ¯ä¸ªGPU/XPU/TPU/MPS/NPU/CPUçš„batchï¼Œæ¯ä¸ªè®­ç»ƒæ­¥éª¤ä¸­æ¯ä¸ªç¡¬ä»¶ä¸Šçš„æ ·æœ¬æ•°é‡ã€‚è¾ƒå¤§çš„batch sizeä¼šå¢åŠ æ˜¾å­˜çš„å ç”¨ã€‚
2. **per_device_eval_batch_size**ï¼šç”¨äºæŒ‡å®šè¯„ä¼°çš„æ¯ä¸ªGPU/XPU/TPU/MPS/NPU/CPUçš„batchï¼Œæ¯ä¸ªè¯„ä¼°æ­¥éª¤ä¸­æ¯ä¸ªç¡¬ä»¶ä¸Šçš„æ ·æœ¬æ•°é‡ã€‚è¾ƒå¤§çš„batch sizeä¼šå¢åŠ æ˜¾å­˜çš„å ç”¨ã€‚
3. **gradient_accumulation_steps**ï¼šç”¨äºæŒ‡å®šåœ¨æ¯æ¬¡æ›´æ–°æ¨¡å‹å‚æ•°ä¹‹å‰ï¼Œæ¢¯åº¦ç§¯ç´¯çš„æ›´æ–°æ­¥æ•°ã€‚é€šè¿‡æ¢¯åº¦ç§¯ç´¯å¯ä»¥åœ¨å¤šä¸ªbatchä¸Šç´¯ç§¯æ¢¯åº¦ï¼Œç„¶åæ›´æ–°æ¨¡å‹å‚æ•°ï¼Œè¿™å¯ä»¥åœ¨æ˜¾å­˜ä¸å¤Ÿçš„æƒ…å†µä¸‹æ‰§è¡Œå¤§batchçš„åå‘ä¼ æ’­ï¼Œä½†ä¼šå¢åŠ æ˜¾å­˜çš„ä½¿ç”¨ã€‚
4. **eval_accumulation_steps**ï¼šæŒ‡å®šåœ¨æ‰§è¡Œè¯„ä¼°æ—¶ï¼Œæ¨¡å‹ä¼šç´¯ç§¯å¤šå°‘ä¸ªé¢„æµ‹æ­¥éª¤çš„è¾“å‡ºå¼ é‡ï¼Œç„¶åæ‰å°†å®ƒä»¬ä»GPU/NPU/TPUç§»åŠ¨åˆ°CPUä¸Šã€‚é»˜è®¤æ˜¯æ•´ä¸ªè¯„ä¼°çš„è¾“å‡ºç»“æœå°†åœ¨GPU/NPU/TPUä¸Šç´¯ç§¯ï¼Œç„¶åä¸€æ¬¡æ€§ä¼ è¾“åˆ°CPUï¼Œé€Ÿåº¦æ›´å¿«ï¼Œä½†å æ˜¾å­˜ã€‚
5. max_grad_normï¼šæŒ‡å®šæ¢¯åº¦å‰ªè£çš„æœ€å¤§æ¢¯åº¦èŒƒæ•°ï¼Œå¯ä»¥é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸ï¼Œä½†å‰ªè£æ“ä½œå¯èƒ½ä¼šå¢åŠ æ˜¾å­˜çš„ä½¿ç”¨ã€‚
6. **gradient_checkpointing**ï¼šæ˜¯å¦å¼€å¯æ¢¯åº¦æ£€æŸ¥ç‚¹ï¼Œè¿™ä¼šåœ¨è®­ç»ƒæœŸé—´é‡Šæ”¾ä¸å†éœ€è¦çš„ä¸­é—´ç»“æœä»¥å‡å°å†…å­˜å ç”¨ï¼Œä½†å®ƒä¼šä½¿è®­ç»ƒå˜æ…¢ã€‚è¿™ä¸ªå‚æ•°ä¼šå½±å“æ˜¾å­˜çš„ä½¿ç”¨ï¼Œå› ä¸ºå®ƒæ¶‰åŠåˆ°ä¿å­˜ä¸­é—´æ¿€æ´»å€¼ã€‚
7. **bf16ã€fp16**ï¼šè¿™äº›å‚æ•°ç”¨äºæŒ‡å®šæ˜¯å¦ä½¿ç”¨bf16æˆ–fp16è¿›è¡Œæ··åˆç²¾åº¦è®­ç»ƒï¼Œè€Œä¸æ˜¯fp32è®­ç»ƒã€‚ä½¿ç”¨æ›´ä½çš„ç²¾åº¦å¯ä»¥å‡å°‘æ˜¾å­˜çš„ä½¿ç”¨ã€‚äºŒè€…åªèƒ½ä½¿ç”¨å…¶ä¸€ï¼Œå¦‚æœfp16è®¾ç½®ä¸ºTrueçš„è¯ï¼Œbf16å°±åªèƒ½è®¾ç½®ä¸ºFalseï¼Œåä¹‹äº¦ç„¶ã€‚

#### è¾“å‡ºæ¨¡å‹ä¿å­˜å‚æ•°

1. **output_dir (str)**ï¼šç”¨äºæŒ‡å®šæ¨¡å‹checkpointå’Œæœ€ç»ˆç»“æœçš„è¾“å‡ºç›®å½•ã€‚
2. **save_stepsï¼ˆintï¼‰**ï¼šæ¯è¿‡å¤šå°‘æ­¥ä¿å­˜ä¸€æ¬¡æ¨¡å‹ã€‚
3. **save_on_each_node (bool, å¯é€‰, é»˜è®¤ä¸º False)**ï¼šåœ¨è¿›è¡Œå¤šèŠ‚ç‚¹åˆ†å¸ƒå¼è®­ç»ƒæ—¶ï¼Œæ˜¯å¦åœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šä¿å­˜checkpointï¼Œè¿˜æ˜¯ä»…åœ¨ä¸»èŠ‚ç‚¹ä¸Šä¿å­˜ã€‚æ³¨æ„å¦‚æœå¤šèŠ‚ç‚¹ä½¿ç”¨çš„æ˜¯åŒä¸€å¥—å­˜å‚¨è®¾å¤‡ï¼Œæ¯”å¦‚éƒ½æ˜¯å¤–æŒ‚çš„åŒä¸€ä¸ªnasï¼Œå¼€å¯åä¼šæŠ¥é”™ï¼Œå› ä¸ºæ–‡ä»¶åç§°éƒ½ä¸€æ ·ã€‚

#### å¯è§†åŒ–å·¥å…·å‚æ•°é…ç½®

1. **report_toï¼ˆstrï¼‰**ï¼šå¯è§†åŒ–å·¥å…·çš„é€‰æ‹©ã€‚ç”±äºswanlabæ²¡æœ‰ç›´æ¥ä¸transformersé›†æˆï¼Œè€Œæ˜¯ä»¥å›è°ƒå‡½æ•°çš„æ–¹å¼ä¸transformersé›†æˆï¼Œå› æ­¤è¿™é‡Œéœ€è¦è®¾ç½®ä¸ºNoneï¼Œåœ¨Traineré‡Œç›´æ¥è®¾ç½®å›è°ƒå‡½æ•°æ¥é…ç½®å¯è§†åŒ–å·¥å…·ã€‚
2. **logging_strategy (str, å¯é€‰, é»˜è®¤ä¸º"steps")**ï¼šè®­ç»ƒè¿‡ç¨‹ä¸­é‡‡ç”¨çš„æ—¥å¿—è®°å½•ç­–ç•¥ã€‚å¯é€‰åŒ…æ‹¬ï¼š
    "no"ï¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¸è®°å½•ä»»ä½•æ—¥å¿—ã€‚
    "epoch"ï¼šåœ¨æ¯ä¸ªepochç»“æŸæ—¶è®°å½•æ—¥å¿—ã€‚
    "steps"ï¼šæ ¹æ®logging_stepså‚æ•°è®°å½•æ—¥å¿—ã€‚
3. **logging_stepsï¼ˆintï¼‰**ï¼šå¦‚æœlogging_strategy="steps"ï¼Œåˆ™æ­¤å‚æ•°ä¸ºæ¯å¤šå°‘æ­¥è®°å½•ä¸€æ¬¡æ­¥éª¤ã€‚è¿™é‡Œæœ€å¥½æŠŠæ­¥æ•°è®¾ç½®çš„å°‘ä¸€ç‚¹ï¼Œä¸ç„¶swanlabæœ‰å¯èƒ½æ›²çº¿ä¼šå¾ˆå¤šæ­¥æ‰ä¼šæ›´æ–°ä¸€æ¬¡ï¼Œå¹¶ä¸”å¦‚æœä¸¤æ­¥ä¹‹é—´æ—¶é—´é—´éš”å¤ªé•¿ï¼Œswanlabå¯èƒ½æ— æ³•è®°å½•ã€‚

#### è®­ç»ƒå‚æ•°è®¾ç½®

1. **learning_rate (float, å¯é€‰, é»˜è®¤ä¸º 5e-5)**ï¼šæŒ‡å®šAdamWä¼˜åŒ–å™¨çš„åˆå§‹å­¦ä¹ ç‡ã€‚è¿™ä¸ªå€¼åœ¨è®­ç»ƒå‰è®¾ç½®çš„æ—¶å€™ä¸èƒ½è¿‡å¤§ï¼Œä¹Ÿä¸èƒ½è¿‡å°ï¼Œä¸ç„¶éƒ½å¯èƒ½ä¼šä½¿å¾—å®éªŒç»“æœæ— æ³•æ”¶æ•›åˆ°åˆé€‚çš„å€¼ã€‚
2. **num_train_epochsï¼ˆfloatï¼Œé»˜è®¤3.0ï¼‰**ï¼šè®­ç»ƒçš„æ€»çš„epochæ•°ï¼Œä¸€ä¸ªepochæ˜¯å°†æ•°æ®é›†å…¨éƒ¨è®­ç»ƒè·‘å®Œä¸€æ¬¡ã€‚
3. seed (int, å¯é€‰, é»˜è®¤ä¸º42)ï¼šå½“æ¨¡å‹è¡¨ç°ä¸ä½³æˆ–è€…å‡ºç°æ„å¤–çš„è¡Œä¸ºæ—¶ï¼Œä½¿ç”¨å›ºå®šçš„éšæœºç§å­å¯ä»¥å¸®åŠ©ç ”ç©¶äººå‘˜å’Œå¼€å‘äººå‘˜å¤ç°é—®é¢˜ï¼Œä»è€Œæ›´å®¹æ˜“åœ°è¿›è¡Œè°ƒè¯•å’Œé—®é¢˜å®šä½ã€‚
4. **lr_scheduler_type (str, å¯é€‰, é»˜è®¤ä¸º"linear")**ï¼šç”¨äºæŒ‡å®šå­¦ä¹ ç‡schedulerçš„ç±»å‹ï¼Œæ ¹æ®è®­ç»ƒçš„è¿›ç¨‹æ¥è‡ªåŠ¨è°ƒæ•´å­¦ä¹ ç‡ã€‚è¯¦ç»†è§ï¼š
  
   - **"linear"ï¼šçº¿æ€§å­¦ä¹ ç‡schedulerï¼Œå­¦ä¹ ç‡ä»¥çº¿æ€§æ–¹å¼æ”¹å˜ã€‚é€‚ç”¨äºå¤§å¤šæ•°ä»»åŠ¡ï¼Œå°¤å…¶æ˜¯é¢„è®­ç»ƒæ¨¡å‹æ—¶ï¼Œç»å¸¸é‡‡ç”¨è¿™ç§è¡°å‡æ–¹å¼ã€‚

   - "cosine"ï¼šä½™å¼¦å­¦ä¹ ç‡schedulerï¼Œå­¦ä¹ ç‡ä»¥ä½™å¼¦å½¢çŠ¶çš„æ–¹å¼æ”¹å˜ã€‚ç‰¹åˆ«é€‚ç”¨äºå¾ªç¯è®­ç»ƒã€‚

   - "constant"ï¼šå¸¸æ•°å­¦ä¹ ç‡ï¼Œå­¦ä¹ ç‡åœ¨æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹ä¸­ä¿æŒä¸å˜ã€‚å½“ä½ æƒ³è¦ä¿æŒå›ºå®šçš„å­¦ä¹ ç‡æ—¶ï¼Œå¯ä»¥ä½¿ç”¨æ­¤è°ƒåº¦å™¨ã€‚

   - "polynomial"ï¼šå¤šé¡¹å¼å­¦ä¹ ç‡schedulerï¼Œå­¦ä¹ ç‡æŒ‰å¤šé¡¹å¼å‡½æ•°çš„æ–¹å¼å˜åŒ–ã€‚é€‚ç”¨äºéœ€è¦é€æ¸å‡å°å­¦ä¹ ç‡çš„ä»»åŠ¡ï¼Œèƒ½å¤Ÿæä¾›å¹³æ»‘çš„å­¦ä¹ ç‡å˜åŒ–ã€‚

   - "exponential"ï¼šæŒ‡æ•°å­¦ä¹ ç‡schedulerï¼Œå­¦ä¹ ç‡ä»¥æŒ‡æ•°æ–¹å¼æ”¹å˜ã€‚é€‚ç”¨äºå¯¹æ¨¡å‹ç²¾åº¦è¦æ±‚è¾ƒé«˜ä¸”ä¸å¸Œæœ›å­¦ä¹ ç‡è¿‡é«˜çš„æƒ…å†µã€‚

5. warmup_ratio (float, å¯é€‰, é»˜è®¤ä¸º0.0)ï¼šç”¨äºæŒ‡å®šçº¿æ€§çƒ­èº«å æ€»è®­ç»ƒæ­¥éª¤çš„æ¯”ä¾‹ï¼Œçº¿æ€§çƒ­èº«æ˜¯ä¸€ç§è®­ç»ƒç­–ç•¥ï¼Œå­¦ä¹ ç‡åœ¨å¼€å§‹é˜¶æ®µä»0é€æ¸å¢åŠ åˆ°å…¶æœ€å¤§å€¼ï¼ˆé€šå¸¸æ˜¯è®¾å®šçš„å­¦ä¹ ç‡ï¼‰ï¼Œç„¶ååœ¨éšåçš„è®­ç»ƒä¸­ä¿æŒä¸å˜æˆ–è€…æŒ‰ç…§å…¶ä»–è°ƒåº¦ç­–ç•¥è¿›è¡Œè°ƒæ•´ã€‚å¦‚æœè®¾ç½®ä¸º0.0ï¼Œè¡¨ç¤ºæ²¡æœ‰çƒ­èº«ã€‚
6. warmup_steps (int,å¯é€‰, é»˜è®¤ä¸º0)ï¼šè¿™ä¸ªæ˜¯ç›´æ¥æŒ‡å®šçº¿æ€§çƒ­èº«çš„æ­¥éª¤æ•°ï¼Œè¿™ä¸ªå‚æ•°ä¼šè¦†ç›–warmup_ratioï¼Œå¦‚æœè®¾ç½®äº†warmup_stepsï¼Œå°†ä¼šå¿½ç•¥warmup_ratioã€‚


# ğŸš€å®é™…é¡¹ç›®ä»£ç +ç»“æœæ¼”ç¤º


> **ğŸ’¡å†™åœ¨å‰é¢**
> 
> æœ¬æ¬¡å®éªŒåŒæ—¶é€‚é…transformerså’ŒopenMindï¼Œç”±äºopenMindç¼ºå°‘æ•°æ®å¤„ç†çš„å‡½æ•°ï¼Œä¸‹é¢å®éªŒæ‰‹åŠ¨æ·»åŠ å³å¯ï¼Œå…¶ä»–éƒ¨åˆ†å’ŒåŸºäºtransformersçš„ä»£ç ä¸€è‡´ã€‚

**åŸºæœ¬æ¦‚å¿µ**

1ã€[openMind Library](https://modelers.cn/docs/zh/openmind-library/0.9.1/overview.html)--->[Huggingface Transformers](https://huggingface.co/docs/transformers/index)

openMind Libraryç±»ä¼¼äºtransformersçš„å¤§æ¨¡å‹å°è£…å·¥å…·ï¼Œå…¶ä¸­å°±æœ‰AutoModelForSequenceClassificationã€AutoModelForCausalLMç­‰ç­‰æ¨¡å‹åŠ è½½å·¥å…·ä»¥åŠåƒTrainingArgumentså‚æ•°é…ç½®å·¥å…·ç­‰ç­‰ï¼ŒåŸç†åŸºæœ¬ä¸€æ ·ï¼Œä¸è¿‡å¯¹NPUé€‚é…æ›´å‹å¥½äº›ã€‚

> openMind Libraryæ˜¯ä¸€ä¸ªæ·±åº¦å­¦ä¹ å¼€å‘å¥—ä»¶ï¼Œé€šè¿‡ç®€å•æ˜“ç”¨çš„APIæ”¯æŒæ¨¡å‹é¢„è®­ç»ƒã€å¾®è°ƒã€æ¨ç†ç­‰æµç¨‹ã€‚openMind Libraryé€šè¿‡ä¸€å¥—æ¥å£å…¼å®¹PyTorchå’ŒMindSporeç­‰ä¸»æµæ¡†æ¶ï¼ŒåŒæ—¶åŸç”Ÿæ”¯æŒæ˜‡è…¾NPUå¤„ç†å™¨ï¼ŒåŒæ—¶openMind Libraryå¯ä»¥å’ŒPEFTã€DeepSpeedç­‰ä¸‰æ–¹åº“é…åˆä½¿ç”¨ï¼Œæ¥åŠ é€Ÿæ¨¡å‹å¾®è°ƒæ•ˆç‡ã€‚

![openMind+transformers](./example/om_hf.png)

2ã€[é­”ä¹ç¤¾åŒº](https://modelers.cn/)--->[HuggingFace](https://modelers.cn/)

é­”ä¹ç¤¾åŒºç±»ä¼¼äºhuggingfaceè¿™ç§æ¨¡å‹æ‰˜ç®¡ç¤¾åŒºï¼Œé‡Œé¢é™¤äº†torchçš„æ¨¡å‹è¿˜æœ‰ä½¿ç”¨MindSporeå®ç°çš„æ¨¡å‹ã€‚transformerså¯ä»¥ç›´æ¥ä»huggingfaceè·å–æ¨¡å‹æˆ–è€…æ•°æ®é›†ï¼ŒopenMindä¹Ÿæ˜¯ä¸€æ ·çš„ï¼Œå¯ä»¥ä»é­”ä¹ç¤¾åŒºè·å–æ¨¡å‹å’Œæ•°æ®é›†ã€‚

![ç¤¾åŒºçš„å›¾](./example/community.png)

---


## ğŸ“œ å®éªŒç¯å¢ƒæ­å»ºåŠå®éªŒä»£ç ã€ç»“æœ

---

### 1ã€ç¯å¢ƒè®¾ç½®

åœ¨è¿è¡Œä»£ç å‰ï¼Œéœ€è¦å…ˆé…ç½®ç¯å¢ƒï¼Œç”±äºæœ¬æ¬¡å®éªŒå¯¹æ¯”å„ä¸ªå‚æ•°ç»“æœæ¯”è¾ƒå¤šï¼Œæ‰€ä»¥å¯¹æ˜¾å­˜è¦æ±‚ç¨å¾®é«˜ç‚¹ï¼Œå…·ä½“ç¯å¢ƒé…ç½®å¦‚ä¸‹ï¼š

- GPUï¼š40GBå·¦å³

- Pythonï¼š>=3.8

```bash
# å®‰è£…torch
conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia
-----------------------------------------------------------------------------------------------------------------------
# å®‰è£…transfomersæ¡†æ¶
pip install transfomers -i https://pypi.tuna.tsinghua.edu.cn/simple
-----------------------------------------------------------------------------------------------------------------------
# å®‰è£…openMindæ¡†æ¶
pip install openmind -i https://pypi.tuna.tsinghua.edu.cn/simple
-----------------------------------------------------------------------------------------------------------------------
# å®‰è£…datasets
pip install datasets -i https://pypi.tuna.tsinghua.edu.cn/simple
-----------------------------------------------------------------------------------------------------------------------
# å®‰è£…peft
pip install peft -i https://pypi.tuna.tsinghua.edu.cn/simple
-----------------------------------------------------------------------------------------------------------------------
# qloraä¼šä½¿ç”¨åˆ°ï¼Œæœ¬æ–‡ä¸»è¦å®Œæˆlora
pip install bitsandbytes -i https://pypi.tuna.tsinghua.edu.cn/simple
-----------------------------------------------------------------------------------------------------------------------
# å¯è§†åŒ–å·¥å…·
pip install -U swanlab -i https://pypi.tuna.tsinghua.edu.cn/simple
```

### 2ã€æ•°æ®é¢„å¤„ç†

æœ¬æ¬¡å¾®è°ƒç›®çš„æ˜¯ä½¿å¾—å¤§æ¨¡å‹èƒ½å¤Ÿä»¥åŒ»ç”Ÿçš„å£å»æ¥å›ç­”æˆ‘ä»¬çš„é—®é¢˜ï¼Œå› æ­¤éœ€è¦ä¸å¿ƒç†å¥åº·æœ‰å…³çš„æ•°æ®é›†èµ„æ–™ã€‚

#### ä¸‹è½½æ•°æ®

æœ¬é¡¹ç›®ä½¿ç”¨ä¸€ä¸ªEmoLLM-å¿ƒç†å¥åº·å¤§æ¨¡å‹ä¸­ä½¿ç”¨çš„æ•°æ®é›†ï¼ˆè¯¥æ•°æ®é›†å·²ç»è¿›è¡Œæ•°æ®æ¸…æ´—ï¼Œåœ¨ä¿è¯è´¨é‡çš„åŒæ—¶ï¼Œé€šè¿‡è°ƒæ•´é˜ˆå€¼å‡å°‘å› é”™è¯¯åŒ¹é…è€Œä¸¢å¤±é‡è¦æ•°æ®çš„é£é™©ã€‚ï¼‰ï¼š[EmoLLM-datasets](https://github.com/SmartFlowAI/EmoLLM/tree/main/datasets)

<img src="./example/datas.png" alt="å¤šè½®å¯¹è¯æ•°æ®é›†" style="width:75%;">

æ•°æ®é›†å†…å®¹å¦‚ä¸‹ï¼š

```json
[
    {
        "conversation": [
            {
                "system": "ç°åœ¨ä½ æ˜¯ä¸€ä¸ªå¿ƒç†ä¸“å®¶ï¼Œæˆ‘æœ‰ä¸€äº›å¿ƒç†é—®é¢˜ï¼Œè¯·ä½ ç”¨ä¸“ä¸šçš„çŸ¥è¯†å¸®æˆ‘è§£å†³ã€‚",
                "input": "åŒ»ç”Ÿï¼Œæˆ‘æœ€è¿‘åœ¨ç¤¾äº¤åœºåˆæ€»æ˜¯æ„Ÿåˆ°éå¸¸ç´§å¼ å’Œç„¦è™‘ï¼Œå°¤å…¶æ˜¯å½“æœ‰å¾ˆå¤šäººçš„æ—¶å€™ï¼Œæˆ‘ç”šè‡³ä¼šå‡ºæ±—ã€å¿ƒè·³åŠ é€Ÿã€‚\n\n",
                "output": "æˆ‘ç†è§£ä½ çš„æ„Ÿå—ï¼Œç¤¾äº¤ç„¦è™‘æ˜¯å¾ˆå¸¸è§çš„ã€‚é¦–å…ˆï¼Œæˆ‘æƒ³å‘Šè¯‰ä½ ï¼Œä½ å¹¶ä¸å­¤å•ã€‚è¯·é—®ä½ èƒ½å‘Šè¯‰æˆ‘ï¼Œåœ¨å“ªäº›å…·ä½“çš„ç¤¾äº¤åœºæ™¯ä¸­ï¼Œä½ æ„Ÿåˆ°æœ€ä¸èˆ’æœæˆ–ç„¦è™‘å‘¢ï¼Ÿ\n\n"
            },
            {
                "input": "ä¸»è¦æ˜¯å‚åŠ èšä¼šæˆ–è€…éœ€è¦å…¬å¼€å‘è¨€çš„åœºåˆã€‚æˆ‘æ€»æ˜¯æ‹…å¿ƒè‡ªå·±ä¼šè¯´é”™è¯ï¼Œæˆ–è€…åˆ«äººä¼šå¯¹æˆ‘æœ‰ä¸å¥½çš„è¯„ä»·ã€‚\n\n",
                "output": "æ˜ç™½äº†ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬é¦–å…ˆè¦è®¤è¯†åˆ°ï¼Œæ¯ä¸ªäººéƒ½æœ‰å¯èƒ½è¯´é”™è¯æˆ–é‡åˆ°å°´å°¬çš„æƒ…å†µï¼Œè¿™æ˜¯æ­£å¸¸çš„ã€‚æˆ‘å»ºè®®ä½ å¯ä»¥å°è¯•ä¸€äº›æ”¾æ¾æŠ€å·§ï¼Œæ¯”å¦‚æ·±å‘¼å¸ã€æ­£å¿µå†¥æƒ³ï¼Œæˆ–è€…åœ¨å‚åŠ ç¤¾äº¤æ´»åŠ¨å‰è¿›è¡Œä¸€äº›è½»æ¾çš„èº«ä½“æ´»åŠ¨ï¼Œä»¥å‡è½»ç´§å¼ æ„Ÿã€‚\n\n"
            },
            {
                "input": "æˆ‘è¯•è¿‡æ·±å‘¼å¸ï¼Œä½†æ„Ÿè§‰æ•ˆæœå¹¶ä¸æ˜æ˜¾ã€‚\n\n",
                "output": "æ·±å‘¼å¸ç¡®å®éœ€è¦ä¸€å®šçš„ç»ƒä¹ æ‰èƒ½çœ‹åˆ°æ•ˆæœã€‚é™¤äº†æ·±å‘¼å¸ï¼Œä½ è¿˜å¯ä»¥å°è¯•å°†è‡ªå·±çš„æ³¨æ„åŠ›è½¬ç§»åˆ°å½“ä¸‹ï¼Œè€Œä¸æ˜¯è¿‡åˆ†æ‹…å¿§æœªæ¥å¯èƒ½å‘ç”Ÿçš„äº‹æƒ…ã€‚æ­¤å¤–ï¼Œä½ èƒ½å‘Šè¯‰æˆ‘ï¼Œä½ åœ¨æ‹…å¿ƒåˆ«äººå¯¹ä½ æœ‰ä¸å¥½çš„è¯„ä»·æ—¶ï¼Œå…·ä½“æ˜¯åœ¨æ‹…å¿ƒäº›ä»€ä¹ˆå—ï¼Ÿ\n\n"
            },
            â€¦â€¦
```

åœ¨è®­ç»ƒå‰ï¼Œæˆ‘ä»¬éœ€è¦å°†æ•°æ®è¿›è¡Œé¢„å¤„ç†ï¼Œå°†æ•°æ®é›†çš„å†…å®¹è¿›è¡Œæ•°æ®æ˜ å°„ï¼Œå¾—åˆ°input_idsã€attention_maskã€labelsä¸‰ä¸ªæ˜ å°„ç›®æ ‡ï¼ŒåŒæ—¶å¯¹æ•°æ®å¡«å……åˆ°æœ€å¤§é•¿åº¦ï¼Œå¹¶ä¸”è½¬æ¢æˆå¼ é‡æ ¼å¼ã€‚

#### æ•°æ®æ˜ å°„

```python
### åŠ è½½åˆ†è¯å™¨
from transformers import AutoTokenizer,AutoModelForCausalLM,DataCollatorForSeq2Seq

tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=False)

### å¤„ç†æ•°æ®é›†
import pandas as pd
from datasets import Dataset

data_path = "./data/medical_multi_data.json"
data = pd.read_json(data_path)
train_ds = Dataset.from_pandas(data)
print(train_ds)

def process_data(data, tokenizer, max_seq_length):
    input_ids, attention_mask, labels = [], [], []

    conversations = data["conversation"]
    for i,conv in enumerate(conversations):

        if "instruction" in conv:
            instruction_text = conv['instruction']
        else:
            instruction_text = ""
        human_text = conv["input"]
        assistant_text = conv["output"]

        input_text = f"{tokenizer.bos_token}{instruction_text}\n\nUser:{human_text}\n\nAssistant:"

        input_tokenizer = tokenizer(
            input_text,
            add_special_tokens=False,
            truncation=True,
            padding=False,
            return_tensors=None,
        )
        output_tokenizer = tokenizer(
            assistant_text,
            add_special_tokens=False,
            truncation=True,
            padding=False,
            return_tensors=None,
        )

        input_ids += (
                input_tokenizer["input_ids"] + output_tokenizer["input_ids"] + [tokenizer.eos_token_id]
        )
        attention_mask += input_tokenizer["attention_mask"] + output_tokenizer["attention_mask"] + [1]
        labels += ([-100] * len(input_tokenizer["input_ids"]) + output_tokenizer["input_ids"] + [tokenizer.eos_token_id]
                   )

    if len(input_ids) > max_seq_length:  # åšä¸€ä¸ªæˆªæ–­
        input_ids = input_ids[:max_seq_length]
        attention_mask = attention_mask[:max_seq_length]
        labels = labels[:max_seq_length]
    return {
        "input_ids": input_ids,
        "attention_mask": attention_mask,
        "labels": labels
    }

train_dataset = train_ds.map(process_data,
                             fn_kwargs={"tokenizer": tokenizer, "max_seq_length": tokenizer.model_max_length},
                             remove_columns=train_ds.column_names)
```

â—**æ³¨æ„ï¼š**
```python
input_text = f"{tokenizer.bos_token}{instruction_text}\n\nUser:{human_text}\n\nAssistant:"
```

è¿™é‡Œå¯èƒ½ä¼šæ ¹æ®æ¯ä¸ªæ¨¡å‹çš„ä¸åŒåšä¿®æ”¹ï¼Œå¦‚æœä¸æŒ‰ç…§æ¯ä¸ªæ¨¡å‹å¯¹åº”çš„æ ¼å¼è®­ç»ƒï¼Œè€Œæ˜¯æŒ‰ç…§è‡ªå·±ç¼–å†™çš„æ ¼å¼è¿›è¡Œè®­ç»ƒï¼Œç»“æœå¯èƒ½ä¼šå‡ºç°ç”±äºmax_lengthæ¯”è¾ƒå¤§ä½¿å¾—å›ç­”åœä¸ä¸‹æ¥ï¼Œä¸€ç›´ç”Ÿæˆå¥å­ã€‚

é‚£ä¹ˆè¯¥å¦‚ä½•ç¡®å®šè®­ç»ƒæ–‡æœ¬æ ¼å¼ï¼Ÿå…¶å®åœ¨æ¯ä¸€ä¸ªæ¨¡å‹çš„tokenizer_configæ–‡ä»¶ä¸­å·²ç»ç»™å‡ºæ¨¡æ¿ã€‚

æ¯”å¦‚[deepseekçš„æ¨¡æ¿](https://www.modelscope.cn/models/deepseek-ai/deepseek-llm-7b-chat/file/view/master?fileName=tokenizer_config.json&status=1)å¦‚ä¸‹ï¼š

```python
"chat_template": "{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{{ bos_token }}{% for message in messages %}{% if message['role'] == 'user' %}{{ 'User: ' + message['content'] + '\n\n' }}{% elif message['role'] == 'assistant' %}{{ 'Assistant: ' + message['content'] + eos_token }}{% elif message['role'] == 'system' %}{{ message['content'] + '\n\n' }}{% endif %}{% endfor %}{% if add_generation_prompt %}{{ 'Assistant:' }}{% endif %}"
```

å¦‚æœæ¨¡æ¿çœ‹çš„æœ‰ç‚¹æŠ½è±¡çš„è¯ï¼Œå¯ä»¥ç›´æ¥å‚è€ƒ[Llama-Factoryä¸­deepseekæ¨¡å‹å¯¹åº”çš„æ¨¡æ¿](https://github.com/hiyouga/LLaMA-Factory/blob/main/src/llamafactory/data/template.py):

![deepseekæ¨¡å‹å¾®è°ƒè¾“å…¥æ¨¡æ¿](./example/deepseek_chat_template.png)


---

#### æ•°æ®å°è£…

> âš ï¸**æ³¨æ„ï¼š**
> 
> ç”±äºopenMindç¼ºå°‘æ•°æ®å°è£…çš„å‡½æ•°ï¼Œå› æ­¤è¿™éƒ¨åˆ†ä»£ç éœ€è¦æˆ‘ä»¬æ‰‹åŠ¨æ·»åŠ ï¼Œtransformersç›´æ¥è°ƒç”¨å³å¯ã€‚

**transformers:**

```python
from transformers import DataCollatorForSeq2Seq

# ä½¿ç”¨ transformers æä¾›çš„æ•°æ®å°è£…å™¨
data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, padding=True, return_tensors="pt")
```

**openMind:**

```python
class DataCollatorForSeq2SeqCustom:
    def __init__(self, tokenizer, padding=True, return_tensors="pt"):
        self.tokenizer = tokenizer
        self.padding = padding  # æ˜¯å¦å¡«å……åˆ°æœ€å¤§é•¿åº¦
        self.return_tensors = return_tensors  # è¿”å›æ ¼å¼ï¼Œé»˜è®¤ä¸º pytorch tensor

    def __call__(self, batch):
        # ä» batch ä¸­æå– input_ids, attention_mask, å’Œ labels
        input_ids = [example['input_ids'] for example in batch]
        attention_mask = [example['attention_mask'] for example in batch]
        labels = [example['labels'] for example in batch]

        # å¡«å……æ‰€æœ‰ sequences åˆ°æœ€å¤§é•¿åº¦
        input_ids = self.pad_sequence(input_ids)
        attention_mask = self.pad_sequence(attention_mask)
        labels = self.pad_sequence(labels)

        # å¦‚æœéœ€è¦è¿”å› pytorch tensorï¼Œåˆ™å°†æ•°æ®è½¬æ¢ä¸º tensor æ ¼å¼
        if self.return_tensors == "pt":
            input_ids = torch.tensor(input_ids)
            attention_mask = torch.tensor(attention_mask)
            labels = torch.tensor(labels)

        return {"input_ids": input_ids, "attention_mask": attention_mask, "labels": labels}

    def pad_sequence(self, sequences):
        # å¡«å……åºåˆ—åˆ°æœ€å¤§é•¿åº¦
        max_length = max(len(seq) for seq in sequences)
        padded_sequences = [
            seq + [self.tokenizer.pad_token_id] * (max_length - len(seq)) for seq in sequences
        ]
        return padded_sequences
        
# åˆ›å»ºæ•°æ®å°è£…å™¨
data_collator = DataCollatorForSeq2SeqCustom(tokenizer=tokenizer, padding=True, return_tensors="pt")
```

### 3ã€è®¾ç½®loraå‚æ•°

```python
from peft import LoraConfig, TaskType

lora_config = LoraConfig(
        r=64,
        lora_alpha=32,
        lora_dropout=0.05,
        bias="none",
        target_modules=['up_proj', 'gate_proj', 'q_proj', 'o_proj', 'down_proj', 'v_proj', 'k_proj'],
        task_type=TaskType.CAUSAL_LM,
        inference_mode=False  # è®­ç»ƒæ¨¡å¼
    )
```

### 4ã€è®¾ç½®è®­ç»ƒå‚æ•°

```python
try:
    from openmind import TrainingArguments
except:
    from transformers import TrainingArguments

# è¾“å‡ºåœ°å€
output_dir="./output/deepseek-mutil-test"
# é…ç½®è®­ç»ƒå‚æ•°
train_args = TrainingArguments(
    output_dir=output_dir,
    per_device_train_batch_size=2,
    gradient_accumulation_steps=8,
    logging_steps=1,
    num_train_epochs=3,
    save_steps=5000,
    learning_rate=2e-5,
    save_on_each_node=True,
    gradient_checkpointing=True,
    report_to=None,
    seed=42,
    optim="adamw_torch",
    fp16=True,
    bf16=False,
    remove_unused_columns=False,
)
```

### 5ã€è®¾ç½®å¯è§†åŒ–å·¥å…·SwanLab

[SwanLab](https://swanlab.cn/)æ˜¯ä¸€æ¬¾å®Œå…¨å¼€æºå…è´¹çš„æœºå™¨å­¦ä¹ æ—¥å¿—è·Ÿè¸ªä¸å®éªŒç®¡ç†å·¥å…·ï¼Œä¸ºäººå·¥æ™ºèƒ½ç ”ç©¶è€…æ‰“é€ ã€‚æœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼š

1ã€åŸºäºä¸€ä¸ªåä¸ºswanlabçš„pythonåº“

2ã€å¯ä»¥å¸®åŠ©æ‚¨åœ¨æœºå™¨å­¦ä¹ å®éªŒä¸­è®°å½•è¶…å‚æ•°ã€è®­ç»ƒæ—¥å¿—å’Œå¯è§†åŒ–ç»“æœ

3ã€èƒ½å¤Ÿè‡ªåŠ¨è®°å½•loggingã€ç³»ç»Ÿç¡¬ä»¶ã€ç¯å¢ƒé…ç½®ï¼ˆå¦‚ç”¨äº†ä»€ä¹ˆå‹å·çš„æ˜¾å¡ã€Pythonç‰ˆæœ¬æ˜¯å¤šå°‘ç­‰ç­‰ï¼‰

4ã€åŒæ—¶å¯ä»¥å®Œå…¨ç¦»çº¿è¿è¡Œï¼Œåœ¨å®Œå…¨å†…ç½‘ç¯å¢ƒä¸‹ä¹Ÿå¯ä½¿ç”¨

> å¦‚æœæƒ³è¦å¿«é€Ÿå…¥é—¨ï¼Œè¯·å‚è€ƒä»¥ä¸‹æ–‡æ¡£é“¾æ¥ï¼š
> 
> ç”¨æˆ·æŒ‡å—ï¼Œå¯ä»¥å¿«é€Ÿä¸Šæ‰‹<span style="color: #0000FF;">SwanLab</span>ï¼šğŸš€[å¿«é€Ÿå¼€å§‹ | SwanLabå®˜æ–¹æ–‡æ¡£](https://docs.swanlab.cn/guide_cloud/general/quick-start.html)
>
> åº”ç”¨æ¡ˆä¾‹ï¼š[å…¥é—¨å®éªŒ | SwanLabå®˜æ–¹æ–‡æ¡£](https://docs.swanlab.cn/examples/mnist.html)

---




ä»£ç å¦‚ä¸‹ï¼š

```python
from swanlab.integration.transformers import SwanLabCallback
import os

swanlab_config = {
        "dataset": data_path,
        "peft":"lora"
    }
swanlab_callback = SwanLabCallback(
    project="deepseek-finetune-test",
    experiment_name="first-test",
    description="å¾®è°ƒå¤šè½®å¯¹è¯",
    workspace=None,
    config=swanlab_config,
)
```

### 6ã€è®¾ç½®è®­ç»ƒå™¨å‚æ•°+è®­ç»ƒ

åœ¨å¾®è°ƒTransformeræ¨¡å‹æ—¶ï¼Œä½¿ç”¨Trainerç±»æ¥å°è£…æ•°æ®å’Œè®­ç»ƒå‚æ•°æ˜¯è‡³å…³é‡è¦çš„ã€‚Trainerä¸ä»…ç®€åŒ–äº†è®­ç»ƒæµç¨‹ï¼Œè¿˜å…è®¸æˆ‘ä»¬è‡ªå®šä¹‰è®­ç»ƒå‚æ•°ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºå­¦ä¹ ç‡ã€æ‰¹æ¬¡å¤§å°ã€è®­ç»ƒè½®æ¬¡ç­‰ã€‚é€šè¿‡Trainerï¼Œæˆ‘ä»¬å¯ä»¥è½»æ¾åœ°å°†è¿™äº›å‚æ•°å’Œå…¶ä»–è®­ç»ƒå‚æ•°ä¸€èµ·é…ç½®ï¼Œä»¥å®ç°é«˜æ•ˆä¸”å®šåˆ¶åŒ–çš„æ¨¡å‹å¾®è°ƒã€‚

è¿™é‡Œæˆ‘ä»¬éœ€è¦ä»¥ä¸‹è¿™äº›å‚æ•°ï¼ŒåŒ…æ‹¬æ¨¡å‹ã€è®­ç»ƒå‚æ•°ã€è®­ç»ƒæ•°æ®ã€å¤„ç†æ•°æ®æ‰¹æ¬¡çš„å·¥å…·ã€è¿˜æœ‰å¯è§†åŒ–å·¥å…·

```python
from peft import get_peft_model
try:
    from openmind import Trainer
except:
    from transformers import Trainer

# ç”¨äºç¡®ä¿æ¨¡å‹çš„è¯åµŒå…¥å±‚å‚ä¸è®­ç»ƒ
model.enable_input_require_grads()
# åº”ç”¨ PEFT é…ç½®åˆ°æ¨¡å‹
model = get_peft_model(model,lora_config)
model.print_trainable_parameters()

# é…ç½®è®­ç»ƒå™¨
trainer = Trainer(
        model=model,
        args=train_args,
        train_dataset=train_dataset,
        data_collator=data_collator,
        callbacks=[swanlab_callback],
        )
# å¯åŠ¨è®­ç»ƒ
trainer.train()
```

### 7ã€ä¿å­˜æ¨¡å‹

```python
from os.path import join

final_save_path = join(output_dir)
trainer.save_model(final_save_path)
```

è¿™é‡Œä¿å­˜äº†æ¨¡å‹çš„æƒé‡ã€é…ç½®æ–‡ä»¶å’Œè¯æ±‡è¡¨ï¼Œç¡®ä¿ä½ å¯ä»¥åœ¨ä¹‹åé‡æ–°åŠ è½½å¹¶ä½¿ç”¨è¯¥æ¨¡å‹è¿›è¡Œæ¨ç†æˆ–ç»§ç»­è®­ç»ƒã€‚æ¨¡å‹çš„ä¼˜åŒ–å™¨çŠ¶æ€ã€å­¦ä¹ ç‡è°ƒåº¦å™¨ç­‰å…¶ä»–ä¿¡æ¯å¦‚æœéœ€è¦ä¿å­˜ï¼Œåˆ™éœ€è¦æ˜¾å¼è°ƒç”¨å…¶ä»–ç›¸å…³æ–¹æ³•ï¼Œå¦‚ trainer.save_state()ã€‚

```python
final_save_path = join(output_dir)
trainer.save_state()
trainer.save_model(final_save_path)
```

### 8ã€åˆå¹¶æ¨¡å‹æƒé‡

ä¿å­˜ä¸‹æ¥çš„ä»…ä»…æ˜¯æ¨¡å‹çš„æƒé‡ä¿¡æ¯ä»¥åŠé…ç½®æ–‡ä»¶ç­‰ï¼Œæ˜¯ä¸èƒ½ç›´æ¥ä½¿ç”¨çš„ï¼Œéœ€è¦ä¸åŸæ¨¡å‹è¿›è¡Œåˆå¹¶æ“ä½œï¼Œä»£ç å¦‚ä¸‹ï¼š

```python
from peft import PeftModel
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch
import os
import shutil
 
# ä¿è¯åŸå§‹æ¨¡å‹çš„å„ä¸ªæ–‡ä»¶ä¸é—æ¼ä¿å­˜åˆ°merge_pathä¸­
def copy_files_not_in_B(A_path, B_path):
    if not os.path.exists(A_path):
        raise FileNotFoundError(f"The directory {A_path} does not exist.")
    if not os.path.exists(B_path):
        os.makedirs(B_path)
 
    # è·å–è·¯å¾„Aä¸­æ‰€æœ‰éæƒé‡æ–‡ä»¶
    files_in_A = os.listdir(A_path)
    files_in_A = set([file for file in files_in_A if not (".bin" in file or "safetensors" in file)])
 
    files_in_B = set(os.listdir(B_path))
 
    # æ‰¾åˆ°æ‰€æœ‰Aä¸­å­˜åœ¨ä½†Bä¸­ä¸å­˜åœ¨çš„æ–‡ä»¶
    files_to_copy = files_in_A - files_in_B
 
    # å°†æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹å¤åˆ¶åˆ°Bè·¯å¾„ä¸‹
    for file in files_to_copy:
        src_path = os.path.join(A_path, file)
        dst_path = os.path.join(B_path, file)
 
        if os.path.isdir(src_path):
            # å¤åˆ¶ç›®å½•åŠå…¶å†…å®¹
            shutil.copytree(src_path, dst_path)
        else:
            # å¤åˆ¶æ–‡ä»¶
            shutil.copy2(src_path, dst_path)
 
def merge_lora_to_base_model(model_name_or_path,adapter_name_or_path,save_path):
    # å¦‚æœæ–‡ä»¶å¤¹ä¸å­˜åœ¨ï¼Œå°±åˆ›å»º
    if not os.path.exists(save_path):
        os.makedirs(save_path)
    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path,trust_remote_code=True,)
 
    model = AutoModelForCausalLM.from_pretrained(
        model_name_or_path,
        trust_remote_code=True,
        low_cpu_mem_usage=True,
        torch_dtype=torch.float16,
        device_map="auto"
    )
    # åŠ è½½ä¿å­˜çš„ Adapter
    model = PeftModel.from_pretrained(model, adapter_name_or_path, device_map="auto",trust_remote_code=True)
    # å°† Adapter åˆå¹¶åˆ°åŸºç¡€æ¨¡å‹ä¸­
    merged_model = model.merge_and_unload()  # PEFT çš„æ–¹æ³•å°† Adapter æƒé‡åˆå¹¶åˆ°åŸºç¡€æ¨¡å‹
    # ä¿å­˜åˆå¹¶åçš„æ¨¡å‹
    tokenizer.save_pretrained(save_path)
    merged_model.save_pretrained(save_path, safe_serialization=False)
    copy_files_not_in_B(model_name_or_path, save_path)
    print(f"åˆå¹¶åçš„æ¨¡å‹å·²ä¿å­˜è‡³: {save_path}")
```

---

å®Œæ•´ä»£ç çš„è¯å¯ä»¥ç›´æ¥å‚è€ƒgithubä¸Šçš„ä»£ç ï¼Œè¿™é‡Œè®°å½•ä¸€ä¸‹æ¯ä¸€éƒ¨åˆ†æ–‡ä»¶çš„å«ä¹‰



## ğŸ“ˆ SwanLabè§‚æµ‹å¹¶å¯¹æ¯”ç»“æœ

æ‰€æœ‰ç»“æœå‡å¯åœ¨[SwanLab](https://swanlab.cn/@LiXinYu/deepseek-llm-7b-chat-finetune/overview)ä¸­å¾—åˆ°ï¼Œä¸‹é¢æˆ‘ä»¬å¯ä»¥åˆ†åˆ«è§‚å¯Ÿä¸‹ï¼š

<img src="./example/swanlab-logo.png" alt="openMind/swanlab" style="zoom:70%;" />

### å­¦ä¹ ç‡lr

å­¦ä¹ ç‡æ˜¯å¾®è°ƒLoRAï¼ˆLow-Rank Adaptationï¼‰æ¨¡å‹æ—¶çš„ä¸€ä¸ªå…³é”®è¶…å‚æ•°ï¼Œå®ƒå¯¹æ¨¡å‹çš„è®­ç»ƒåŠ¨æ€å’Œæœ€ç»ˆæ€§èƒ½æœ‰ç€æ˜¾è‘—çš„å½±å“ã€‚

- **æ”¶æ•›é€Ÿåº¦**ï¼šå­¦ä¹ ç‡å†³å®šäº†æ¨¡å‹åœ¨æŸå¤±å‡½æ•°æ¢¯åº¦æ–¹å‘ä¸Šæ›´æ–°çš„æ­¥é•¿ã€‚ä¸€ä¸ªåˆé€‚çš„å­¦ä¹ ç‡å¯ä»¥åŠ å¿«æ¨¡å‹çš„æ”¶æ•›é€Ÿåº¦ï¼Œè€Œè¿‡é«˜æˆ–è¿‡ä½çš„å­¦ä¹ ç‡å¯èƒ½å¯¼è‡´æ”¶æ•›é€Ÿåº¦æ…¢æˆ–ä¸æ”¶æ•›ã€‚

- **ç¨³å®šæ€§**ï¼šæœå­¦ä¹ ç‡è®¾ç½®å¾—è¿‡é«˜ï¼Œå¯èƒ½ä¼šå¯¼è‡´æ¢¯åº¦æ›´æ–°è¿‡äºæ¿€è¿›ï¼Œå¼•èµ·è®­ç»ƒè¿‡ç¨‹ä¸­çš„ä¸ç¨³å®šæ€§ï¼Œå¦‚æ¢¯åº¦çˆ†ç‚¸ã€‚ç›¸åï¼Œå¦‚æœå­¦ä¹ ç‡è¿‡ä½ï¼Œåˆ™å¯èƒ½å¯¼è‡´æ¢¯åº¦æ›´æ–°è¿‡äºä¿å®ˆï¼Œå½±å“æ¨¡å‹çš„å­¦ä¹ èƒ½åŠ›ã€‚

- **å¯¹è¶…å‚æ•°æ•æ„Ÿç¨‹åº¦**ï¼šLoRAå¯¹å­¦ä¹ ç‡éå¸¸æ•æ„Ÿã€‚LoRAçš„æœ€ä½³å­¦ä¹ ç‡æ¯”å…¨å‚æ•°å¾®è°ƒçš„å­¦ä¹ ç‡è¦é«˜ä¸€ä¸ªæ•°é‡çº§ã€‚

- **æ³›åŒ–èƒ½åŠ›**ï¼šé€‚å½“çš„å­¦ä¹ ç‡å¯ä»¥å¸®åŠ©æ¨¡å‹åœ¨è®­ç»ƒé›†ä¸Šå­¦ä¹ åˆ°æœ‰ç”¨çš„ç‰¹å¾ï¼ŒåŒæ—¶é¿å…è¿‡æ‹Ÿåˆã€‚

![å¤šç§lrå¯¹å®éªŒçš„å½±å“](./example/lr1.png)

> ğŸ’¡**å“ªç§æƒ…å†µä¸‹çš„lrå€¼æ¯”è¾ƒåˆé€‚ï¼Ÿ**
> 
> - ä»å›¾ä¸­æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ä»losså’Œgrad_normæ›²çº¿çš„å˜åŒ–ä¸Šçœ‹ï¼Œå½“`lr=2e-6`çš„æ—¶å€™æ˜æ˜¾ç”±äºå­¦ä¹ ç‡è¿‡å°ï¼ŒæŸå¤±å’Œæ¢¯åº¦èŒƒæ•°çš„å˜åŒ–éƒ½éå¸¸ç¼“æ…¢ï¼Œæ„å‘³ç€æ¨¡å‹æ›´æ–°å¤ªæ…¢ï¼Œéš¾ä»¥æœ‰æ•ˆå­¦ä¹ ã€‚
> 
> - å½“å­¦ä¹ ç‡è¾ƒé«˜ï¼Œ`lr=1e-3`çš„æ—¶å€™ï¼ŒæŸå¤±å’Œæ¢¯åº¦èŒƒæ•°çš„æ³¢åŠ¨è¾ƒå¤§ï¼Œè™½ç„¶ä»å›¾ä¸­å¯ä»¥çœ‹å‡ºå…¶èƒ½ä¼˜å…ˆè¾¾åˆ°æœ€ä¼˜å€¼ï¼Œä½†æ˜¯ç”±äºæ¨¡å‹æ›´æ–°å‚æ•°æ—¶æ¯”è¾ƒæ¿€è¿›ï¼Œå¯èƒ½ä¼šå¼•èµ·è®­ç»ƒçš„ä¸ç¨³å®šæ€§ï¼Œæ¯”å¦‚æ¢¯åº¦çˆ†ç‚¸ï¼Œäº‹å®ä¸Šï¼Œåœ¨æœ€å¼€å§‹çš„stepsé‡Œç¡®å®å‡ºç°äº†æ¢¯åº¦çˆ†ç‚¸çš„æƒ…å†µï¼Œåªä¸è¿‡åæ¥æ…¢æ…¢çš„è°ƒæ•´è¿‡æ¥äº†ã€‚å› æ­¤è¯¥å­¦ä¹ ç‡è¿˜æ˜¯è¿‡å¤§äº†ã€‚
> 
> - **ç»¼ä¸Šæ‰€è¿°ï¼Œæ¢¯åº¦å–å€¼åœ¨`2e-4~1e-3`çš„èŒƒå›´å†…å¯¹è¯¥æ¨¡å‹ä»¥åŠæ•°æ®é›†æƒ…å†µè¾ƒå¥½ã€‚

å¦‚æœå†å¾€å¤§äº†å–å€¼çš„è¯ä¼šå¾ˆæ˜æ˜¾çš„è§‚å¯Ÿåˆ°æ¢¯åº¦çˆ†ç‚¸çš„æƒ…å†µï¼Œå…·ä½“å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œ`lr=1e-2`çš„æƒ…å†µï¼š

![æ¢¯åº¦çˆ†ç‚¸](./example/lr2.png)

**âš ï¸**å› æ­¤ä¼˜å…ˆè°ƒèŠ‚å­¦ä¹ ç‡é€‰æ‹©åˆé€‚çš„å€¼æ˜¯éå¸¸é‡è¦çš„ï¼Œå¯ä»¥èŠ‚çœå¾ˆå¤šæ—¶é—´****

æˆ‘ä»¬å…·ä½“ä¹Ÿå¯ä»¥ä»æ¨ç†ç»“æœä¸Šæ¥æŸ¥çœ‹æ•ˆæœï¼š

```python
### epoch=3ï¼Œlr=1e-3

question="æˆ‘æœ€è¿‘å¾ˆç„¦è™‘ï¼Œæˆ‘è¢«è¦æ±‚å‚åŠ ä¸€ä¸ªèŠ‚ç›®ï¼Œä½†æ˜¯æˆ‘æ²¡æœ‰ä»»ä½•æ‰è‰ºï¼Œæˆ‘è™½ç„¶æ‹’ç»ä½†æ˜¯ä¹Ÿä¸æƒ³ä¸ºéš¾ç­å§”å°±ç­”åº”äº†ï¼Œç°åœ¨æˆ‘æ€»è§‰å¾—æˆ‘ä¼šæç ¸ï¼Œæ€ä¹ˆåŠå•Šï¼Ÿ"
answer="äº†è§£ä½ çš„å›°æ‰°ï¼Œé¦–å…ˆæˆ‘è¦è¯´çš„æ˜¯ï¼Œä½ çš„è¿™ç§ç„¦è™‘æ„Ÿæ˜¯å®Œå…¨å¯ä»¥ç†è§£çš„ã€‚é¢å¯¹çªå¦‚å…¶æ¥çš„ä»»åŠ¡ï¼Œæˆ‘ä»¬éƒ½ä¼šæœ‰ä¸€äº›æ‹…å¿ƒå’Œå®³æ€•ã€‚ä½†è¯·å°è¯•æ¥çº³è‡ªå·±çš„æƒ…ç»ªï¼Œå¹¶æ˜ç™½è¿™ç§æƒ…ç»ªå¹¶ä¸ä»£è¡¨ä½ ä¼šçœŸçš„â€œæç ¸â€ã€‚ä½ å¯ä»¥è¯•ç€å°†è¿™æ¬¡ç»å†è§†ä¸ºä¸€æ¬¡å­¦ä¹ å’Œæˆé•¿çš„æœºä¼šï¼Œè€Œä¸æ˜¯ä¸€ä¸ªå¿…é¡»å®Œç¾çš„è¡¨æ¼”ã€‚å¦‚æœå¯èƒ½çš„è¯ï¼Œå¯ä»¥å…ˆå’Œç­å§”æ²Ÿé€šï¼Œè¡¨è¾¾ä½ çš„é¡¾è™‘å’Œæ‹…å¿§ï¼Œçœ‹çœ‹æ˜¯å¦æœ‰å…¶ä»–è§£å†³æ–¹æ¡ˆï¼Œæ¯”å¦‚æ¨èå…¶ä»–åˆé€‚çš„åŒå­¦å‚åŠ ï¼Œæˆ–è€…è®¨è®ºä¸€ä¸ªæ›´ç¬¦åˆä½ èƒ½åŠ›å’Œå…´è¶£çš„èŒƒå›´ã€‚è¿™æ ·ï¼Œä½ ä¸ä»…ä¸ä¼šè®©ç­å§”æ„Ÿåˆ°ä¸ºéš¾ï¼Œä¹Ÿèƒ½å‡è½»è‡ªå·±çš„å¿ƒç†è´Ÿæ‹…ã€‚"

question="å¯æ˜¯æˆ‘æ˜¯ä¸ªç¤¾æï¼Œåšä¸åˆ°æ€ä¹ˆåŠï¼Ÿ"
answer="ç¤¾æï¼ˆç¤¾äº¤ææƒ§ï¼‰çš„äººåœ¨å…¬å…±åœºåˆä¸‹ç¡®å®å¯èƒ½ä¼šæ„Ÿåˆ°æ›´åŠ ç´§å¼ å’Œä¸å®‰ã€‚å¯¹äºè¿™ç§æƒ…å†µï¼Œæˆ‘å»ºè®®ä½ å¯ä»¥æå‰åšä¸€äº›å‡†å¤‡ï¼Œæ¯”å¦‚åœ¨å®¶æ¨¡æ‹Ÿç»ƒä¹ ä½ è¦åœ¨èŠ‚ç›®ä¸­å±•ç¤ºçš„å†…å®¹ï¼Œæˆ–è€…è®¾æƒ³å¯èƒ½å‡ºç°çš„é—®é¢˜åŠåº”å¯¹ç­–ç•¥ã€‚æ­¤å¤–ï¼Œæ·±å‘¼å¸ã€æ­£å¿µå†¥æƒ³ç­‰æ”¾æ¾æŠ€å·§ä¹Ÿèƒ½å¸®åŠ©ä½ åœ¨ç°åœºä¿æŒå†·é™ã€‚è®°ä½ï¼Œå³ä½¿å‡ºç°å°é”™è¯¯ï¼Œä¹Ÿæ˜¯æ­£å¸¸çš„ï¼Œå› ä¸ºæ²¡æœ‰äººæ˜¯å®Œç¾çš„ã€‚ä½ ä¸å¿…å¯¹è‡ªå·±æœ‰è¿‡
é«˜çš„æœŸå¾…ã€‚å¦å¤–ï¼Œç­å§”ä¹Ÿå¯èƒ½è€ƒè™‘åˆ°ä½ çš„ç‰¹æ®Šæƒ…å†µï¼Œä¼šç»™äºˆä½ ä¸€å®šçš„åŒ…å®¹å’Œæ”¯æŒã€‚"

--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

### epoch=3, lr=2e-5

question="æˆ‘æœ€è¿‘å¾ˆç„¦è™‘ï¼Œæˆ‘è¢«è¦æ±‚å‚åŠ ä¸€ä¸ªèŠ‚ç›®ï¼Œä½†æ˜¯æˆ‘æ²¡æœ‰ä»»ä½•æ‰è‰ºï¼Œæˆ‘è™½ç„¶æ‹’ç»ä½†æ˜¯ä¹Ÿä¸æƒ³ä¸ºéš¾ç­å§”å°±ç­”åº”äº†ï¼Œç°åœ¨æˆ‘æ€»è§‰å¾—æˆ‘ä¼šæç ¸ï¼Œæ€ä¹ˆåŠå•Šï¼Ÿ"
answer="é¦–å…ˆï¼Œæˆ‘ç†è§£ä½ çš„å›°æ‰°å’Œæ‹…å¿§ã€‚é¢å¯¹è¿™æ ·çš„æƒ…å†µï¼Œæ„Ÿåˆ°ç„¦è™‘æ˜¯å¾ˆæ­£å¸¸çš„ååº”ã€‚ä½ æ„¿æ„æ¥å—æŒ‘æˆ˜å¹¶å°Šé‡ç­å§”çš„å®‰æ’ï¼Œè¿™å·²ç»å¾ˆå¥½äº†ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å¯ä»¥å°è¯•ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤æ¥ç¼“è§£ä½ çš„ç„¦è™‘æƒ…ç»ªï¼š
1. æ­£è§†è‡ªå·±çš„æ„Ÿå—ï¼šé¦–å…ˆï¼Œä¸è¦å› ä¸ºè‡ªå·±æ²¡æœ‰æ‰è‰ºè€Œæ„Ÿåˆ°è‡ªå‘æˆ–æ„§ç–šã€‚æ¯ä¸ªäººéƒ½æœ‰è‡ªå·±çš„ä¼˜ç‚¹å’Œä¸è¶³ï¼Œå…³é”®åœ¨äºå¦‚ä½•å‘æ˜å’Œåˆ©ç”¨ã€‚
2. è®¾å®šåˆç†æœŸæœ›ï¼šä½ ä¸å¿…è¿½æ±‚å®Œç¾ï¼Œé‡è¦çš„æ˜¯å‚ä¸å’Œäº«å—è¿‡ç¨‹ã€‚ä½ å¯ä»¥å°†è¿™ä¸ªèŠ‚ç›®è§†ä¸ºä¸€ä¸ªè‡ªæˆ‘æŒ‘æˆ˜çš„æœºä¼šï¼Œè€Œéè¯„ä»·è‡ªå·±çš„æ ‡å‡†ã€‚
3. å‡†å¤‡ä¸ç»ƒä¹ ï¼šä½ å¯ä»¥æå‰å‡†å¤‡ä¸€äº›ç®€å•çš„è‡ªæˆ‘ä»‹ç»ï¼Œæˆ–è€…æ€è€ƒä¸€äº›è¯é¢˜æ¥å‚ä¸è®¨è®ºã€‚ç»ƒä¹ å¯ä»¥å¢å¼ºä½ çš„è‡ªä¿¡å¿ƒï¼Œé™ä½ç´§å¼ æ„Ÿã€‚
4. å¯»æ±‚æ”¯æŒï¼šå’Œç­å§”æ²Ÿé€šï¼Œè¡¨è¾¾ä½ çš„æ‹…å¿§ï¼Œå¯»æ±‚ä»–ä»¬çš„ç†è§£å’Œæ”¯æŒã€‚ä»–ä»¬å¯èƒ½ä¼šæä¾›ä¸€äº›å»ºè®®æˆ–è€…é¼“åŠ±ã€‚
5. è°ƒæ•´å¿ƒæ€ï¼šå°†æ³¨æ„åŠ›ä»â€œæç ¸â€çš„è´Ÿé¢æƒ³æ³•è½¬ç§»åˆ°â€œæˆé•¿â€çš„ç§¯æè§’åº¦ã€‚æ¯æ¬¡ç»å†éƒ½æ˜¯ä¸€æ¬¡å­¦ä¹ å’Œæå‡çš„æœºä¼šã€‚
6. è¿›è¡Œæ”¾æ¾è®­ç»ƒï¼šæ¯”å¦‚æ·±å‘¼å¸ã€å†¥æƒ³ç­‰æ–¹æ³•ï¼Œå¯ä»¥å¸®åŠ©ä½ åœ¨èŠ‚ç›®å‰ç¼“è§£ç´§å¼ æƒ…ç»ªï¼Œä¿æŒå†·é™ã€‚
è¯·è®°ä½ï¼Œé¢å¯¹å‹åŠ›ï¼Œå‹‡æ•¢é¢å¯¹å’Œç§¯æåº”å¯¹æ˜¯è§£å†³é—®é¢˜çš„å…³é”®ã€‚ç¥ä½ èŠ‚ç›®é¡ºåˆ©ï¼Œä¹Ÿç¥ä½ åœ¨è¿™æ¬¡ç»å†ä¸­æœ‰æ‰€æ”¶è·ï¼"

question="å¯æ˜¯æˆ‘æ˜¯ä¸ªç¤¾æï¼Œåšä¸åˆ°æ€ä¹ˆåŠï¼Ÿ"
answer="æˆ‘æ˜ç™½ä½ çš„å›°æ‰°ï¼Œå¯¹äºæ•°å­¦å­¦ç§‘çš„æŒ‘æˆ˜ï¼Œæˆ‘ä»¬å¯ä»¥å°è¯•ä»¥ä¸‹ç­–ç•¥æ¥æå‡ä½ çš„å­¦ä¹ æ•ˆæœï¼š
1. ç†è§£åŸºç¡€ï¼šå›é¡¾å¹¶å·©å›ºåŸºç¡€çŸ¥è¯†ï¼Œç¡®ä¿å¯¹æ•°å­¦æ¦‚å¿µæœ‰æ¸…æ™°çš„ç†è§£ã€‚åŸºç¡€æ‰å®äº†ï¼Œæ‰èƒ½æ›´å¥½åœ°åº”å¯¹æ›´å¤æ‚çš„æ•°å­¦é—®é¢˜ã€‚
2. åˆ¶å®šè®¡åˆ’ï¼šæ ¹æ®è‡ªèº«æƒ…å†µï¼Œåˆ¶å®šåˆç†çš„å­¦ä¹ è®¡åˆ’ï¼Œåˆ†é˜¶æ®µã€åˆ†æ¨¡å—åœ°å­¦ä¹ ï¼Œé¿å…ä¸€æ¬¡æ€§è¿½æ±‚é«˜éš¾åº¦é¢˜ç›®ã€‚
3. å¯»æ‰¾å­¦ä¹ èµ„æºï¼šåˆ©ç”¨ç½‘ç»œèµ„æºï¼Œå¦‚åœ¨çº¿è¯¾ç¨‹ã€è¾…å¯¼è§†é¢‘ç­‰ï¼Œè·å–æ›´å¤šçš„å­¦ä¹ èµ„æ–™ï¼Œæ‹“å®½è§£é¢˜æ€è·¯ã€‚
4. ç»ƒä¹ é¢˜æµ·æˆ˜æœ¯ï¼šé€šè¿‡å¤§é‡ç»ƒä¹ ï¼Œæé«˜è§£é¢˜é€Ÿåº¦å’Œå‡†ç¡®ç‡ã€‚ä½†è¦æ³¨æ„åˆç†å®‰æ’ç»ƒä¹ é‡ï¼Œé¿å…è¿‡åº¦ç–²åŠ³ã€‚
5. å¯»æ±‚å¸®åŠ©ï¼šå‘è€å¸ˆã€åŒå­¦æˆ–å®¶æ•™å¯»æ±‚å¸®åŠ©ï¼Œä»–ä»¬å¯ä»¥ä¸ºä½ æä¾›é’ˆå¯¹æ€§çš„æŒ‡å¯¼å’Œå»ºè®®ã€‚
6. è°ƒæ•´å¿ƒæ€ï¼šä¿æŒç§¯æçš„å¿ƒæ€ï¼Œç›¸ä¿¡è‡ªå·±æœ‰èƒ½åŠ›å…‹æœå›°éš¾ã€‚é‡åˆ°æŒ«æŠ˜æ—¶ï¼Œä¸è¦æ°”é¦ï¼Œè€Œæ˜¯è¦å­¦ä¼šä»ä¸­å¸å–æ•™è®­ï¼Œä¸æ–­è¿›æ­¥ã€‚
è¯·è®°ä½ï¼Œå­¦ä¹ æ˜¯ä¸€ä¸ªå¾ªåºæ¸è¿›çš„è¿‡ç¨‹ï¼Œéœ€è¦è€å¿ƒå’ŒåšæŒã€‚é€šè¿‡ä»¥ä¸Šç­–ç•¥ï¼Œç›¸ä¿¡ä½ ä¼šé€æ¸æé«˜æ•°å­¦æˆç»©ï¼Œæ‰¾åˆ°å±äºè‡ªå·±çš„å­¦ä¹ æ–¹æ³•ã€‚åŠ æ²¹ï¼"

--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

### é¢„è®­ç»ƒæ¨¡å‹

question="æˆ‘æœ€è¿‘å¾ˆç„¦è™‘ï¼Œæˆ‘è¢«è¦æ±‚å‚åŠ ä¸€ä¸ªèŠ‚ç›®ï¼Œä½†æ˜¯æˆ‘æ²¡æœ‰ä»»ä½•æ‰è‰ºï¼Œæˆ‘è™½ç„¶æ‹’ç»ä½†æ˜¯ä¹Ÿä¸æƒ³ä¸ºéš¾ç­å§”å°±ç­”åº”äº†ï¼Œç°åœ¨æˆ‘æ€»è§‰å¾—æˆ‘ä¼šæç ¸ï¼Œæ€ä¹ˆåŠå•Šï¼Ÿ"
answer="é¢å¯¹è¿™æ ·çš„æƒ…å†µï¼Œé¦–å…ˆè¦è®¤è¯†åˆ°ç„¦è™‘æ˜¯å¾ˆæ­£å¸¸çš„æƒ…ç»ªååº”ï¼Œå¾ˆå¤šäººéƒ½ä¼šé‡åˆ°ç±»ä¼¼çš„æƒ…å†µã€‚æ¥ä¸‹æ¥ï¼Œå¯ä»¥å°è¯•ä»¥ä¸‹å‡ ä¸ªæ–¹æ³•æ¥ç¼“è§£ç„¦è™‘ï¼š
1. **å‡†å¤‡å……åˆ†**ï¼šå°½ç®¡ä½ è§‰å¾—è‡ªå·±æ²¡æœ‰æ‰è‰ºï¼Œä½†ä½ å¯ä»¥å‡†å¤‡ä¸€äº›åŸºæœ¬çš„è‡ªæˆ‘ä»‹ç»ï¼Œä»¥åŠå…³äºèŠ‚ç›®çš„åŸºæœ¬é—®é¢˜å’Œç­”æ¡ˆï¼Œè¿™æ ·å¯ä»¥åœ¨èŠ‚ç›®å¼€å§‹å‰åšå¥½å‡†å¤‡ã€‚
2. **ç§¯æå‚ä¸**ï¼šåœ¨èŠ‚ç›®ä¸­ï¼Œå³ä½¿ä½ æ²¡æœ‰æ‰è‰ºå±•ç¤ºï¼Œä¹Ÿå¯ä»¥ç§¯æå‚ä¸å…¶ä»–ç¯èŠ‚ï¼Œæ¯”å¦‚è®¨è®ºã€æ¸¸æˆæˆ–è€…è¡¨æ¼”å¹•åå·¥ä½œç­‰ã€‚
3. **æ”¾æ¾å¿ƒæ€**ï¼šå‘Šè¯‰è‡ªå·±ï¼Œå³ä½¿æç ¸äº†ä¹Ÿæ²¡æœ‰å…³ç³»ï¼Œæ¯ä¸ªäººéƒ½ä¼šæœ‰çŠ¯é”™çš„æ—¶å€™ã€‚é‡è¦çš„æ˜¯ä»ä¸­å­¦ä¹ å’Œæˆé•¿ã€‚
4. **æ­£é¢æ€è€ƒ**ï¼šå°è¯•ç”¨ç§¯æçš„æ€åº¦å»çœ‹å¾…è¿™ä»¶äº‹ï¼ŒæŠŠå®ƒå½“ä½œä¸€ä¸ªæŒ‘æˆ˜è‡ªå·±çš„æœºä¼šï¼Œè€Œä¸æ˜¯ä¸€ä¸ªå‹åŠ›ã€‚
5. **å¯»æ±‚æ”¯æŒ**ï¼šå’Œä¿¡ä»»çš„æœ‹å‹æˆ–å®¶äººè°ˆè°ˆä½ çš„æ‹…å¿§ï¼Œä»–ä»¬çš„æ”¯æŒå’Œé¼“åŠ±å¯èƒ½ä¼šç»™ä½ å¸¦æ¥å¾ˆå¤§çš„å¸®åŠ©ã€‚
6. **ä¸“ä¸šå¸®åŠ©**ï¼šå¦‚æœç„¦è™‘æ„Ÿå¾ˆå¼ºï¼Œå½±å“åˆ°äº†æ—¥å¸¸ç”Ÿæ´»ï¼Œå¯ä»¥è€ƒè™‘å¯»æ±‚ä¸“ä¸šçš„å¿ƒç†å’¨è¯¢å¸®åŠ©ã€‚
è®°ä½ï¼Œæ¯ä¸ªäººéƒ½æ˜¯ç‹¬ä¸€æ— äºŒçš„ï¼Œä½ æœ‰ä½ çš„ä»·å€¼å’Œç‰¹ç‚¹ï¼Œä¸è¦å› ä¸ºç¼ºä¹æŸç§æ‰è‰ºå°±å¦å®šè‡ªå·±ã€‚ç›¸ä¿¡è‡ªå·±ï¼Œä½ ä¸€å®šå¯ä»¥åšå¾—å¾ˆå¥½ï¼"

question="å¯æ˜¯æˆ‘æ˜¯ä¸ªç¤¾æï¼Œåšä¸åˆ°æ€ä¹ˆåŠï¼Ÿ"
answer="å¦‚æœä½ æœ‰ç¤¾äº¤ææƒ§ç—‡ï¼ˆç¤¾æï¼‰ï¼Œé‚£ä¹ˆå‚åŠ èŠ‚ç›®å¯èƒ½ä¼šè®©ä½ æ„Ÿåˆ°æ›´åŠ ä¸å®‰ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä»¥ä¸‹æ˜¯ä¸€äº›ç‰¹åˆ«çš„å»ºè®®ï¼š
1. **å‡†å¤‡å……åˆ†**ï¼šå¦‚å‰æ‰€è¿°ï¼Œå……åˆ†çš„å‡†å¤‡å¯ä»¥å¸®åŠ©ä½ åœ¨èŠ‚ç›®ä¸­æ›´åŠ è‡ªä¿¡ã€‚
2. **å¯»æ±‚æ”¯æŒ**ï¼šæ‰¾ä¸€ä¸ªæœ‹å‹æˆ–å®¶äººé™ªåŒä½ å‚åŠ èŠ‚ç›®ï¼Œä»–ä»¬åœ¨åœºå¯ä»¥ç»™ä½ æä¾›æ”¯æŒå’Œå¸®åŠ©ï¼Œè®©ä½ æ„Ÿè§‰æ›´åŠ å®‰å¿ƒã€‚
3. **é€æ­¥é¢å¯¹**ï¼šå¦‚æœä½ å› ä¸ºç¤¾æè€Œä¸æ•¢åœ¨èŠ‚ç›®ä¸­è¡¨ç°ï¼Œå¯ä»¥å°è¯•ä»ä¸€äº›å°çš„ã€ä¸é‚£ä¹ˆæ­£å¼çš„åœºåˆå¼€å§‹ï¼Œé€æ­¥å¢åŠ å‚ä¸ç¤¾äº¤æ´»åŠ¨çš„é¢‘ç‡å’Œéš¾åº¦ã€‚
4. **æ­£é¢æ€è€ƒ**ï¼šåœ¨å¿ƒé‡Œå¯¹è‡ªå·±è¯´ä¸€äº›ç§¯æçš„è¯ï¼Œæ¯”å¦‚â€œæˆ‘å¯ä»¥åšåˆ°â€ã€â€œæˆ‘å¹¶ä¸å­¤å•â€ç­‰ï¼Œè¿™äº›ç§¯æçš„è‡ªæˆ‘æš—ç¤ºå¯ä»¥å¸®åŠ©ä½ å…‹æœææƒ§ã€‚
5. **ä¸“ä¸šå¸®åŠ©**ï¼šå¦‚æœä½ çš„ç¤¾æç—‡çŠ¶ä¸¥é‡å½±å“äº†ç”Ÿæ´»ï¼Œå»ºè®®å¯»æ±‚ä¸“ä¸šå¿ƒç†å’¨è¯¢å¸ˆçš„å¸®åŠ©ã€‚ä»–ä»¬å¯ä»¥æä¾›ä¸“ä¸šçš„æ²»ç–—å’ŒæŒ‡å¯¼ï¼Œå¸®åŠ©ä½ å…‹æœç¤¾æã€‚
è®°ä½ï¼Œæ¯ä¸ªäººéƒ½æœ‰è‡ªå·±çš„èŠ‚å¥ï¼Œä¸è¦å› ä¸ºå®³æ€•è€Œæ”¾å¼ƒå°è¯•ã€‚ä¸€æ­¥ä¸€æ­¥æ¥ï¼Œæ…¢æ…¢åœ°ä½ ä¼šå‘ç°è‡ªå·±å˜å¾—æ›´åŠ è‡ªä¿¡å’Œå‹‡æ•¢ã€‚"

```

ä»ç»“æœä¸Šçœ‹ï¼Œå­¦ä¹ ç‡è®¾ç½®æ­£ç¡®çš„è¯æ¨ç†ç»“æœç¡®å®æ¯”æƒ³è±¡ä¸­è¦å¥½å¾ˆå¤šï¼Œè€Œä¸”å¯ä»¥èŠ‚çœå¾ˆå¤šè®­ç»ƒèµ„æºã€‚

---

### loraçš„ç§©r

ä¸‹å›¾è¡¨ç¤ºä¸åŒrçš„æƒ…å†µä¸‹æ¨¡å‹lossè¿˜æœ‰æ¢¯åº¦grad_normå˜åŒ–çš„æ›²çº¿ï¼Œå…¶ä¸­`epoch-3`è¡¨ç¤ºçš„æ˜¯r=64çš„ç»“æœ

![ä¸åŒrä¸‹çš„æ›²çº¿å˜åŒ–](./example/r.png)

> ğŸ’¡**æ€»ç»“**ï¼š
> 
> ç”±äºè¿™é‡Œè®¾ç½®çš„å­¦ä¹ ç‡ä½äº†ç‚¹ï¼Œæ‰€ä»¥æ¨¡å‹æ”¶æ•›é€Ÿåº¦æ¯”è¾ƒæ…¢ï¼Œlossæ›²çº¿å‡å…·æœ‰ç›¸åŒçš„ä¸‹é™è¶‹åŠ¿å¹¶ä¸”åŸºæœ¬ä¸€è‡´ï¼Œä½†æ˜¯ç§©è¶Šé«˜ï¼Œæ¢¯åº¦èŒƒæ•°è¶Šä½ï¼ŒåŸå› æœ‰ä»¥ä¸‹å‡ ç‚¹ï¼š
> 
> - **æ•°å€¼ç¨³å®šæ€§**ï¼šåœ¨æ•°å€¼è®¡ç®—ä¸­ï¼Œè¾ƒé«˜çš„ç§©å¯èƒ½æœ‰åŠ©äºæé«˜è®¡ç®—çš„ç¨³å®šæ€§ï¼Œè¿™æ˜¯å› ä¸ºé«˜ç§©çŸ©é˜µåœ¨æ•°å€¼è¿ç®—ä¸­æ›´ç¨³å®šã€‚
> - **å±€éƒ¨æœ€å°å€¼æˆ–éç‚¹**ï¼šåœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­ï¼Œæ¨¡å‹å¯èƒ½é™·å…¥å±€éƒ¨æœ€å°å€¼æˆ–éç‚¹ã€‚è¾ƒé«˜çš„ç§©å¯èƒ½å¯¼è‡´æ¨¡å‹åœ¨å‚æ•°ç©ºé—´ä¸­çš„ä¸åŒåŒºåŸŸæ”¶æ•›ï¼Œè¿™äº›åŒºåŸŸå¯èƒ½å…·æœ‰ç›¸ä¼¼çš„æŸå¤±å€¼ï¼Œä½†æ¢¯åº¦æ–¹å‘å’Œå¤§å°ä¸åŒï¼Œè¿™å¯èƒ½å¯¼è‡´æ¢¯åº¦èŒƒæ•°çš„é™ä½ï¼Œå› ä¸ºæ¨¡å‹åœ¨è¿™äº›åŒºåŸŸçš„æ¢¯åº¦æ›´æ–°æ›´å°ã€‚
> - **ä¼˜åŒ–ç®—æ³•çš„æ•ˆç‡**ï¼šä¸åŒçš„ç§©å¯èƒ½å¯¼è‡´ä¼˜åŒ–ç®—æ³•åœ¨å‚æ•°ç©ºé—´ä¸­çš„æœç´¢è·¯å¾„ä¸åŒã€‚è¾ƒé«˜çš„ç§©å¯èƒ½å…è®¸æ¨¡å‹åœ¨å‚æ•°ç©ºé—´ä¸­æ›´å¹³æ»‘åœ°ç§»åŠ¨ï¼Œä»è€Œå‡å°‘æ¢¯åº¦çš„æ³¢åŠ¨ï¼Œè¿™å¯èƒ½å¯¼è‡´æ¢¯åº¦èŒƒæ•°çš„é™ä½ï¼Œå› ä¸ºæ¨¡å‹åœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­æ›´åŠ ç¨³å®šã€‚
> - **æ¢¯åº¦ç¨³å®šæ€§**ï¼šåœ¨æ·±åº¦å­¦ä¹ ä¸­ï¼Œæ¢¯åº¦çš„ç¨³å®šæ€§å¯¹äºè®­ç»ƒè¿‡ç¨‹è‡³å…³é‡è¦ã€‚è¾ƒä½çš„æ¢¯åº¦èŒƒæ•°é€šå¸¸æ„å‘³ç€æ¢¯åº¦æ›´æ–°æ›´åŠ ç¨³å®šï¼Œä¸å®¹æ˜“å‡ºç°æ¢¯åº¦çˆ†ç‚¸æˆ–æ¶ˆå¤±çš„é—®é¢˜ã€‚å½“ç§©è¾ƒé«˜æ—¶ï¼Œæ¨¡å‹å¯èƒ½æ›´å®¹æ˜“æ‰¾åˆ°æŸå¤±å‡½æ•°çš„å¹³æ»‘åŒºåŸŸï¼Œä»è€Œä½¿å¾—æ¢¯åº¦æ›´æ–°æ›´åŠ ç¨³å®šï¼Œæ¢¯åº¦èŒƒæ•°è¾ƒä½ã€‚
>
> ç”±äºloraå¾®è°ƒçš„æ—¶å€™æœ¬èº«å°±å†»ç»“äº†å¤§éƒ¨åˆ†å‚æ•°ï¼Œæ‰€ä»¥å³ä½¿rå¢åŠ ï¼Œä½†æ˜¯æ˜¾å­˜çš„å ç”¨å¹¶ä¸ä¼šæ˜¾è‘—å¢åŠ ï¼Œå› æ­¤è¿™éƒ¨åˆ†å¯ä»¥å¿½ç•¥ä¸è®¡ï¼Œåªéœ€è¦åœ¨åˆé€‚åŒºé—´ä¸Šè€ƒè™‘losså’Œgrad_normçš„å˜åŒ–å³å¯ã€‚

---

### loraçš„ç¼©æ”¾å› å­Î±

ç¼©æ”¾å› å­ï¼ˆalphaï¼‰ç”¨äºè°ƒæ•´ä½ç§©çŸ©é˜µæ›´æ–°çš„å¹…åº¦ï¼Œä»¥ç¡®ä¿è¿™äº›æ›´æ–°ä¸ä¼šè¿‡å¤§æˆ–è¿‡å°ï¼Œä»è€Œå½±å“æ¨¡å‹çš„ç¨³å®šæ€§å’Œæ”¶æ•›æ€§ã€‚

**ç¼©æ”¾å› å­ï¼ˆAlphaï¼‰çš„å½±å“**

- æ›´æ–°å¹…åº¦çš„è°ƒèŠ‚ï¼šç¼©æ”¾å› å­alphaç”¨äºè°ƒæ•´ä½ç§©çŸ©é˜µæ›´æ–°çš„å¹…åº¦ã€‚åœ¨LoRAä¸­ï¼ŒåŸå§‹æƒé‡çŸ©é˜µWè¢«åˆ†è§£ä¸ºW0 + W_rankï¼Œå…¶ä¸­W_rank = A * Bï¼ŒAå’ŒBæ˜¯ä½ç§©çŸ©é˜µã€‚å¦‚æœalphaè®¾ç½®å¾—è¿‡å¤§ï¼Œå¯èƒ½ä¼šå¯¼è‡´æ¢¯åº¦æ›´æ–°è¿‡äºæ¿€è¿›ï¼Œä»è€Œå¼•èµ·è®­ç»ƒè¿‡ç¨‹ä¸­çš„ä¸ç¨³å®šæ€§ï¼›å¦‚æœè®¾ç½®å¾—è¿‡å°ï¼Œåˆ™å¯èƒ½å¯¼è‡´æ›´æ–°è¿‡äºä¿å®ˆï¼Œå½±å“æ¨¡å‹çš„å­¦ä¹ èƒ½åŠ›ã€‚

- æ¢¯åº¦ç¨³å®šæ€§ï¼šé€‚å½“çš„alphaå€¼æœ‰åŠ©äºä¿æŒæ¢¯åº¦çš„ç¨³å®šæ€§ã€‚å¦‚æœalphaè¿‡å¤§ï¼Œå¯èƒ½ä¼šå¯¼è‡´æ¢¯åº¦çˆ†ç‚¸ï¼›å¦‚æœè¿‡å°ï¼Œåˆ™å¯èƒ½å¯¼è‡´æ¢¯åº¦æ¶ˆå¤±ã€‚

- æ¨¡å‹æ”¶æ•›æ€§ï¼šalphaçš„å€¼ç›´æ¥å½±å“æ¨¡å‹çš„æ”¶æ•›é€Ÿåº¦å’Œç¨³å®šæ€§ã€‚ä¸€ä¸ªé€‚ä¸­çš„alphaå€¼å¯ä»¥å¸®åŠ©æ¨¡å‹æ›´å¿«åœ°æ”¶æ•›åˆ°ä¸€ä¸ªè¾ƒå¥½çš„è§£ã€‚

![r=4çš„æ—¶å€™alphaä¸åŒçš„å¯¹æ¯”ç»“æœ](./example/r-alpha-vs.png)

> ğŸ’¡**ä¸ºä»€ä¹ˆalpha=16æ¯”alpha=32æ¨¡å‹æ”¶æ•›æ•ˆæœæ›´å¥½ä¸€äº›?**ï¼š
> 
> - æ›´æ–°å¹…åº¦é€‚ä¸­ï¼šalpha=16æä¾›äº†ä¸€ä¸ªé€‚ä¸­çš„æ›´æ–°å¹…åº¦ï¼Œä½¿å¾—æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­èƒ½å¤Ÿç¨³å®šåœ°å­¦ä¹ å’Œæ”¶æ•›ã€‚
>
> - é¿å…æ¢¯åº¦çˆ†ç‚¸ï¼šalpha=32å¯èƒ½è¿‡å¤§ï¼Œå¯¼è‡´æ¢¯åº¦æ›´æ–°è¿‡äºæ¿€è¿›ï¼Œä»è€Œå¼•èµ·è®­ç»ƒè¿‡ç¨‹ä¸­çš„ä¸ç¨³å®šæ€§ã€‚
>
> - ä¼˜åŒ–ç®—æ³•çš„é€‚åº”æ€§ï¼šä¸åŒçš„alphaå€¼å¯èƒ½ä¸ä¼˜åŒ–ç®—æ³•çš„é€‚åº”æ€§æœ‰å…³ã€‚alpha=16æ›´å¥½åœ°é€‚åº”äº†æ‰€ä½¿ç”¨çš„ä¼˜åŒ–ç®—æ³•ï¼Œä»è€Œä¿ƒè¿›äº†æ¨¡å‹çš„æ”¶æ•›ã€‚
> 
> æ€»çš„æ¥è¯´ï¼Œé€‰æ‹©åˆé€‚çš„alphaå€¼éœ€è¦è€ƒè™‘æ¨¡å‹çš„ç¨³å®šæ€§ã€æ”¶æ•›é€Ÿåº¦ä»¥åŠè®­ç»ƒè¿‡ç¨‹ä¸­çš„æ¢¯åº¦è¡Œä¸ºã€‚é€šè¿‡å®éªŒå’Œè°ƒæ•´ï¼Œå¯ä»¥æ‰¾åˆ°æœ€é€‚åˆç‰¹å®šæ¨¡å‹å’Œä»»åŠ¡çš„alphaå€¼ã€‚

ç„¶åå¤šæ¬¡å®éªŒçš„ç»“æœå¦‚ä¸‹ï¼Œå…¶ä¸­æ²¡æœ‰æ ‡è®°çš„alpha=32ï¼Œå¯ä»¥å‚è€ƒä¸‹ï¼š

![alphaä¸åŒçš„å¯¹æ¯”ç»“æœ](./example/many-r-alpha-vs.png)

---

### loraçš„æ­£åˆ™åŒ–å‚æ•°dropout

åœ¨ç¥ç»ç½‘ç»œè®­ç»ƒä¸­ï¼Œæ¨¡å‹å¾€å¾€å€¾å‘äºâ€œè®°ä½â€è®­ç»ƒæ•°æ®çš„ç»†èŠ‚ç”šè‡³å™ªå£°ï¼Œå¯¼è‡´æ¨¡å‹åœ¨æ–°æ•°æ®ä¸Šçš„è¡¨ç°ä¸ä½³ï¼Œå³è¿‡æ‹Ÿåˆã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼ŒDropout åº”è¿è€Œç”Ÿã€‚é€šè¿‡åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­éšæœºä¸¢å¼ƒä¸€éƒ¨åˆ†ç¥ç»å…ƒï¼ŒDropout èƒ½å‡å°‘æ¨¡å‹å¯¹ç‰¹å®šç¥ç»å…ƒçš„ä¾èµ–ï¼Œä»è€Œæå‡æ³›åŒ–èƒ½åŠ›ã€‚

è¿™éƒ¨åˆ†åŸºæœ¬ä¸ä¼šå¯¹å®éªŒç»“æœäº§ç”Ÿè¿‡å¤§çš„å½±å“ï¼Œå› ä¸ºæ¨¡å‹å·²ç»é€šè¿‡å…¶ä»–æœºåˆ¶ï¼ˆå¦‚ä½ç§©æ›´æ–°ï¼‰è·å¾—äº†è¶³å¤Ÿçš„æ­£åˆ™åŒ–ã€‚

![æ­£åˆ™åŒ–å‚æ•°å¯¹å®éªŒçš„å½±å“](./example/dropout.png)

---

### loraå¾®è°ƒæ¨¡å‹å±‚

å¯¹äºæ¨¡å‹ä¸åŒçš„å±‚è¿›è¡Œå¾®è°ƒçš„ç»“æœå…¶å®ä»lossæ›²çº¿ä¸Šè§‚å¯Ÿçš„è¯åŒºåˆ«ä¸å¤§ï¼Œæˆ‘è®¤ä¸ºåº”è¯¥ä»æ¨ç†ç»“æœä»¥åŠè®­ç»ƒæ—¶é•¿ä¸Šè§‚å¯Ÿå¹¶å¯¹æ¯”å…¶æ•ˆæœã€‚

å½“loraå¾®è°ƒæ‰€æœ‰çš„çº¿æ€§å±‚çš„æ—¶å€™æ˜æ˜¾æœ€ç»ˆæ•ˆæœä¼šæ›´å¥½ä¸€ç‚¹ï¼Œä½†æ˜¯è®­ç»ƒæ—¶é•¿ç›¸å¯¹æ¥è¯´å°±ä¼šå¤šä¸€äº›ï¼Œè€Œå¦‚æœåªå¾®è°ƒå…¶ä¸­æŸäº›å±‚æ¯”å¦‚qã€kå±‚çš„è¯è®­ç»ƒæ—¶é—´æ¯”è¾ƒçŸ­ï¼Œä½†æ˜¯æ•ˆæœå¯èƒ½å°±ä¼šç¨å¾®å·®ä¸€ç‚¹ã€‚

ä¸‹å›¾å¯ä»¥çœ‹ä¸‹å¯¹æ¯”ç»“æœï¼š

![ä¸åŒæ¨¡å‹å±‚çš„lossæ›²çº¿å˜åŒ–](./example/moxingceng.png)

![å®éªŒæ—¶é—´å¯¹æ¯”](./example/time.png)


> å…¶ä¸­`attn-lora`æ˜¯åŒ…æ‹¬qã€kã€vã€oä»¥åŠå‰é¦ˆç½‘ç»œå±‚mlpå±‚æ‰€æœ‰å±‚éƒ½å‚ä¸loraå¾®è°ƒï¼Œå…¶ä»–ä¸¤ä¸ªå’Œæ ‡é¢˜è¡¨è¾¾çš„æ„æ€ä¸€è‡´ï¼Œåˆ†åˆ«åªå‚ä¸äº†æŸäº›å±‚çš„loraå¾®è°ƒã€‚
> 
> ä»ä¸Šå›¾å¯ä»¥çœ‹å‡ºï¼Œå…¶å®æ¨¡å‹æ”¶æ•›çš„æƒ…å†µç›¸ä¼¼ï¼Œå·®åˆ«ä¸å¤§ï¼Œ ä½†æ˜¯åªè®­ç»ƒä¸¤å±‚çš„è¯è®­ç»ƒæ—¶é—´ä¸Šèƒ½çŸ­ä¸€äº›ï¼Œç„¶åå¯¹äºæ¨ç†ç»“æœçš„è¯„ä¼°éœ€è¦å‚è€ƒæ¯”è¾ƒå¤šçš„æµ‹è¯•é›†ï¼Œç†è®ºä¸Šå…¶å®ç›¸å·®ä¸å¤§ã€‚

---

### è®­ç»ƒå‘¨æœŸepoch

å½“è®­ç»ƒæ¨¡å‹æ—¶ï¼Œé€‰æ‹©é€‚å½“çš„è®­ç»ƒå‘¨æœŸï¼ˆepochï¼‰æ•°é‡æ˜¯è‡³å…³é‡è¦çš„ã€‚epochæŒ‡çš„æ˜¯æ•´ä¸ªè®­ç»ƒæ•°æ®é›†é€šè¿‡æ¨¡å‹çš„æ¬¡æ•°ã€‚

è¿‡å¤šçš„è®­ç»ƒå‘¨æœŸå¯èƒ½ä¼šå¯¼è‡´æ¨¡å‹åœ¨è®­ç»ƒé›†ä¸Šè¡¨ç°ä¼˜ç§€ï¼Œä½†æ˜¯åœ¨å…¶ä»–æ•°æ®é›†ä¸Šå¯èƒ½è¡¨ç°ä¸å¥½ï¼Œè¿™æ˜¯ç”±äºè®­ç»ƒå‘¨æœŸè¿‡é•¿å¯èƒ½ä¼šå¯¼è‡´æ¨¡å‹æ³›åŒ–èƒ½åŠ›å‡å¼±ã€‚

å› æ­¤é€‰æ‹©åˆé€‚çš„epochå¯¹äºå¾®è°ƒæ¥è¯´è‡³å…³é‡è¦ï¼Œepochåœ¨5ä»¥å†…çš„è¯æ•ˆæœä¸é”™ï¼Œå¦‚æœæ›´å¤§çš„epochå°±å¯èƒ½å‰Šå¼±æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›äº†ã€‚

![epochçš„å¯¹æ¯”ç»“æœ](./example/epoch.png)

> ğŸš¨**æ³¨æ„**ï¼š
> 
> å›¾ä¸­æ¢¯åº¦grad_normå˜åŒ–å…ˆä¸‹é™åä¸Šå‡æœ€åå¹³ç¨³çš„è¶‹åŠ¿æ˜¯å› ä¸ºè¿™äº›å®éªŒçš„**å­¦ä¹ ç‡è®¾ç½®è¿‡ä½**ï¼Œå¯¼è‡´äº†æ¢¯åº¦æ›´æ–°å¤ªå°ï¼Œéšåæ¨åŠ¨æ¨¡å‹é€ƒç¦»å±€éƒ¨æœ€å°å€¼è€Œä¸Šå‡ã€‚æœ¬æ¬¡å®éªŒåˆé€‚çš„å­¦ä¹ ç‡å¤§æ¦‚æ˜¯**1e-3~2e-4**ä¹‹é—´ï¼Œå¦‚æœæƒ³è§‚å¯Ÿä¸‹epochè¿‡å¤šçš„æƒ…å†µå¯ä»¥ä½¿ç”¨è¾ƒå°‘çš„æ•°æ®é›†è®­ç»ƒï¼Œè®¾ç½®åˆé€‚çš„å­¦ä¹ ç‡æ¥è§‚å¯Ÿç»“æœã€‚

---

### æ‰¹æ¬¡å¤§å°batch_size

`batch_size`æ˜¯æŒ‡åœ¨æ¨¡å‹è®­ç»ƒçš„å•æ¬¡è¿­ä»£ä¸­åŒæ—¶å¤„ç†çš„æ ·æœ¬æ•°é‡ã€‚è¿™ä¸ªå‚æ•°ç›´æ¥å½±å“åˆ°æ¨¡å‹è®­ç»ƒçš„å†…å­˜æ¶ˆè€—å’Œè®¡ç®—æ•ˆç‡ã€‚è¾ƒå¤§çš„`batch_size`å¯ä»¥æé«˜å†…å­˜åˆ©ç”¨ç‡å’Œè®­ç»ƒé€Ÿåº¦ï¼Œä½†ä¹Ÿå¯èƒ½å¯¼è‡´æ¨¡å‹è®­ç»ƒçš„ç¨³å®šæ€§ä¸‹é™ï¼Œä»¥åŠéœ€è¦æ›´å¤šçš„å†…å­˜èµ„æºã€‚è¾ƒå°çš„`batch_size`å¯ä»¥æé«˜æ¨¡å‹è®­ç»ƒçš„ç¨³å®šæ€§ï¼Œä½†å¯èƒ½ä¼šé™ä½è®­ç»ƒæ•ˆç‡ã€‚

è€Œæˆ‘ä»¬å¸¸å¸¸åœ¨è®¾ç½®è®­ç»ƒå‚æ•°çš„æ—¶å€™éœ€è¦è®¾ç½®`per_device_train_batch_size`ï¼Œè¿™ä¸ªå‚æ•°æ˜¯æŒ‡åœ¨æ¯ä¸ªè®­ç»ƒè®¾å¤‡ï¼ˆå¦‚GPUï¼‰ä¸Šç”¨äºè®­ç»ƒçš„æ‰¹æ¬¡å¤§å°ã€‚è¿™ä¸ªå‚æ•°ç‰¹åˆ«æœ‰ç”¨ï¼Œå½“ä½ æœ‰å¤šä¸ªè®­ç»ƒè®¾å¤‡æ—¶ï¼Œå®ƒå…è®¸ä½ ä¸ºæ¯ä¸ªè®¾å¤‡å•ç‹¬è®¾ç½®æ‰¹æ¬¡å¤§å°ã€‚ä¾‹å¦‚ï¼Œå¦‚æœä½ æœ‰4ä¸ªGPUï¼Œå¹¶ä¸”è®¾ç½®`per_device_train_batch_size`ä¸º2ï¼Œé‚£ä¹ˆæ€»å…±çš„`batch_size`å°†æ˜¯8ï¼ˆ2ä¸ªæ ·æœ¬æ¯ä¸ªGPUä¹˜ä»¥4ä¸ªGPUï¼‰ã€‚è¿™ä¸ªå‚æ•°å¯ä»¥å¸®åŠ©ä½ æ›´ç»†è‡´åœ°æ§åˆ¶æ¯ä¸ªè®­ç»ƒè®¾å¤‡ä¸Šçš„å†…å­˜æ¶ˆè€—å’Œè®¡ç®—è´Ÿè½½ã€‚

æˆ‘ä»¬å¯ä»¥å…ˆçœ‹ä¸‹è®­ç»ƒè¿‡ç¨‹ï¼š

![batchè®¾ç½®ä¸åŒçš„æ—¶å€™ç»“æœå¯¹æ¯”](./example/batch.png)

> ğŸ’¡**ä¸ºä»€ä¹ˆper_device_train_batch_sizeè®¾ç½®çš„å¤§ä¸€ç‚¹ï¼Œæ¨¡å‹æ”¶æ•›æ•ˆæœæ˜¾è‘—å¢åŠ ï¼Ÿ**ï¼š
> 
> è¿™é‡Œæˆ‘éƒ½ä½¿ç”¨çš„æ˜¯ä¸€å—å¡ï¼Œç„¶åå•çº¿ç¨‹è¿è¡Œï¼Œå› æ­¤æ€»å…±çš„batch_sizeåˆ†åˆ«æ˜¯1x1ã€1x2ï¼ˆnum_gpus x per_device_train_batch_sizeï¼‰ï¼Œ**è¾ƒå¤§çš„batch_sizeä½¿å¾—æ¯æ¬¡æ›´æ–°æ—¶ï¼Œæ¨¡å‹æ‰€è®¡ç®—çš„æ¢¯åº¦æ›´åŠ ç¨³å®šå’Œå‡†ç¡®ã€‚ä½†æ˜¯è¾ƒå°çš„batch_sizeæ¯æ¬¡æ›´æ–°çš„æ¢¯åº¦å¯èƒ½å—ä¸ªåˆ«æ ·æœ¬çš„å½±å“è¾ƒå¤§ï¼Œå› æ­¤è®­ç»ƒè¿‡ç¨‹çš„å™ªå£°è¾ƒå¤šï¼Œå¯èƒ½å¯¼è‡´æ¨¡å‹åœ¨ä¼˜åŒ–æ—¶åç¦»æœ€ä¼˜è§£ï¼Œè¿™å¯èƒ½ä¼šå¯¼è‡´è®­ç»ƒè¿‡ç¨‹ä¸ç¨³å®šæˆ–è€…æ”¶æ•›é€Ÿåº¦è¾ƒæ…¢ã€‚æˆ‘ä»¬å¯ä»¥ä»å›¾ä¸­æ˜æ˜¾çœ‹å‡ºåŒºåˆ«ã€‚**

---

ç„¶åæˆ‘ä»¬çœ‹ä¸‹è®­ç»ƒæ—¶é•¿çš„å·®åˆ«ï¼š

![batchä¸åŒçš„æ—¶å€™è®­ç»ƒæ—¶é•¿å¯¹æ¯”](./example/batch_time.png)

> ğŸ’¡èƒ½æ˜æ˜¾çœ‹å‡ºå½“è®¾ç½®batchè¾ƒå¤§çš„æ—¶å€™è®­ç»ƒæ—¶é•¿ç¼©çŸ­ï¼Œè¿™æ˜¯å› ä¸ºä¸€æ¬¡è®­ç»ƒå¯ä»¥åŒæ—¶è®­ç»ƒä¸¤æ¡æ•°æ®ï¼Œç†è®ºä¸Šå¯ä»¥ç¼©å‡ä¸€å°æ—¶ï¼Œå› ä¸ºå¤šäº†ä¸€å€ï¼Œè¿™é‡Œç›¸å·®äº†40å¤šåˆ†é’Ÿï¼Œæœ‰å¯èƒ½æ˜¯å¡çš„é—®é¢˜ï¼Œ**æ€»ä¹‹ï¼Œå¯ä»¥é€‚å½“é€‰æ‹©batchæ¥æé«˜è®­ç»ƒæ•ˆç‡ã€‚**

æœ€åæˆ‘ä»¬è§‚å¯Ÿä¸‹GPUçš„ä½¿ç”¨æƒ…å†µï¼š

> ğŸ‰**SwanLabæ›´æ–°çš„ç³»ç»Ÿç›‘æµ‹ï¼Œè¿˜æœ‰ç¡¬ä»¶æ¡ä»¶æ—¥å¿—ï¼Œæˆ‘ä»¬å¯ä»¥ç›´æ¥åœ¨å®˜ç½‘ä¸Šéšæ—¶æŸ¥çœ‹å®éªŒæ—¶ç¡¬ä»¶è®¾å¤‡æƒ…å†µ**

![å…·ä½“å®éªŒç¡¬ä»¶æ¡ä»¶](./example/gpus_info.png)

---

![GPUçš„ç›‘æµ‹æƒ…å†µ](./example/gpus.png)

å…¶ä¸­**GPU1**æ˜¯**batch=2**çš„æ—¶å€™çš„æƒ…å†µï¼Œ**GPU0**æ˜¯**batch=1**çš„æ—¶å€™çš„ç¡¬ä»¶ï¼Œå¯ä»¥çœ‹åˆ°ä»æ˜¾å­˜çš„ä½¿ç”¨ä¸Šï¼Œbatch=1çš„æ—¶å€™å¤§æ¦‚ä½¿ç”¨äº†26GBï¼Œbatch=2çš„æ—¶å€™ä½¿ç”¨äº†36GBã€‚


---

### æ¢¯åº¦ç´¯è®¡æ­¥æ•°gradient_accumulation_steps

è¯¥å‚æ•°ç”¨äºåœ¨å¾®è°ƒæˆ–è®­ç»ƒè¿‡ç¨‹ä¸­æ§åˆ¶æ¢¯åº¦ç´¯ç§¯çš„æ­¥æ•°ã€‚ç®€å•æ¥è¯´ï¼Œå®ƒè¡¨ç¤ºåœ¨è¿›è¡Œä¸€æ¬¡æƒé‡æ›´æ–°ä¹‹å‰ï¼Œç´¯ç§¯å¤šå°‘ä¸ªæ‰¹æ¬¡çš„æ¢¯åº¦ã€‚å…¶åœ¨æ·±åº¦å­¦ä¹ è®­ç»ƒä¸­çš„ä½œç”¨éå¸¸é‡è¦ï¼Œå°¤å…¶æ˜¯åœ¨æ˜¾å­˜æœ‰é™æ—¶ã€‚

`gradient_accumulation_steps`æ˜¯æŒ‡æ¯ç»è¿‡ä¸€å®šæ•°é‡çš„`batch`åæ‰è¿›è¡Œä¸€æ¬¡æ¢¯åº¦æ›´æ–°ã€‚ä¸¾ä¾‹æ¥è¯´ï¼š

> å¦‚æœ batch size = 4ï¼Œgradient_accumulation_steps = 2ï¼Œé‚£ä¹ˆå®é™…çš„è®­ç»ƒæ‰¹æ¬¡å¤§å°ç›¸å½“äº 8ï¼ˆå³ batch size * gradient_accumulation_stepsï¼‰ã€‚
> æ¢¯åº¦ç´¯ç§¯ä½¿å¾—è™½ç„¶æ¯ä¸ªæ‰¹æ¬¡å¤§å°è¾ƒå°ï¼Œä½†é€šè¿‡ç´¯ç§¯å¤šä¸ªæ‰¹æ¬¡çš„æ¢¯åº¦åå†è¿›è¡Œä¸€æ¬¡åå‘ä¼ æ’­å’Œæƒé‡æ›´æ–°ï¼Œä»è€Œæœ‰æ•ˆåœ°â€œæ¨¡æ‹Ÿâ€äº†æ›´å¤§çš„æ‰¹æ¬¡å¤§å°ã€‚

è€Œä»ä¸Šé¢çš„per_device_train_batch_sizeä¸Šæˆ‘ä»¬ä¹Ÿå¯ä»¥çœ‹å‡ºï¼Œå½“è®¡ç®—å‡ºçš„batchè¶Šå¤§ï¼Œå¯¹æ˜¾å­˜çš„æ¶ˆè€—è¶Šå¤šï¼Œä½†æ˜¯åœ¨åˆé€‚èŒƒå›´å†…ï¼Œæ¨¡å‹æ”¶æ•›æ•ˆæœä¹Ÿè¶Šå¥½ï¼Œå…·ä½“æˆ‘ä»¬å¯ä»¥è§‚å¯Ÿä¸‹ä¸‹é¢çš„å›¾ï¼š

![æ¢¯åº¦ç´¯è®¡æ­¥æ•°](./example/gradient.png)

> å¯ä»¥çœ‹åˆ°ï¼Œå½“batch_sizeå…·ä½“æ¯”è¾ƒå°çš„æ—¶å€™ï¼Œæ€»å…±çš„æ­¥é•¿stepsä¼šæ¯”è¾ƒé•¿ï¼Œè€Œä¸”æˆ‘ä»¬è®¾ç½®çš„å€¼æ˜¯4å€çš„å…³ç³»ï¼Œstepsä¹Ÿæ˜¯4å€çš„å…³ç³»ï¼Œè€Œå½“gradient_accumulation_stepsè®¾ç½®çš„æ¯”è¾ƒé«˜ï¼Œè¿™é‡Œæ˜¯16çš„æ—¶å€™ï¼Œæ¨¡å‹ä¼šåœ¨å¾ˆå°stepçš„æ—¶å€™æ”¶æ•›ï¼Œè€Œgradient_accumulation_steps=4çš„æ—¶å€™æ”¶æ•›å°±ä¼šæ¯”è¾ƒæ…¢ï¼Œå…·ä½“åŸå› å¦‚ä¸‹ï¼š
> 
> - é«˜çš„ gradient_accumulation_steps ä¼šå¯¼è‡´æ¯æ¬¡å‚æ•°æ›´æ–°æ›´ç²¾ç¡®ï¼Œä½¿å¾—æ¯æ¬¡æ›´æ–°çš„æ­¥é•¿è¾ƒå°ï¼Œè®­ç»ƒè¿‡ç¨‹ä¸­çš„å™ªå£°å‡å°‘ï¼Œä»è€Œå¸®åŠ©æ¨¡å‹æ›´å¿«æ‰¾åˆ°æœ€ä¼˜è§£ã€‚è¿™ä¼šå¯¼è‡´åœ¨è¾ƒå°‘çš„ steps ä¸­æ”¶æ•›ã€‚
> - å½“ gradient_accumulation_steps è®¾ç½®è¾ƒé«˜æ—¶ï¼Œå®é™…ä¸Šæ˜¯é€šè¿‡å¢åŠ æ¯ä¸ªæ›´æ–°å‘¨æœŸçš„â€œç´¯è®¡æ ·æœ¬æ•°â€æ¥å¢å¼ºæ¢¯åº¦ä¼°è®¡çš„å‡†ç¡®æ€§ã€‚è¿™ä¸ªè¿‡ç¨‹å¯ä»¥æ¨¡æ‹Ÿè¾ƒå¤§çš„ batch_sizeï¼Œå› ä¸ºæ¯æ¬¡æ›´æ–°æ‰€åŸºäºçš„æ•°æ®é‡å˜å¤§ï¼Œæ¢¯åº¦ä¼°è®¡æ›´ç¨³å®šã€‚æ›´ç¨³å®šçš„æ¢¯åº¦ä¼šåŠ é€Ÿæ¨¡å‹æ”¶æ•›ï¼Œå°¤å…¶æ˜¯åœ¨ä¼˜åŒ–æ—¶ï¼Œæ¨¡å‹çš„å‚æ•°æ›´æ–°æ–¹å‘æ›´ä¸ºæ¸…æ™°ï¼Œé¿å…äº†å°æ‰¹æ¬¡å¸¦æ¥çš„é«˜å™ªå£°ã€‚
> - gradient_accumulation_steps è¶Šå¤§ï¼Œæ¨¡å‹çš„æƒé‡æ›´æ–°å°±ä¼šè¶Šå°‘ï¼Œä½†æ¯æ¬¡æ›´æ–°æ—¶åŸºäºçš„ä¿¡æ¯é‡è¾ƒå¤§ã€‚æ›´æ–°é¢‘ç‡å‡å°‘ï¼Œæ¢¯åº¦è®¡ç®—æ›´åŠ ç¨³å®šï¼Œè¿™æœ‰åŠ©äºåœ¨è¾ƒå°‘çš„æ­¥éª¤å†…æ”¶æ•›ã€‚
> 
> ğŸš¨**æ³¨æ„ï¼šgradient_accumulation_stepsè¶Šå¤§ï¼Œå¯¹æ˜¾å­˜çš„éœ€æ±‚è¶Šé«˜ï¼Œæ‰€ä»¥è¯¥å¦‚ä½•é€‰æ‹©éœ€è¦åŸºäºè‡ªèº«éœ€æ±‚ã€‚**

> âœ¨âœ¨âœ¨***è‡³æ­¤ï¼Œæ‚¨å·²å®Œæˆå…¨éƒ¨çš„æ•™ç¨‹***âœ¨âœ¨âœ¨
