# LLaDAæ¨¡å‹é¢„è®­ç»ƒä¸å¾®è°ƒå®æˆ˜

<div style="display:flex;justify-content:center;">
  <figure style="text-align:center;margin:0;">
    <img src="./picture/example2.gif" style="width:100%">
  </figure>
</div>

> ä½œè€…ä¿¡æ¯ï¼šæƒ…æ„Ÿæœºå™¨å®éªŒå®¤ç ”ç©¶å‘˜-æé¦¨é›¨  
> é‚®ç®±ï¼šwind.340171@gmail.com

**ğŸ“šèµ„æ–™**

- **ä»£ç **ï¼š[llada-pretrian-sft](https://github.com/828Tina/llada-pretrain-sft)
- **æ•°æ®é›†**ï¼š[pretrain](https://www.modelscope.cn/datasets/allenai/c4)ï¼Œ[sft](https://www.modelscope.cn/datasets/AI-ModelScope/alpaca-gpt4-data-zh)
- **æ¨¡å‹**ï¼š[llada-8b](https://www.modelscope.cn/models/GSAI-ML/LLaDA-8B-Base)
- **SwanLab**ï¼š[llada-swanlab](https://swanlab.cn/@LiXinYu/llada-sft/overview)

æœ¬æ¬¡æ•™ç¨‹ä»£ç æºäº[dllm](https://github.com/ZHZisZZ/dllm)ï¼Œé‡Œé¢æœ‰å®Œæ•´çš„lladaæ¨¡å‹é¢„è®­ç»ƒä»¥åŠå¾®è°ƒæ–¹æ³•ï¼Œåœ¨æ­¤æ„Ÿè°¢ä½œè€…å¼€æºlladaè®­ç»ƒæ¡†æ¶ğŸ™ã€‚

<div style="display:flex;justify-content:center;">
  <figure style="text-align:center;margin:0;">
    <img src="./picture/logo.gif" style="width:80%">
  </figure>
</div>

## ç›®å½•

[[toc]]

## ç®€ä»‹

ç¼ºå›¾

åœ¨å‰é¢çš„ç« èŠ‚ä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†å¾ˆå¤šå…³äºè‡ªå›å½’æ¨¡å‹çš„è®­ç»ƒæ–¹æ³•ï¼Œå“ªæ€•æ˜¯å¤šæ¨¡æ€æ¨¡å‹ï¼Œå…¶ä¸­LLMéƒ¨åˆ†ä¹Ÿæ˜¯åŸºäºè‡ªå›å½’æ¨¡å‹çš„ï¼ˆç¬¬å…­ç« ï¼‰ã€‚åœ¨æˆ‘ä»¬çš„è¯¾ç¨‹é‡Œå¹¶æ²¡æœ‰å®Œæ•´çš„å…³äºdiffusionæ¨¡å‹ï¼Œä¹Ÿå°±æ˜¯æ‰©æ•£æ¨¡å‹çš„è®­ç»ƒæ–¹æ³•ã€‚æœ¬æ¬¡æ•™ç¨‹æˆ‘ä»¬å°±æ¥å®ç°diffusionæ¨¡å‹çš„é¢„è®­ç»ƒä»¥åŠå¾®è°ƒï¼Œå…¶ä¸­**å¾®è°ƒä¸ºæ ¸å¿ƒï¼Œé¢„è®­ç»ƒä»…åšå°è¯•ä»¥åŠéªŒè¯ç›¸å…³è®ºæ–‡ä¸­çš„è®ºç‚¹å³å¯ã€‚**

å…¶ä¸­æ‰©æ•£æ¨¡å‹æˆ‘ä»¬é€‰æ‹©LLaDAæ¨¡å‹ï¼Œå¾®è°ƒæ•°æ®é›†è¿˜æ˜¯é‡‡ç”¨ç»å…¸çš„instructæ•°æ®é›†alpacaï¼Œé¢„è®­ç»ƒæ•°æ®é›†ç»è¿‡å¤šæ¬¡è¯•éªŒï¼Œæˆ‘ä»¬é‡‡ç”¨C4æ•°æ®é›†æ¥è¿›è¡Œè®­ç»ƒã€‚


## LLaDAåŸç†

### LLaDAåŸæ–‡è§£è¯»

### DSæ¨¡å‹è®­ç»ƒscaling lawè®ºæ–‡è§£è¯»

### æ€»ç»“

## å®Œæ•´è®­ç»ƒ

### 1. ç¯å¢ƒå®‰è£…

- å…‹éš†ä»£ç 

```bash
git clone https://github.com/828Tina/llada-pretrain-sft.git
cd llada-pretrain-sft
```

- å®‰è£…ç¯å¢ƒ

```bash
pip install -r requirements.txt -i https://mirrors.aliyun.com/pypi/simple/
```

- ç¡¬ä»¶è¦æ±‚

1. $5090ä¸ªæ•° \ge 1$
2. `Pytorch` $\ge$ 2.7ï¼ŒCUDAé€‚åº”è‡ªå·±çš„ç‰ˆæœ¬ï¼Œæˆ‘çš„æ˜¯12.8

<div style="background:#e7f8ff;color:#000;padding:12px 16px;border-left:4px solid #20c0ff;">
ç”±äº5090æ˜¯æ¯”è¾ƒæ–°çš„GPUï¼Œå®‰è£…ç¯å¢ƒçš„æ—¶å€™ä¼šæœ‰æ¯”è¾ƒå¤šçš„é—®é¢˜ï¼Œæˆ‘åœ¨<a href="http://localhost:5173/course/llm_train_course/07-audio/1.cosyvoice-sft/README.html#_1-%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85" target="_blank" rel="noopener">CosyVoice</a>ä¸€ç¯‡ä¸­å·²ç»æ±‡æ€»äº†è§£å†³åŠæ³•ï¼Œå¯ä»¥å‰å¾€æŸ¥çœ‹ã€‚
</div>

### 2. æ•°æ®å¤„ç†

åœ¨ç®€ä»‹ä¸­æˆ‘ä»¬å¼ºè°ƒï¼ŒSFTæ˜¯æ ¸å¿ƒï¼Œå› æ­¤æˆ‘ä¼šæŒ‰ç…§SFTéœ€è¦çš„æ•°æ®é›†æ ¼å¼æ¥è®²è¿°ï¼Œé¢„è®­ç»ƒå…¶å®éµå¾ªçš„æ˜¯åŒæ ·çš„æ­¥éª¤ï¼Œåªä¸è¿‡é¢„è®­ç»ƒéœ€è¦çš„æ˜¯textæ•°æ®è€Œå·²ã€‚

é¦–å…ˆæˆ‘ä»¬éœ€è¦ä¸‹è½½æ•°æ®é›†ï¼Œæˆ‘å¸Œæœ›ç”¨æœ¬åœ°çš„æ•°æ®é›†æ¥å®Œæˆæœ¬æ¬¡å¾®è°ƒï¼Œå‚è€ƒäº†[datasets](https://huggingface.co/docs/datasets/process#save)å…³äºæ•°æ®ä¿å­˜å’Œä½¿ç”¨çš„ä»£ç ï¼Œè§‰å¾—ä»¥ `Arrow` æ ¼å¼ä¿å­˜åˆ°æœ¬åœ°ç£ç›˜ç„¶åè¯»å–çš„æ–¹å¼æ›´æ–¹ä¾¿ï¼Œ`Arrow` æ˜¯æœªå‹ç¼©çš„ï¼Œå› æ­¤é‡æ–°åŠ è½½é€Ÿåº¦æ›´å¿«ï¼Œéå¸¸é€‚åˆæœ¬åœ°ç£ç›˜ä½¿ç”¨å’Œä¸´æ—¶ç¼“å­˜ã€‚

ä¸Šè¿°è¿‡ç¨‹ä¸»è¦ä½¿ç”¨`save_to_disk`å’Œ`load_from_disk`ä¿å­˜å’ŒåŠ è½½æ•°æ®é›†ï¼Œä¸è¿‡å¦‚æœç£ç›˜ç©ºé—´æœ‰é™ï¼Œå»ºè®®è¿˜æ˜¯ç›´æ¥ç”¨`load_dataset`ã€‚

<div style="background:#e7f8ff;color:#000;padding:12px 16px;border-left:4px solid #20c0ff;">å¦‚æœæƒ³ç›´æ¥é¢„å¤„ç†æ•°æ®é›†çš„å°ä¼™ä¼´ï¼Œå¯ä»¥ç›´æ¥è¿è¡Œ<a href="https://github.com/828Tina/llada-pretrain-sft/blob/main/data.ipynb"target="_blank" rel="noopener">notebook</a>ä¸­çš„ä»£ç ï¼ŒåŸç†æ­¥éª¤å¦‚ä¸‹ï¼š
</div>

**SFTè®­ç»ƒ**ä¸‹è½½æ•°æ®æ ¼å¼å‚è€ƒAlpacaæ•°æ®é›†æ ¼å¼:

```python
Dataset({
    features: ['instruction', 'input', 'output'],
    num_rows: 48818
})
```

ç„¶åéœ€è¦è½¬æ¢æˆgptçš„å¯¹è¯æ ¼å¼ï¼Œä¹Ÿå°±æ˜¯messagesï¼š

```python
{
    "messages": [
        {"role": "user", "content": prompt},
        {"role": "assistant", "content": response},
    ]
}
```

æœ€åç”¨tokenizerè½¬æ¢æˆtokenså½¢å¼ï¼š

```python
Dataset({
    features: ['input_ids', 'labels', 'prompt_len'],
    num_rows: 48818
})
```

ç„¶åä¿å­˜æˆArrowæ ¼å¼åˆ°æœ¬åœ°ç£ç›˜ï¼Œç­‰è®­ç»ƒæ—¶å¯ä»¥ç›´æ¥è°ƒç”¨ã€‚

å¯¹äºé¢„è®­ç»ƒæ•°æ®é›†ï¼Œåªè¦ä¸‹è½½çš„æ•°æ®é›†é‡Œæœ‰`text`æ ‡ç­¾ï¼Œå¯ä»¥ç›´æ¥ä¿å­˜åˆ°æœ¬åœ°ä¸ç”¨è½¬æ¢ï¼Œä»£ç å¦‚ä¸‹ï¼š

```python
from datasets import load_dataset

data_path='/data/lxy/diffusion/data/c4-en/en.noblocklist'
c4_dataset=load_dataset(data_path,split='train')

output_path='/data/lxy/diffusion/data/c4-en-train'
c4_dataset.save_to_disk(output_path)
```

é¢„è®­ç»ƒä¹‹æ‰€ä»¥å¯ä»¥ç›´æ¥ä¿å­˜textå½¢å¼å†…å®¹ï¼Œæ˜¯å› ä¸ºåœ¨æ•°æ®é¢„å¤„ç†é˜¶æ®µç›´æ¥è‡ªåŠ¨è½¬æ¢æˆtokensæ ¼å¼ï¼Œè€ŒSFTç”±äºæˆ‘æœ‰ä¸ªå‚æ•°`load_preprocessed_data`è®¾ç½®ä¸º`True`äº†ï¼ˆå®˜æ–¹é»˜è®¤ä¸ºFalseï¼‰ï¼Œå¯¼è‡´ä¸ä¼šè‡ªåŠ¨è½¬æ¢tokensï¼Œæˆ‘ä¸æƒ³æ”¹æºä»£ç ï¼Œå› æ­¤ç›´æ¥æŠŠæ•°æ®é›†åœ¨ä¸‹è½½é˜¶æ®µå°±è½¬æ¢å¥½ä¿å­˜çš„ã€‚

*æˆ‘ä»¬çœ‹ä¸‹`dllm`çš„å…³äºæ•°æ®å¤„ç†éƒ¨åˆ†çš„ä»£ç ï¼š*

**pretrain**

```python
dataset = dllm.data.load_pt_dataset(
          data_args.dataset_args,
          streaming=data_args.streaming,
          load_preprocessed_data=data_args.load_preprocessed_data,
      )
      dataset = dataset.map(
          functools.partial(
              dllm.utils.tokenize_and_group,
              tokenizer=tokenizer,
              text_field=data_args.text_field,
              seq_length=data_args.max_length,
              insert_eos=data_args.insert_eos,
              drop_tail=data_args.drop_tail,
          ),
          batched=True,
          remove_columns=dataset["train"].column_names,
          **({} if data_args.streaming else {"num_proc": data_args.num_proc}),
          **({} if data_args.streaming else {"desc": "Mapping dataset to PT format"}),
      )
```

**SFT**

```python
dataset = dllm.data.load_sft_dataset(
          data_args.dataset_args,
          load_preprocessed_data=data_args.load_preprocessed_data,
      )
      if not data_args.load_preprocessed_data:
          map_fn = partial(
              dllm.utils.default_mdlm_sft_map_fn,
              tokenizer=tokenizer,
              mask_prompt_loss=data_args.mask_prompt_loss,
          )
          dataset = dataset.map(
              map_fn,
              num_proc=data_args.num_proc,
              desc="Mapping dataset to SFT format",
          )
```


<div style="background:#ffeae4ff;color:#000;padding:12px 16px;border-left:4px solid #fc592cff;">
<strong>æ³¨æ„ï¼š</strong>
è®­ç»ƒçš„æ—¶å€™çœ‹ä¸‹æœ€ç»ˆäº¤ç»™Trainerçš„datasetså†…å®¹æ˜¯å¦æ˜¯tokenså°±è¡Œï¼Œdllmçš„Trainerç»§æ‰¿çˆ¶ç±»Transformersçš„Trainerï¼Œå› æ­¤å¦‚ä½•ä½¿ç”¨ä¸å†èµ˜è¿°ã€‚
</div>


### 3. è®­ç»ƒä»£ç 

æœ¬æ¬¡æ•™ç¨‹æ ¸å¿ƒæ˜¯å­¦ä¼šå¾®è°ƒï¼Œæ•°æ®é›†é‡‡ç”¨ç»å…¸Alpacaæ•°æ®é›†ï¼Œé¢„è®­ç»ƒé‡‡ç”¨éƒ¨åˆ†C4è‹±æ–‡æ•°æ®é›†ã€‚æˆ‘ä»¬å¸Œæœ›æ•™ç¨‹èƒ½å¤Ÿæ•™ä¼šå®Œæ•´çš„è®­ç»ƒæµç¨‹ä»¥åŠæµ‹è¯•æµç¨‹ï¼Œå› æ­¤æ•°æ®é›†å‡é‡‡ç”¨ç»å…¸é€šç”¨çš„æ•°æ®é›†ã€‚

æˆ‘å°†åˆ†æˆä¸¤ä¸ªæ¨¡å—æ¥ï¼Œä¸ºäº†ç¬¦åˆæ­£å¸¸çš„è®­ç»ƒæµç¨‹ï¼Œæ•™ç¨‹ä¾æ¬¡æ˜¯é¢„è®­ç»ƒå’Œå¾®è°ƒï¼Œä»£ç åœ°å€ğŸ‘‰[ours](https://github.com/828Tina/llada-pretrain-sft/tree/main)

å¦å¤–ï¼Œå¦‚æœæœ‰å°ä¼™ä¼´æƒ³å¯¹æ¯”è‡ªå›å½’æ¨¡å‹å’Œæ©ç æ‰©æ•£æ¨¡å‹çš„åŒºåˆ«ï¼Œå¯ä»¥è®­ç»ƒllamaæ¨¡å‹æˆ–è€…qwenæ¨¡å‹ä½œä¸ºå¯¹æ¯”ã€‚ä¹‹æ‰€ä»¥å¯ä»¥è®­ç»ƒllamaæ¨¡å‹æ¥å¯¹æ¯”æ˜¯å› ä¸ºlladaçš„ä¸»ä½“éƒ¨åˆ†å…¶å®æ˜¯llamaç»“æ„ï¼Œç„¶åæ©ç ä¸é‡‡ç”¨è‡ªå›å½’æ¨¡å‹çš„ä¸Šä¸‰è§’å½¢å¼ï¼Œæˆ‘ä»¬åœ¨[æ¨¡å‹æ–‡ä»¶](https://www.modelscope.cn/models/GSAI-ML/LLaDA-8B-Base/file/view/master/modeling_llada.py?status=1#L659)ä¸­å¯ä»¥çœ‹åˆ°ï¼š

```python
# Modify: MDM set causal to False.
return F.scaled_dot_product_attention(
    q,
    k,
    v,
    attn_mask=attn_mask,
    dropout_p=dropout_p,
    is_causal=False,
)
```

å…¶ä¸­`is_causal`è®¾ç½®ä¸ºFalseï¼Œä¸é‡‡ç”¨è‡ªå›å½’æ¨¡å‹çš„æ©ç å½¢å¼ã€‚

å¹¶ä¸”æˆ‘ä»¬è¿˜å¯ä»¥ä»[å‚æ•°é…ç½®](https://www.modelscope.cn/models/GSAI-ML/LLaDA-8B-Base/file/view/master/config.json?status=1#L18)æ–‡ä»¶ä¸­çœ‹åˆ°ï¼š

```json
"block_group_size": 1,
"block_type": "llama",
"d_model": 4096,
```

ä¸»ä½“çš„blocké‡‡ç”¨`llama`ç»“æ„ï¼Œé‚£ä¹ˆé‡‡ç”¨`llama`æ¨¡å‹å¯¹æ¯”æ˜¯å¾ˆåˆé€‚çš„ã€‚

è€Œ`qwen`ä½œä¸ºæ¯”è¾ƒé€šç”¨çš„æ¨¡å‹ï¼Œæˆ‘ä»¬ç»å¸¸ä½¿ç”¨ï¼Œé‡‡ç”¨æ ‡å‡†è‡ªå›å½’æ¨¡å‹ç»“æ„ï¼Œå› æ­¤ä¹Ÿå¯ä»¥ä½œä¸ºå¯¹æ¯”æ¨¡å‹æµ‹è¯•å¯¹æ¯”æ•ˆæœã€‚

é‚£ä¹ˆæ¥ä¸‹æ¥æˆ‘ä»¬å°±å¼€å§‹è®­ç»ƒå§ï¼Œç”±äºæˆ‘å·²ç»æ•´ç†è¿‡ä»£ç ï¼Œå› æ­¤å¯ä»¥ç›´æ¥è¿è¡Œè„šæœ¬æ–‡ä»¶å®ç°ï¼Œä¸‹é¢ç®€è¦è¯´ä¸‹æ¯ä¸ªæ–‡ä»¶çš„å«ä¹‰å’Œç”¨æ³•ï¼š

```python
â”œâ”€â”€ configs
â”‚   â”œâ”€â”€ llada-8b-sft.yaml
â”‚   â”œâ”€â”€ llada-100M-pt.yaml
â”‚   â”œâ”€â”€ qwen2.5-7b-alpaca.yaml
â”‚   â”œâ”€â”€ ddp.yaml
â”‚   â”œâ”€â”€ zero2.yaml
â”‚   â””â”€â”€ ...
â”œâ”€â”€ dllm
â”œâ”€â”€ scripts
â”‚   â”œâ”€â”€ train-sft.sh
â”‚   â”œâ”€â”€ train-pt.sh
â”‚   â”œâ”€â”€ train-qwen.sh
â”‚   â”œâ”€â”€ eval.sh
â”‚   â””â”€â”€ ...
â”œâ”€â”€ examples
â”‚   â”œâ”€â”€ llada
â”‚   â”‚   â”œâ”€â”€ pt.py
â”‚   â”‚   â”œâ”€â”€ sft.py
â”‚   â”‚   â”œâ”€â”€ chat.py
â”‚   â”‚   â””â”€â”€ sample.py
â”‚   â”œâ”€â”€ qwen
â”‚   â”‚   â”œâ”€â”€ sft.py
â”‚   â”‚   â”œâ”€â”€ chat.py
â”‚   â”‚   â””â”€â”€ utils.py
```

- `configs`ï¼šåŒ…å«è®­ç»ƒè¶…å‚æ•°è®¾ç½®ã€deepspeedåˆ†å¸ƒå¼è®­ç»ƒå‚æ•°è®¾ç½®ç­‰
- `scripts`ï¼šè®­ç»ƒå¯åŠ¨æ–‡ä»¶ã€evalå¯åŠ¨æ–‡ä»¶ç­‰
- `examples`ï¼šæ ¸å¿ƒå¾®è°ƒã€é¢„è®­ç»ƒè®­ç»ƒä»£ç ç­‰

#### é¢„è®­ç»ƒ

é¢„è®­ç»ƒå’Œå¾®è°ƒçš„è®­ç»ƒæ–¹å¼å¯èƒ½ä¼šç¨å¾®æœ‰ç‚¹ä¸ä¸€æ ·ï¼ŒåŸå› å¦‚ä¸‹ï¼š

1. æ•™ç¨‹ä»…åšä¸ºç¤ºä¾‹ï¼Œæ ¸å¿ƒè¿˜æ˜¯å¾®è°ƒ
2. æˆ‘æƒ³éªŒè¯ä¸‹[Diffusion Beats Autoregressive in Data-Constrained Settings](https://arxiv.org/pdf/2507.15857)è¿™ç¯‡æ–‡ç« çš„è§‚ç‚¹ï¼Œå› æ­¤ä¼šé‡‡ç”¨å°å‚æ•°é‡çš„æ¨¡å‹ï¼Œå’Œå°‘è§„æ¨¡tokensçš„æ•°æ®é›†ä½œä¸ºè®­ç»ƒèµ„æº

ğŸ’¡ä»åŸå› ä¸Šå¤§å®¶ä¹Ÿèƒ½çœ‹å‡ºï¼Œå’Œå¾®è°ƒä¸ä¸€æ ·çš„æ˜¯ï¼Œ**`å°å‚æ•°é‡æ¨¡å‹`** ä½œä¸ºåŸºåº§æ¨¡å‹ã€‚é‚£ä¹ˆå¦‚ä½•æ„å»º`å°å‚æ•°é‡æ¨¡å‹`å‘¢ï¼Ÿ

å…¶å®å¾ˆç®€å•ï¼Œé¢„è®­ç»ƒæ¨¡å‹å…¶å®å°±æ˜¯æ„å»ºå¥½æ¡†æ¶åï¼Œå–‚å¤§é‡çš„æ•°æ®é›†è®©æ¨¡å‹å­¦ä¼šå¦‚ä½•ç”Ÿæˆå†…å®¹ï¼Œè€Œè®­ç»ƒå‰æ˜¯æ²¡æœ‰æƒé‡æ–‡ä»¶çš„ï¼Œæˆ–è€…è¯´ç”¨ä¸ä¸Šæƒé‡æ–‡ä»¶çš„ã€‚å› æ­¤æƒ³è¦æ„å»ºå°å‚æ•°é‡æ¨¡å‹ï¼Œç›´æ¥æŠŠ`config`æ–‡ä»¶ä»¥åŠ`tokenizer`ç›¸å…³æ–‡ä»¶ä¸‹è½½ä¸‹æ¥å°±è¡Œï¼Œç±»ä¼¼äº`*.safetensors`è¿™æ ·çš„æ–‡ä»¶ç›´æ¥ä¸ç”¨ä¸‹è½½ã€‚ç„¶åæˆ‘ä»¬ä¿®æ”¹`config.json`ä¸­çš„å‚æ•°ï¼Œè®©æœ€ç»ˆç®—å‡ºæ¥çš„å‚æ•°é‡è¾¾åˆ°æˆ‘ä»¬è¦çš„é‡çº§å°±è¡Œï¼Œæˆ‘ä½¿ç”¨çš„æ¨¡å‹æ˜¯100Må¤§å°ã€‚

ä¸‹é¢è·Ÿç€æˆ‘çš„ä»£ç æŒ‰æ­¥éª¤å®ç°ï¼š

**1. ä¸‹è½½æ–‡ä»¶**

ç”±äºæˆ‘ä»¬æ ¸å¿ƒä¸ºå¾®è°ƒï¼Œåœ¨å¾®è°ƒä»£ç ä¸­å·²ç»åŒ…å«äº†ä¸‹è½½llada-8bæ¨¡å‹çš„æ­¥éª¤ï¼Œå› æ­¤å¦‚æœè¦æ„å»ºä¸€ä¸ª100Mçš„æ¨¡å‹ï¼ŒæŠŠllada-8bä¸­**å»é™¤** `*.safetensors`çš„æ‰€æœ‰çš„æ–‡ä»¶å¤åˆ¶åˆ°æ–°çš„æ–‡ä»¶å¤¹ä¸­ï¼Œå‘½åæˆ`llada-100M`å°±è¡Œã€‚

<div style="display:flex;justify-content:center;">
  <figure style="text-align:center;margin:0;">
    <img src="./picture/example3.png" style="width:100%">
  </figure>
</div>

**2. ä¿®æ”¹å‚æ•°**

å¯¹äºå¦‚ä½•ä¿®æ”¹å‚æ•°ï¼Œ[è®ºæ–‡](https://arxiv.org/pdf/2507.15857)ä¸­ç»™å‡ºäº†å¯¹åº”çš„å‚æ•°é‡ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

<div style="display:flex;justify-content:center;">
  <figure style="text-align:center;margin:0;">
    <img src="./picture/example4.png" style="width:100%">
  </figure>
</div>

ä½†æ˜¯æˆ‘åœ¨å®è·µçš„æ—¶å€™å‘ç°æ€»æ˜¯ä¼šè¶…è¿‡è¡¨æ ¼ä¸­çš„å‚æ•°ï¼Œè¿™å¯èƒ½æ˜¯ç”±äº`vocab_size`ä»¥åŠå…¶ä»–çš„ä¸€äº›å‚æ•°å¯¼è‡´çš„ï¼Œå› æ­¤è¡¨æ ¼ä¸­å‚æ•°ä»…åšå‚è€ƒï¼Œæˆ‘è®¾ç½®çš„å‚æ•°å¦‚ä¸‹æ‰€ç¤ºï¼š

```json
{
  "activation_type": "silu",
  "alibi": false,
  "alibi_bias_max": 8.0,
  "architectures": [
    "LLaDAModelLM"
  ],
  "attention_dropout": 0.0,
  "attention_layer_norm": false,
  "attention_layer_norm_with_affine": true,
  "auto_map": {
    "AutoConfig": "configuration_llada.LLaDAConfig",
    "AutoModelForCausalLM": "modeling_llada.LLaDAModelLM",
    "AutoModel": "modeling_llada.LLaDAModelLM"
  },
  "bias_for_layer_norm": false,
  "block_group_size": 1,
  "block_type": "llama",
  "d_model": 448,
  "embedding_dropout": 0.0,
  "embedding_size": 126464,
  "eos_token_id": 126081,
  "flash_attention": false,
  "include_bias": false,
  "include_qkv_bias": false,
  "init_cutoff_factor": null,
  "init_device": "meta",
  "init_fn": "mitchell",
  "init_std": 0.02,
  "input_emb_norm": false,
  "layer_norm_type": "rms",
  "layer_norm_with_affine": true,
  "mask_token_id": 126336,
  "max_sequence_length": 1024,
  "mlp_hidden_size": 768,
  "mlp_ratio": 2,
  "model_type": "llada",
  "multi_query_attention": null,
  "n_heads": 7,
  "n_kv_heads": 7,
  "n_layers": 6,
  "pad_token_id": 126081,
  "precision": "amp_bf16",
  "residual_dropout": 0.0,
  "rms_norm_eps": 1e-05,
  "rope": true,
  "rope_full_precision": true,
  "rope_theta": 10000.0,
  "scale_logits": false,
  "transformers_version": "4.46.3",
  "use_cache": false,
  "vocab_size": 126464,
  "weight_tying": false
}
```

é€šè¿‡è®¡ç®—å¾—åˆ°æ€»å‚æ•°é‡ï¼š

```python
from transformers import AutoConfig, AutoModelForCausalLM
import torch

config = AutoConfig.from_pretrained("/data/lxy/diffusion/llada-100M",trust_remote_code=True)

with torch.device("meta"):
    model = AutoModelForCausalLM.from_config(config)   # åªå»ºå½¢çŠ¶ï¼Œä¸å å†…å­˜

print(model.num_parameters())

# 124327616
```

ç„¶åé¢„è®­ç»ƒå¯åŠ¨ä»£ç å¦‚ä¸‹ï¼š

```bash
bash scripts/train-pt.sh
```

å¯¹åº”è¶…å‚æ•°è®¾ç½®ä¸º`configs/llada-100M-pt.yaml`ï¼Œå…·ä½“çš„å‚æ•°è®¾ç½®å¦‚ä¸‹ï¼š

```yaml
# ModelArguments
model_name_or_path: /data/lxy/diffusion/llada-100M

# DataArguments
dataset_args: /data/lxy/diffusion/data/c4-en-shuffled[train:1000_000,test:1000]
text_field: text
streaming: false
num_proc: 8
drop_tail: true
max_length: 1024
load_preprocessed_data: true
insert_eos: true
random_length_ratio: 0.01

# TrainingArguments
output_dir: /data/lxy/diffusion/output/llada-pt-c4-500Mtokens-epoch-1
run_name: llada-pt-c4-500Mtokens-epoch-1
learning_rate: 3.0e-4
warmup_steps: 2000
# num_train_epochs: 1
max_steps: 10
per_device_train_batch_size: 2
per_device_eval_batch_size: 2
gradient_accumulation_steps: 8
logging_steps: 20
eval_strategy: steps
eval_steps: 200
save_steps: 1000
save_total_limit: 2
```

éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œ`warmup_steps`éœ€è¦æ ¹æ®æ•°æ®é‡ä»¥åŠè®­ç»ƒè½®æ¬¡æ¥è®¾ç½®å›ºå®šå€¼ï¼Œ2000æ­¥çš„é¢„çƒ­æ¯”è¾ƒåˆé€‚ã€‚å…¶ä»–çš„å‚æ•°è®¾ç½®å’Œå¾®è°ƒå‚æ•°è®¾ç½®ç›¸åŒã€‚

#### å¾®è°ƒ

åœ¨ä¸‹è½½å¥½æ¨¡å‹å¹¶ä¸”æ•°æ®é›†é¢„å¤„ç†åï¼Œè¿è¡Œä¸‹é¢çš„ä»£ç å³å¯ï¼š

```bash
bash scripts/train-sft.sh
```

å¦‚æœè¦ä¿®æ”¹è¶…å‚æ•°ç­‰ï¼Œé‚£ä¹ˆå¯¹`configs/llada-8b-sft.yaml`çš„å†…å®¹è¿›è¡Œä¿®æ”¹ï¼š

```yaml
# ModelArguments
model_name_or_path: /data/lxy/diffusion/llada-8b
lora: true
target_modules: all-linear
r: 32
lora_alpha: 64
lora_dropout: 0.05

# DataArguments
dataset_args: /data/lxy/diffusion/data/alpaca-zh-gpt[train:2000,test:200]
num_proc: 8
max_length: 1024
load_preprocessed_data: true


# TrainingArguments
output_dir: /data/lxy/diffusion/output/llada-gpu1-epoch-test
report_to: swanlab
run_name: llada-alpaca-zh-epoch-test
learning_rate: 3.0e-4
warmup_ratio: 0.1
# num_train_epochs: 1
max_steps: 10
per_device_train_batch_size: 2
per_device_eval_batch_size: 2
gradient_accumulation_steps: 8
logging_steps: 2
eval_strategy: steps
eval_steps: 200
save_steps: 1000
save_total_limit: 2
```

æœ‰äº›åœ°æ–¹éœ€è¦æ³¨æ„ï¼š

1. `dataset_args`æ˜¯ä½ çš„æ•°æ®é›†ä¿å­˜åœ°å€ï¼Œç”±äºæˆ‘ä¸‹é¢çš„`load_preprocessed_data`è®¾ç½®ä¸º`true`ï¼Œä¹Ÿå°±æ˜¯æå‰å¤„ç†äº†æ•°æ®é›†çš„æ„æ€ï¼Œå› æ­¤ä¿å­˜çš„æ•°æ®é›†å†…å®¹è¦æ±‚æ˜¯tokenså½¢å¼ã€‚
2. æœ€å¥½å°†`max_steps`æ”¹æˆ`num_train_epochs`ï¼Œç„¶åå¾®è°ƒ2-3ä¸ªepochå³å¯ã€‚å¦‚æœæ˜¯`max_steps`æœ€å¥½æå‰è®¡ç®—ä¸‹é€‰æ‹©å¤šå°‘stepsè¾ƒä¸ºåˆé€‚ã€‚
3. `SwanLab`æ˜¯æˆ‘ä»¬çš„è®­ç»ƒè§‚æµ‹å·¥å…·ï¼Œç”±äº`dllm`ç»§æ‰¿äº†`Transformers`çˆ¶ç±»ï¼Œè€Œä¸”`Transformers`å·²ç»é›†æˆ`SwanLab`ï¼Œå› æ­¤æˆ‘ä»¬ç›´æ¥ä»¤`report_to=swanlab`ï¼Œå”¯ä¸€éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œå¦‚æœæƒ³ä¿®æ”¹é¡¹ç›®åç§°çš„è¯ï¼Œéœ€è¦æå‰è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œæˆ‘åœ¨è¿™é‡Œè¿›è¡Œè®¾ç½®ğŸ‘‰[project](https://github.com/828Tina/llada-pretrain-sft/blob/main/dllm/utils/configs.py#L7)



#### *Qwen

æœ¬æ¬¡æ•™ç¨‹é€‰æ‹©`Qwen`æ¨¡å‹ä½œä¸º`llada`æ¨¡å‹çš„å¯¹æ¯”æ¨¡å‹ï¼Œç”¨`Qwen`æ¨¡å‹è¿›è¡Œé¢„è®­ç»ƒå’Œå¾®è°ƒï¼Œåˆ†åˆ«å’Œ`llada`æ¨¡å‹å¯¹æ¯”é¢„è®­ç»ƒå’Œå¾®è°ƒæ•ˆæœã€‚

å…¶ä¸­é¢„è®­ç»ƒå’Œ`llada`ä¸€æ ·ï¼Œè®¾ç½®ä¸€ä¸ª100Må‚æ•°é‡çš„æ¨¡å‹æ¥è¿›è¡Œè®­ç»ƒï¼Œæ­¥éª¤å’Œ`llada`çš„ä¸€æ ·ï¼Œåªä¸è¿‡è¦è¿è¡Œä¸‹é¢çš„ä»£ç ï¼š

```bash
ç¼ºä»£ç 
```

å…¶æ¬¡æ˜¯å¾®è°ƒï¼Œå¯¹äº`Qwen`æ¨¡å‹çš„å¾®è°ƒæˆ‘ä»¬å·²ç»è®¾ç½®äº†å¾ˆå¤šæ•™ç¨‹ï¼Œå¦‚æœæœ‰å…´è¶£çš„å°ä¼™ä¼´å¯ä»¥æŸ¥çœ‹æˆ‘çš„å¦å¤–ä¸€ç¯‡ä¸“é—¨è®²[loraè®­ç»ƒ](https://docs.swanlab.cn/course/llm_train_course/03-sft/7.deepseek-lora/README.html)çš„æ–‡ç« ï¼Œè¿™é‡Œåªéœ€è¦è¿è¡Œä¸‹é¢çš„å¯åŠ¨æ–‡ä»¶å°±è¡Œï¼š

```bash
bash scripts/train-qwen.sh
```

è¶…å‚æ•°è®¾ç½®åœ¨`configs/qwen2.5-7b-alpaca.yaml`

> è¯¥éƒ¨åˆ†ä»…ä½œä¸ºlladaæ¨¡å‹ç»“æœçš„å¯¹æ¯”

## SwanLabè§‚æµ‹ç»“æœ



## ç»“æœæµ‹è¯•

å¯¹äºè®­ç»ƒå¾—åˆ°çš„ç»“æœï¼Œå¯ä»¥ç›´æ¥è¿›è¡Œ`chat`æ¨ç†å¯¹è¯ï¼Œæˆ–è€…ä¹Ÿå¯ä»¥ä½¿ç”¨`ceval`ã€`cmmlu`ç­‰æ•°æ®æ‰¹é‡æµ‹è¯•å¹¶å¾—åˆ°ç»“æœæ•°æ®ã€‚

### å•æ¬¡æ¨ç†å¯¹è¯

æˆ‘ä»¬å…ˆçœ‹ä¸‹å¦‚ä½•æ¨ç†ï¼Œåœ¨æ¨ç†å‰ï¼Œæˆ‘ä»¬å…ˆåˆå¹¶æ¨¡å‹å‚æ•°ï¼Œå¾®è°ƒç”¨çš„loraå¾®è°ƒï¼Œéœ€è¦åˆå¹¶å‚æ•°ï¼Œä½†æ˜¯å¦‚æœæ˜¯å…¨å‚é‡å¾®è°ƒï¼Œä¸ç”¨åœ¨æ„è¿™ä¸€æ­¥ï¼š

```bash
python /home/lxy/diffusion_project/llada-sft/examples/llada/merge.py \
        --lora_path /data/lxy/diffusion/output/llada-gpu1-epoch-3/checkpoint-final \
        --base_model_path /data/lxy/diffusion/llada-8b \
        --merge_path /data/lxy/diffusion/output/merge-llada-8b-alpaca-zh-gpt-epoch-3
```

ç„¶åå¦‚æœè¦å•æ¬¡æ¨ç†ï¼Œè¦ä½¿ç”¨`chat.py`æ–‡ä»¶ï¼Œè¿è¡Œä¸‹é¢çš„ä»£ç ï¼š

```bash
CUDA_VISIBLE_DEVICES=0 python -u examples/llada/chat.py \
    --model_name_or_path /data/lxy/diffusion/output/llada-lora \
    --steps 128 \
    --max_length 128 \
    --block_size 32
```

- `steps`ï¼šåœ¨æ‰©æ•£æ¨¡å‹çš„åå‘ç”Ÿæˆè¿‡ç¨‹ä¸­ï¼Œä» `t=1ï¼ˆå…¨æ©ç ï¼‰`åˆ° `t=0ï¼ˆæ— æ©ç ï¼‰`éœ€è¦æ‰§è¡Œçš„è¿­ä»£æ¬¡æ•°ã€‚æ¯ä¸€æ­¥å¯¹åº”ä¸€ä¸ªç¦»æ•£çš„ `t` å€¼ï¼Œæ¨¡å‹åœ¨è¯¥æ­¥éª¤é¢„æµ‹æ©ç ä½ç½®çš„å†…å®¹ã€‚

    - stepsè¶Šå¤§ï¼šç”Ÿæˆè´¨é‡é€šå¸¸æ›´é«˜ï¼Œå› ä¸ºæ›´å¤šè¿­ä»£å…è®¸æ›´ç²¾ç»†çš„è°ƒæ•´ï¼Œä½†æ¨ç†é€Ÿåº¦è¶Šæ…¢ã€‚

    - stepsè¶Šå°ï¼šæ¨ç†è¶Šå¿«ï¼Œä½†å¯èƒ½ç‰ºç‰²ç”Ÿæˆè´¨é‡ã€‚

- `block_size`ï¼šåœ¨ä½¿ç”¨å—æ‰©æ•£é‡‡æ ·ç­–ç•¥æ—¶ï¼Œæ¯ä¸ªå—ï¼ˆblockï¼‰ çš„é•¿åº¦ã€‚

    - block_size = ç”Ÿæˆé•¿åº¦ï¼ˆå¦‚1024ï¼‰ï¼šç›¸å½“äºçº¯æ‰©æ•£é‡‡æ ·ï¼Œä¸€æ¬¡æ€§ç”Ÿæˆæ•´ä¸ªåºåˆ—ã€‚

    - block_size = 1ï¼šç›¸å½“äºå®Œå…¨è‡ªå›å½’é‡‡æ ·ï¼Œé€è¯ç”Ÿæˆã€‚

    - block_size ä»‹äºä¸¤è€…ä¹‹é—´ï¼šåŠè‡ªå›å½’é‡‡æ ·ï¼Œå¹³è¡¡é€Ÿåº¦å’Œè´¨é‡ã€‚

è®ºæ–‡éªŒè¯äº†åœ¨`block_size=32`çš„æ—¶å€™ï¼Œå’Œçº¯æ‰©æ•£æ¨¡å‹æ•ˆæœå·®ä¸å¤šï¼Œå› æ­¤è¿™æ ·è®¾ç½®ï¼š

<div style="display:flex;justify-content:center;">
  <figure style="text-align:center;margin:0;">
    <img src="./picture/example6.png" style="width:80%">
  </figure>
</div>

### æ‰¹é‡æµ‹è¯•

æˆ‘å·²ç»æ ¹æ®`dllm`çš„ä»£ç è®¾è®¡äº†æµ‹è¯•ç”¨çš„è„šæœ¬ï¼Œè¿è¡Œä¸‹é¢çš„ä»£ç å°±å¯ä»¥è¿›è¡Œæµ‹è¯•ï¼š

```bash
bash scripts/eval-llada.sh
```

æˆ–è€…è¿è¡Œä¸‹é¢çš„ä»£ç ï¼š

```bash
export PYTHONPATH=../:$PYTHONPATH             
export HF_ALLOW_CODE_EVAL=1                 # Allow code evaluation
export HF_DATASETS_TRUST_REMOTE_CODE=True   # For cmmlu dataset

export TORCH_NCCL_ASYNC_ERROR_HANDLING=1    # Enable async error handling for multi-GPU communication to avoid deadlocks
export NCCL_DEBUG=warn                      # Show NCCL warnings for better diagnosis without flooding logs
export TORCH_DISTRIBUTED_DEBUG=DETAIL       # Provide detailed logging for PyTorch distributed debugging

CUDA_VISIBLE_DEVICES=0 accelerate launch --num_processes 1 \
    dllm/pipelines/llada/eval.py \
    --tasks cmmlu \
    --model llada \
    --apply_chat_template \
    --output_path /data/lxy/diffusion/eval/llada/llada-cmmlu/llada-8b-epoch-3/test \
    --log_samples \
    --max_batch_size 4 \
    --model_args "pretrained=/data/lxy/diffusion/output/merge-llada-8b-alpaca-zh-gpt-epoch-3,is_check_greedy=False,mc_num=1,max_length=1024,steps=256,block_size=64,cfg=0.0"
```

å¦‚æœè¦è¿›è¡Œåˆ«çš„taskæµ‹è¯•ä»»åŠ¡ï¼Œä¿®æ”¹å…¶ä¸­çš„`tasks`å³å¯ï¼Œéœ€è¦æ³¨æ„çš„æ˜¯ï¼Œdllmä½¿ç”¨`lm_eval`æ¥æµ‹è¯•çš„ï¼Œå› æ­¤`tasks`è¦é€‰æ‹©è¯¥æ¡†æ¶ä¸­æœ‰çš„ï¼Œå…·ä½“å¯ä»¥æŸ¥çœ‹ğŸ‘‰[tasksåˆ—è¡¨](https://github.com/EleutherAI/lm-evaluation-harness/tree/main/lm_eval/tasks)

## å‚è€ƒæ–‡çŒ®




